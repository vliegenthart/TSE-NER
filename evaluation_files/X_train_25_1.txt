These are the two Wikia encyclopedias with the largest number of articles evaluated by users regarding their quality. From the Wikia service  , we selected the encyclopedias Wookieepedia  , about the Star Wars universe  , and Muppet  , about the TV series " The Muppet Show " .their ground truth difference with the production ranker would be the same as ordering them by the estimated difference. P -perfect user model setting  , I -informational  , N -navigational LETOR eval- uation.In ranked lists  , users cannot understand " what the resource is about " without opening and investigating the LOD resource itself. Sindice 1  , Watson 2  adopt keyword-based search and ranked result lists presentation of traditional Information Retrieval IR  , which is not very efficient for large volumes of data 3 .Recall that in Figure 1we examined the same relationship on RateBeer data in more detail. In other words  , products with high average ratings are rated more highly by experts; products with low average ratings are rated more highly by beginners.We augmented these by pulling from a few repositories on GitHub that were aimed at collecting source code examples. We obtained our snippets from the Stack Overflow data repository provided for the 2013 MSR Challenge 3.The code to calculate MRR is included in the GitHub repository for this paper. Therefore  , we chose to only report MAP results in this paper  , since we consider MAP as more representative of the performance of an approach with regard to all results.In LETOR 3.0 package  , each dataset is partitioned into five for five-fold cross validation and each fold includes training   , testing and validation sets. Table 1shows the statistics of the datasets included in the LETOR 3.0 benchmark.To create features for the selection framework  , we use the published test runs 1 for these rankers to obtain the document scores for top 10 ranking documents  , and the list of 64 features that are available as part of LETOR. We use the results from three ranker baselines: Rank- Boost 5  , Regression  , and FRank 9 .all the incoming and outgoing links  , and for different values of the parameter λ  , in most cases did not result in retrieval improvement within the WT2g corpus Savoy 01. Fixing the parameter λ to 0.1 and k to 5  , the final retrieval status value of D 4   , noted RSVD 4   , will be :Low-level features include term frequency tf  , inverse document frequency idf  , document length dl  , and their combinations. Features in Letor OHSUMED dataset consists of 'low-level' features and 'high-level' features.In this paper  , we presented and evaluated GERBIL  , a platform for the evaluation of annotation frameworks. In the future  , we also plan to provide information about the point in time since when an annotator is stable  , i.e.  , the algorithm underlying the webservice has not changed.The similar reviews include similar expressions such as " would definitely return "   , " will definitely return " . Table 4presents one positive seed review from TripAdvisor.Therefore  , we make estimation from the crawled posting data. However  , accurate estimation of visit probabilities is impossibile due to the lack of login and browsing data of TripAdvisor users.On the Microsoft LETOR data set  , we see a small decrease in accuracy  , but the speedups are even more impressive. In particular  , on Set 1 the larger data set  , our parallel algorithm  , within a matter of hours  , achieves Expected Reciprocal Rank results that are within 1.4% of the best known results 6.Github provided an initial set of 1 ,733 projects meeting this criterion. As a concession to ease of analysis  , only projects using the popular Maven 4 build system were considered.Previous work on open source software projects and developers suggests that there is a complex social and technical structure around the concept of making contributions to projects. Informed by previous work  , we generate hypotheses to test in our analysis of contributions in GitHub.Knowing that hundreds or thousands of users  , some highly visible  , depend on a particular project may discourage project managers from accepting risky or uncertain code contributions. For popular projects  , the transparent nature of GitHub means project managers are aware  , at least in part  , of the identity of users of their project 5.The experimental results show that our approach can improve the base algorithm significantly with better precision  , recall and conversion rates. We evaluate our algorithm on the purchase history from an e-commerce website shop.com.Using parallelization with 20 threads  , our model could be fit on our largest dataset RateBeer of 2 million total events within two minutes. Updating Θ can be done in parallel for each class and stage  , and updating stages and classes can be parallelized for each sequence.To examine as many different implementations and hosts as possible  , we noted that the Billion Triple Challenge 2014 13 dataset consisted of a 4 GTriple corpus of spidered Web data. This resulted in a list of 312 endpoints.The project has been collecting data since February 2012. The GHTorrent dataset covers a broad range of development activities on Github  , including pull requests and issues.We compare the following three methods using Douban datasets: 1. This setting is employed to fairly compare the method SRimp with SRexp.Our study is based on data from the Github collaborative development forge  , as made available through our GHTorrent project 16. We then examine 291 carefully selected Ruby  , Python  , Java and Scala projects in total  , 166 ,884 pull requests  , and identify  , using qualitative and quantitative analysis  , the factors that affect pull request lifetime  , merging and rejection.The first is in the context of attention rewards on user-generated content UGC based sites  , such as online Q&A forums like Quora or StackOverflow. We are motivated by two different kinds of questions that arise in the context of designing rewards for crowdsourced content  , depending on the setting and the nature of the rewards .Surprisingly   , we were able to observe that a representative amount of users who have a website in their profiles are in fact self promoters  The percentage of self promoters found by this simple approach could be an indicator that in fact Pinterest is becoming more related to e-commerce. We do so by verifying if the main domain of a user is also her personal website described in the profile.To represent two different dimensions of the social connections in GitHub  , we used a measure for social distance and another for prior interaction. Events include participating in issues  , pull requests  , and commenting on various GitHub artifacts.This annotation has been widely adopted; for example  , GitHub contains about 35 ,000 uses of the annotation in 7 ,000 files https://github.com/search ?l=java&q=GuardedBy&type=Code. The intention is that when a locking discipline is expressed with @GuardedBy  , then " No set of operations performed sequentially or concurrently on instances of a thread-safe class can cause an instance to be in an invalid state " ; a thread-safe class is one that " uses synchronization whenever accessing the shared  , mutable state " .Finally  , we evaluate the proposed method on LETOR 3.0 benchmark collections1. The empirical results indicate that even with sparse models  , the ranking performance is still comparable to that of the standard gradient descent ranking algorithm.Despite its short history Quora exited beta status in January 2010  , Quora seems to have achieved where its competitors have failed  , i.e. Various estimates of user growth include numbers such as 150% growth in one month  , and nearly 900% growth in one year 23.Both Sig.ma and Sindice are document-based and don't offer SWS discovery features or search for data using SWS. It crawls the web continuously to index new documents and update the indexed ones.Integrators should be both proactive   , by establishing and perhaps even documenting a professional communication etiquette  , and reactive  , by following discussions and intervening in cases where discussion diverges from the etiquette . Awareness can be increased by contacting the development team using real-time communication channels e.g.  , IRC or its evolved counterpart GITTER  , which is better integrated in GitHub or by following the minimal PR idiom 7  depending on project preferences.Our approach was based on using the WT2g dataset  , consisting of 247 ,491 HTML documents at 2GB storage requirements. In order to test whether the associated hypothesis is true  , we developed a software application which would produce results based on conventional Content Analysis the baseline result and then re-rank those results based on a number of related Connectivity Analysis approaches.The code of the Primary Sources Tool is openly available https://github. With just one click  , the contributor can reject or approve a statement  , and  , in case of approval  , add the statement to Wikidata.To highlight key results  , we use comparisons against Stack Overflow  , a popular Q&A site without an integrated social network. In this paper  , we perform a detailed measurement study of Quora  , and use our analyses to shed light on how its internal structures contribute to its success.As Quora continues to grow  , it is clear that helping users easily identify and find the most meaningful and valuable questions and answers is a growing challenge. Our estimated number of questions in Quora for June 2012 is 700K  , which is consistent with previously reported estimates 24.They learn multiple ranking models for each of these clusters where they incorporate the notion of freshness into the traditional letor approach by generating hybrid labels based on relevance and freshness judgments similar to Dong et al. The clustering employed is a soft-clustering where each query is associated with all the clusters with different association weights.We started by identifying all the distinct hosts represented in the 100 gigabyte collection. The method of choosing the WT2g subset collection was entirely heuristic.The website is not used only for collaboration  , but also as a resource to find quality software. In addition to that  , GitHub users can follow other users  , to be notified of their actions.As we have seen in our experiments  , a HAC algorithm over term similarity outperforms all the RepLab systems: this is another evidence that corroborates the issue of data sparsity in our Online Reputation Monitoring problem. Overall  , the results of official RepLab systems were the first set of experiments on the RepLab 2013 dataset.The length of sequence can be of great interest in many datasets; for example  , it represents how actively a user enters reviews on BeerAdvocate and RateBeer  , how popular a phrase is in NIFTY  , or the skill of a player on Wikispeedia. Or  , do sequences that go through stages very quickly have more events ?These include the ability for developers to "follow" other members in the community and to "star" the repositories of different projects. GitHub also provides a set of social networking features.Many of such features cannot be easily integrated in the formulae of conventional retrieval models due to lack of theoretical foundations. One advantage of LETOR is that it allows incorporating features that addresses various characteristics of a document and its relevance to a topic.It is not uncommon to find prolific developers contributing code to 5-10 GitHub projects in the same week. With the advent of social coding tools like GitHub  , this has intensified.the Sindice dump for each entity candidate. At the final stage  , we perform search in the link open data LOD collection  , i.e.By comparing against this gold standard  , we evaluate the lexicons constructed using different methods. In this section  , we describe how we create a gold standard by performing human annotation on a data set of hotel reviews from TripAdvisor.Changes that required high amounts of discussion tend to be more closely scrutinized by more members of the site  , as GitHub users would look at discussion on a contribution as a signal of controversy. Certain contributions raise uncertainty about their value for a project and subsequently generate more discussion 19.I always got these favorites and these retweets  , and then I got followers on GitHub on the project. " . These two sub-collections are built from the same crawl; however  , blank nodes are filtered out in Sindice-ED  , therefore it is a subset of Sindice-DE. The dataset is available in two different formats: structured around documents Sindice-DE and structured around entities Sindice-ED.Figure 6 : Age of curated Pinterest identities: identities curated using Pinterest reputation signals vs additionally curated identities using all signals. Thus  , using inter-domain reputation signals allows us to curate more identities and enables us to do it faster.We randomly selected email addresses in batches of ten. We recruited eight participants from GitHub  , randomly selecting from the 68 ,949 GitHub users who had made at least one contribution in the previous twelve months  , used Java in at least one of their projects  , and had published their email address.We plot the log of negative log-likelihood due to scale of the values  , and so lower value implies that model has higher likelihood. Figures 4b shows the performance of our model in comparison with the best baseline B3 over the NASDAQ.The retrieval performance achieved was at least as good as the LETOR 4.0 baselines. To test the correctness of our SVM ranking algorithm and the correctness of the feature extractor we extracted features from the Million Query 2008 collection  , and performed a five-fold cross validation.Those features are then piped into different LETOR algorithms to produce several rank lists  , and eventually all the rank lists are merged using the conventional Reciprocal Rank based data fusion method. We introduce a two-pass retrieval framework  , where in the first pass we aim to retrieve as many relevant document as possible to ensure a reasonable level of recall  , and in the second pass we process all the retrieved documents in the first pass and extract features.In this section we present descriptions of the GitHub setting  , our data collection procedures  , measure calculation  , and analysis technique. From this dataset  , we fit a statistical model that associates social and technical contribution measures with the likelihood of pull request acceptance.We then present an evaluation of the framework that aims to quantify the effort necessary to include novel annotators and datasets to the framework. We focus in particular on how annotators and datasets can be added to GERBIL and give a short overview of the annotators and tools that are currently included in the framework.In detail  , in the first pass we use the standard Indri retrieval algorithm and BM25 with pseudo relevance feedback on the topby the length of the document. Those features are then piped into different LETOR algorithms to produce several rank lists  , and eventually all the rank lists are merged using the conventional Reciprocal Rank based data fusion method.Pinterest is a pinboard-style image sharing social network  , where everything is about photos and videos. Chafkin 2012.The LETOR-like selection methodology also selects very similar documents  , since the documents selected are those that give high BM25 values and thus have similar characteristics. At the other end of the discrepancy scale  , infAP for small sampling percentages selects the most diverse relevant documents while it converges fast to the average discrepancy between documents in the complete collection.All gathering is based on HTTP requests   , which is a challenge due to how the network was developed . There is no official public API to gather data from Pinterest   , thus we create our own distributed framework based on a client-server model.Fig- ure 1 shows a typical profile of a user that Silbermann's strategy successfully attracted to the network Chafkin 2012. Recently  , but after our crawling period  , Pinterest enabled the possibility of creating secret boards: basically  , boards which only the owner has access Milam 2012.Table 4presents one positive seed review from TripAdvisor. Both the similar reviews are negative and contain negative words like " horrible "   , " bad "   , " nauseous " which are synonyms to " awful " in the seed.The input to the job is METS documents retrieved from the DOMS repository using the Stager on top of the SCAPE DOMS connector. The source code for the implementation is available from GitHub 1 .Hence  , we only compare the proposal algorithm with Ranking-SVM  , but not Rank-Boost. The experimental results provided in the LETOR collection also confirm this.We first describe the process of curating identities on Pinterest. For this  , we consider the task of curating identities in the target domain Pinterest.Another kind of social interaction explored was board sharing  , for which we calculate the percentage of shared boards among the total amount of boards  , separated by gender Table 2. As shown in figure 4  , Pinterest users tend to follow others entirely and this behavior is not mediated by gender.TD2004 have more relevant documents per topic than other LETOR collections  , relevant documents remain relatively sparse. As the histogram shows  , relevant documents per topic are quite sparse  , restricting the number of feedback iterations possible with stable evaluation.If the NASDAQ Computer Index were further divided into software  , hardware  , services  , etc.  , one can further analyze comparisons with them. In this instance  , the computer sector has been outperformed by one of its members Apple by a large margin.The WT2G collection is a general Web crawl of Web documents  , which has 2 Gigabytes of uncompressed data. The Disk4&5 collection contains newswire articles from various sources  , such as Association Press AP  , Wall Street Journal WSJ  , Financial Times FT  , etc.  , which are usually considered as high-quality text data with little noise.This result is higher than the overall we calculated for Github; we attribute this to the fact that the dataset generation process employs heuristics to detect merges in addition to those happening with Github facilities. In our dataset  , most pull requests 84.73% are eventually merged.We have also made the code available for analyzing and benchmarking the profiles. We have implemented a URI-Key Generator  , more than one CDX Profiler  , and a script to merge profiles and published the code on GitHub 3 .Note that in all the results reported  , mentions that contain NIL or empty ground truth entities are discarded before the evaluation; this decision is taken as well in Gerbil version 1.1.4. Let M * be the ground truth entity annotations associated with a given set of mentions X.Missing important tweets and news items about an entity of interest can be disastrous and expensive 9. DOI: http://dx.doi.org/10.1145/2766462.2767839 previously been considered in various settings: at the WePS-3 evaluation effort 1  and as part of the RepLab 2012 and 2013 chal- lenges 2  , 3.Thus  , the collection is a means of curating but also supporting the re-finding of content that has been encountered online. the person who uploaded a photo that has been pinned on Pinterest may hold the original and may host it elsewhere online  , these would be difficult to obtain by the user if their collection was lost even if simply because it's hard to remember what's in the collection .In general  , such a set of features is based on datasets and vocabularies used in some LOD collection  , e.g.  , a huge collection of RDF graphs that was crawled by a Linked Data crawler like the Billion Triple Challenge dataset. To describe the differences of the data models that express the same example instance with different vocabularies and vocabulary terms  , we make use of features such as the number of datasets using a vocabulary or the total occurrence of a vocabulary term.Further  , the discrepancy among the selected relevant documents   , along with the discrepancy among the selected relevant and non-relevant documents for the different selection methods is illustrated in Figures 2. The LETOR-like selection achieves both high precision and recall at small percentages of data used for training up to 5% and then it drops to the levels of statAP and depth pooling.Despite the large number of repositories hosted at GitHub  , developers work only on a consistently smaller fraction of them. 6Each burst contains 10 new questions sent seconds apart  , and consistently produced 10 sequential qid's. To validate this statement  , we performed several small experiments where we added small bursts of new meaningful questions to Quora.Recent work Zoghbi  , Vuli´cVuli´c  , and Moens 2013 verifies that the images posted to sites like Pinterest are an accurate reflection of a user's interest   , and can be used to recommend relevant products. 2013 that focus on quantifying and analyzing Pinterest user behavior.They proposed several features based on users contributions and graph influence. 33  proposed an expertise modeling algorithm for Pinterest.The most comprehensive open access database for the area of chemistry is PubChem 14 . Generally  , this information can be retrieved from topic-centered databases.In LETOR  , there are a total of 16 ,140 query-document pairs with relevance judgments  , and 25 extracted features. definitely  , possibly  , or not relevant.Although the absolute performance of the best learned function seems low 0.63 accuracy  , we will see in the following sections that  , once the classification confidence is used as similarity measure  , it leads to the best topic detection performance reported on the RepLab dataset so far. In summary  , most signals in our study are able to improve the classification process with statistical significance over the use of term-based features only  , and their combination gives the best performance.In Quora  , the top 10 includes topics in various areas including technology  , food  , entertainment  , health  , etc. " We observed 56K topics in our dataset  , which is twice more than that of Stack Overflow  , even though Quora is smaller by 0   20   40   60   80   100   10 0 10 1 10 2 10 3 10 4 10 5 10Table 2lists the top 10 topics with most number of questions in each site.Suppose that user ui has n explicit social connections in the Douban dataset  , then we will choose the most similar n users as the implicit social connections in this method. SRimp: this is the social regularization method that uses the implicit social information.The relevancy judgments provided in OHSUMED are scored 0  , 1 or 2 and there are 45 features for each querydocument pair. The datasets provided in the LETOR There are 106 queries in the OSHUMED dataset.ACSys made that data available in two ways. Nick Craswell developed software for extracting hyper-link connectivity information from WT2g.But chemical articles contains both text and molecule structure images; we can only imagine what opportunities would we get by combining text data mining methods and cheminformatics search techniques. For example  , another popular database  , that provides substructure search functionality over more than 31 million chemical molecules  , is the PubChem database 2.Quora applies a voting system that leverages crowdsourced efforts to promote good answers. Second  , do super users get more votes  , and do these votes mainly come from their followers ?However  , Sindice search results may change due to dynamic indexing. One option was to use Sindice for dynamic querying.were detailed earlier in this document. Figure 3below shows the precision at 5 -1000 documents returned from running the modified queries on WT2g.GERBIL is an opensource and extensible framework that allows evaluating tools against currently 9 different annotators on 11 different datasets within 6 different experiment types. In this paper  , we present GERBIL – a general entity annotator benchmark –  , a community-driven effort to enable the continuous evaluation of annotation tools.Indri query language is utilized to integrate the synonyms of all identified chemicals into the automatically constructed queries with its powerful capabilities using the {} operator to handle synonyms of identified chemical entities. After the chemical entities are extracted  , we include top 10 most commonly used synonyms of the identified chemicals from PubChem 4 in the query.market  , we used data provided by TripAdvisor: The consumers that write reviews about hotels on TripAdvisor also identify their travel purpose business  , romance  , family  , friend  , other  and age group 1317  , 18-24  , 25-34  , 35-49  , 50-64  , 65+. For our experimental evaluation  , we instantiated our model framework using as target application the area of hotel search.This effectively creates a related question graph  , where nodes represent questions  , and links represent a measure of similarity as determined by Quora. One of Quora's core features is the ability to locate questions " related " to a given question.showing the proportion of social and non-social repins vs. the " maturity " of user on Pinterest  , as measured by the number of repins made since joining. Cosine similarity was computed at random time points between vectors of pins of users and 1 pins of their friends marked as " friends "  andThe index matching service that finds all web pages containing certain keywords is heavy-tailed. The applications used for the evaluation are two services from Ask.com 2 with different size distribution characteristics: a database index matching service and a page ranking service.However  , users cannot understand " what the resource is about " without opening and investigating the LOD resource itself  , since the resource title or example triples about the resource are not informative enough. Current WoD search engines and mechanisms  , such as Sindice 2 and Watson 3  , utilize full-text retrieval  , where they present a list of search results in decreasing relevance.We picked all projects that we could retrieve given the Github API  , and selected from these only based on constraints of building and testing. Threats due to sampling bias: To ensure representativeness of our samples  , we opted to use search results from the Github repository of Java projects that use the Maven build system.It extends SCOVO 10 with the ability to explicitly describe the structure of the data and distinguishes between dimensions  , attributes and measures. Data Cube model is compatible with SDMX – an ISO standard for sharing and exchanging statistical data and metadata.Figure 9plots the daily activity patterns of our target users  , broken down by individual days of the week. One deviation occurs the week of October 28: we hypothesize that Pinterest saw increased activity this week due Halloween-related pins.In Pinterest  , users pin photos or videos of interest to create theme-based image/video collections such as hobbies  , fashion  , events. That possibly returns to the different nature of the usage of both sites.In our survey  , we included an additional question asking why participants contribute to the chosen project. Indeed  , various developers discuss whether 1  , 50 or not 8  GitHub profiles should be the new de facto CV for developers .Our dataset includes various types of events performed by users on public repositories or following events between users i.e.  , when a user starts following another user. In this paper  , we analyze events that happened on GitHub over a period of 18 months  , between March 11  , 2012 and September 11  , 2013  , retrieved from that archive.Here  , the mechanism designer  , or site owner  , has a choice about how many of the received contributions to display  , i.e.  , how to reward the contributions with attention — he could choose to display all contributions for a particular task  , or display only the best few  , suppressing some of the poorer contributions. The first is in the context of attention rewards on user-generated content UGC based sites  , such as online Q&A forums like Quora or StackOverflow.These collections are hosted online and largely comprise other-generated content. Examples include Pinterest boards  , blogs  , and even collections of tweets.An interesting fact which helps to understand the Pinterest community is that in its earliest days  , the sign up was restricted to invitees only. Every pin posted must have a description and those which are not uploaded must have a direct link to its original source in the web.For our empirical analysis  , we use the different segments of the data set provided for the Billion Triple Challenge BTC 2012. The stream-based approach is also applicable to the full data crawls of D Datahub ,In Letor  , the data is represented as feature vectors and their corresponding relevance labels . There are 16 ,140 query-document pairs with relevance labels.It only requires UMBEL categorizations  , which can be achieved by number of methods such as the fuzzy retrieval model 8. iv Our approach is adaptable and can be plugged on top of any Linked Data search engine; in this paper  , we use Sindice 1.com/ViDA-NYU/user-agent-study. The URLs used in the experiment  , source code and response headers of all requests are available at https://github.Baker analyzed 1 ,000 JavaScript source code snippets and 4 ,000 Java source code snippets. We augmented these by pulling from a few repositories on GitHub that were aimed at collecting source code examples.f Xanga web-link categories In this section we study the prevalence with which this information is available  , and use this information to understand the extent to which one user may create multiple blogs.It is one example of how novel technology benefits programmers  , and it empowers them; GitHub's platform is responsible for the inception of many projects  , that otherwise wouldn't have existed 34. The features and usability provided by GitHub play a big role 34.The survey participants reported development experience was 17.2 years on average median 15; range 7 to 40  , while their GitHub experience was 5.9 years on average median 6; range less than 1 to since GitHub was founded. We iterated through the open-ended responses using grounded theory methods 12  , to categorize them and identify themes.A GitHub-wide acceptance process definition and enforcement mechanism might be beneficial to both integrators and contributors and might deter one-off  , low-quality contributions. In addition  , experienced contributors are used to searching for PR process documents  , though such policy documents are often not present in smaller projects.Each user has a " Top page  , which displays updates on recent activities and participated questions of their friends followees  , as well as recent questions under the topic they followed. Each Quora user has a profile that displays her bio information  , previous questions and answers  , followed topics  , and social connections followers and followees.Pull Requests in Github. An overview of the pull request process can be seen in Figure 1.The social graph of Pinterest is created through users following other users or boards they find interesting. In addition to pinning or repinning  , users can like a pin or comment on a pin.Further  , the samples came from a single repository Github  , and are all open source projects. Finally  , our findings are restricted to projects using the Java language  , the Maven framework  , and a standard project layout.We previously considered BeerAdvocate and RateBeer data in 28   , though not in the context of recommendation. In principle we obtain the complete set of reviews from each of these sources; data in each of our corpora spans at least 10 years.The first set is a relatively coarse-grained approach wherein we measure how many images a user repins in each of the 32 different Pinterest categories. To describe users' preferences for particular types of content  , we use two sets of features: Category Preferences and Object Preferences .By integrating such a large number of datasets  , experiment types and frameworks  , GERBIL allows users to evaluate their tools against other semantic entity annotation systems short: entity annotation systems by using exactly the same setting  , leading to fair comparisons based on exactly the same measures . GERBIL is an opensource and extensible framework that allows evaluating tools against currently 9 different annotators on 11 different datasets within 6 different experiment types.Figure 1: Number of events detected in the GitHub stream. Each event  , regardless of its kind  , usually includes some metadata about the entities involved e.g.  , the profile information of a user  , his or her number of followers  , the language of a repository   , etc.Simple K-nearest neighbour KNN with K set to 20 and Regression Tree was used to perform point-wise LETOR. Multiple LETOR methods have been tried  , which are different in many ways and we expect them to be complimentary during the final fusion.discussing travel experiences in TripAdvisor. Answers while others could be more general e.g.To answer our research questions  , we created and analyzed a dataset from the social open source software hosting site GitHub 12. In this section we present descriptions of the GitHub setting  , our data collection procedures  , measure calculation  , and analysis technique.Examples of Web of Data search engines 7 and lookup indexes are Falcons  , Sindice  , Swoogle and Watson. Examples of Linked Data browsers 6 are Tabulator  , Disco  , the OpenLink data browser and the Zitgist browser.We sent them an email if their address was registered with GitHub and if they were not integrators in the same repository; we collected 4 ,617 emails. For each repository  , we extracted the top 3 pull request contributors by the number of PRs they contributed.How to optimize towards diversity under the context LETOR is yet another problem to be studied in future. This is because we were counting on topic modelling based query expansion to improve diversity performance  , such that we have not defined a dedicated list-wise optimization criterion on top of the rank list that addresses diversity.Awareness. They might  , however  , rely on subtle social signals that environments like GitHub provide  , without realizing it.We use open coding a grounded theory tool to come up with an inclusive set of reasons of why pull requests are not merged as follows: the first author read the pull request discussion on Github for randomly selected pull requests and summarized the reasons for closing them into one sentence per sample; during a second pass  , the descriptions were aggregated and codes were extracted . RQ4 To examine why some pull requests are not merged  , we qualitatively analyze a set of randomly chosen non-merged pull requests in depth.Nevertheless  , in a setup similar to LETOR setup  , as in our experiments  , we show that substantially less documents than the ones used in LETOR can lead to similar performance of the trained ranking functions. Therefore  , in the case where hundreds of raw features are employed  , ranking functions may need more than 1% of the complete collection to achieve optimal performance.For example  , paid-for services such as pin4ever.com enable users to also store the visual juxtapositions  , re-pins and likes that relate to pinned content. Services already exist to support the backup of Pinterest boards  , tweets and blogs  , and this can take advantage of the curation that has already occurred online.Already  , we are working with members of the W3C Linking Open Drug Data LODD to add their code to this GitHub repository  , identify and select an open source license  , and improve the linking of Bio2RDF data. First  , the consolidation of scripts into a single GitHub repository will make it easier for the community to report problems  , contribute code fixes  , or contribute new scripts to add more data into the Bio2RDF network of linked data for the life sciences.Prime examples are the substance database PubChem 1 combining several chemical entity data sources and the document search engine ChemXSeer 2 . In an attempt to overcome the costly access to chemical literature  , several groups are currently working on building free chemical search engines.Whenever the need arises to more explicitly declare what kind of range is intended  , this technique can be used e.g. The earlier can be used to capture more information pertaining to the creation of a particular statistical item; – Defining sub-properties of using SCOVO-min and max.This model is easily extensible by defining new factors and agents pertaining to the actual statistical data. Dimensions of a statistical item are factors of the corresponding events  , attached through the dimension property  , pointing to an instance of the SCOVO Dimension class.In this paper we have analyzed the events happening on GitHub  , the most popular repository for open source code  , for 18 months between March 11  , 2012 and September 11  , 2013. We think that this might represent a starting point for the development of novel strategies and tools for supporting online collaboration more effectively and efficiently.These  , for instance  , are an indicator for available source code. Segments in curly brackets denote whole URLs that match predefined URL patterns   , such as GitHub URLs as denoted by {github}.The online version of GERBIL can be accessed at http://gerbil.aksw.org/gerbil. More information can be found at our project webpage http:// gerbil.aksw.org and at the code repository page https: //github.com/AKSW/gerbil.Thereafter  , we present the GERBIL framework. We begin by giving an overview of related work.Moreover   , partial results are not considered within the evaluation. To address this problem  , we aim to develop/implement novel measures into GERBIL that make use of scores e.g.  , Mean Reciprocal Rank.Datasets. Table 2shows the most prominent words for each of the chosen topics from the Quora topic model.We have not addressed the possibility that the user's subject context is excluded from the display. The two methods described in this section focus the user's display on their current context e.g.  , mediaeval history.The full set of queries is available in the Github repository  , and additional information about the experiments can be found there as well 6 . We have taken the SRBench queries and adapted them according to our extended ontology.Previous qualitative research on GitHub by Dabbish et al. We use GitHub as an example of a new class of transparent software environments that incorporate social media features to make work more visible.Explicit uncertainty information can  , of course  , be used for other purposes — for example  , to provide for the user a confidence level for each document in the ranking. However  , we have found little evidence  , at least for the LETOR OHSUMED data set  , that explicit use of the uncertainty information can improve model performance in terms of NDCG.The query translation types supported by Morph are the na¨ıvena¨ıve translation queries C  , which are the result of the query rewriting algorithm described in Section 3  , together with three variants of it; with subquery elimination SQE  , self-join elimination SJE  , and both types of eliminations SQE+SJE. Our query translation algorithm has been implemented in our latest version of Morph  , which is available as a Java/Scala opensource project in Github 9 .Overall  , our approach attains the best averaged F1 value of all systems. The corresponding GERBIL result sheet is available on the GERBIL website 4 and can be used to make comparisons to our approach in future evaluations.To enable this comparison  , we selected 30K Pinterest users uniformly at random from our original sample of 2 million Pinterest users. The purpose of this comparison is to quantify any bias in our target population.As stated before  , Pinterest is all about pins  , thus our first analysis focuses on the activity of the users. We calculate the complementary cumulative distribution function CCDF of boards and pins per user by gender Figure 2 and report that  , although the distribution of boards does not vary greatly by gender  , females tend to catalog relatively more pins thus being more active in the network.Figure 6compares the CDF of the age of the accounts on Pinterest for identities that are curated using intra-domain reputation signals  , and the additionally curated identities. To understand what kind of identities benefit the most from inter-domain reputation signals  , we study the properties of identities that do not get curated using only intra-domain reputation signals  , but that get curated using both intra-domain and inter-domain reputation signals – we call these identities the additionally curated identities.Not all nodes in this Semantic Web graph are entities; identifying the nodes which refer to an entity is one of the challenges introduced by the task. We use the Billion Triple Challenge BTC collection 3   , a publicly available Semantic Web crawl; we consider this collection as a reasonable sample of Linked Open Data LOD.Pins are 'pinned' onto a so-called 'pinboard' which is intended to be a thematic Figure 1: Social network is not critical for information seeking on Pinterest: a The source of pins in our dataset. The user who introduces an image into Pinterest is called its pinner; others who re-appropriate it for their own pinboards are repinners.Controls for changes in developer experience with time  , that may have affected individual productivity. To ensure compliance with lmer's modeling assumptions  , we also checked the QQ-plot for our model  , which showed good match with a normal of the current week  , relative to one's first ever recorded GitHub contribution .Following LETOR convention  , each dataset is divided into 5 folds with a 3:1:1 ratio for training  , validation  , and test set. 16  , here we investigate whether a simple unweighted average is sufficient to give improve- ments.Informed by previous work  , we generate hypotheses to test in our analysis of contributions in GitHub. We also examine new software development environments that make use of transparency and social media features  , which sheds light on the kinds of signals that are visible and the inferences developers make.Note that our definition of project as a collection of repositories owned by the same GitHub user is broader than the definition of project as a main repository together with all its forks  , proposed in the literature 25. The resulting aggregation of this data  , using our conceptualization of a project  , depicted in the right part of Figure 1  , shows contributions to only 4 projects.It is arguably less costly to switch between such related repositories in terms of context switches than other  , less related repositories on GitHub. 1 Such repositories are conceptually and technically related  , or even interde- pendent 7.JavaScript has been the lingua franca of client-side web development for some years. JavaScript has been selected as the most popular programming language for three consecutive years 42 and it is the most used language on GitHub 23.the LETOR benchmark 5 requires only one parameter c as input. Since higher NDCG values are obtained when the most relevant results are ranked on the top followed by the less relevant and the irrelevant ones  , the above observation enforces our claim that our method favors the most relevant results of each query.Our approach can be plugged on top of any LOD search engine currently using Sindice search API. Using the input queries  , the WoD is searched.Community question and answer sites provide a unique and invaluable service to its users. As Quora and its repository of data continues to grow in size and mature  , our results suggest that these unique features will help Quora users continue find valuable and relevant content.the number of query topics  , on ranking performance by conducting comparison study with varying the value of n. Figure 3show the performance of TRSVM on Letor dataset with varying values of n in terms of MAP. In this experiment  , we explore the effects of different settings of the parameter n  , i.e.From an initial 1  , 800 projects  , we eliminated aggregate projects  , and projects without test suites  , which left us with 796 projects. We chose a large random sample of Java projects from Github 22 9 and the Apache Software Foundation 6 that use the popular Maven 7 build system.These are augmented by a set of features drawn from the Pinner who published the image  , as various characteristics of the original Pinner  , such as her " taste " of images  , and how influential a user she is on Pinterest  , may affect repinnability of the image. The pin p is described by the set of image features I in Table 1  , which may be attributed to the content of the pinned image.To address these challenges  , we built a distributed crawler that collected pins from the selected users every day. The second challenge occurs because Pinterest does not have a public API for gathering pins with timestamps in bulk.After receiving results  , our system augments the results with UMBEL categorizations  , which can be performed offline or dynamically 9. Our approach can be plugged on top of any LOD search engine currently using Sindice search API.In the following  , we present current state-of-the-art approaches both available or unavailable in GERBIL. Currently  , GERBIL offers 9 entity annotation systems with a variety of features  , capabilities and experiments.In Section 7.2 we discuss our results in contrast to other works that are not publicly available. In Section 7.1 we directly compare the approaches on the basis of its results achieved with GERBIL.For this  , we consider the task of curating identities in the target domain Pinterest. The goal of this section is to show the benefits of inter-domain trust transfer in a practical scenario.Identities with black-market association: In this dataset  , we collect information about identities associated with a black-market service. 11 Out of the 1.7M Pinterest identities  , we found that 74 ,549 have been suspended.Datasets: CIFAR-10 3 and Tiny 100K image 8 datasets both encoded with GIST features. Finally  , we then find the optimal value for the flexibility of margin C ∈ {0.01  , 0.1  , 1.0  , 10  , 100}.A core function of interest-based and content-driven sites such as Pinterest is to enable users to find the information that suits their interests. But the difference between the two proportions is reduced as users become more experienced in the plat- formFuture research may investigate how developers use signals in other work environments  , transparent or not. Our findings inform how software developers and project managers make use of information in social work environments such as GitHub and imply a variety of ways that social features in work environments can support software development.This is because the LETOR data set offers results of linear RankSVM. For all the SVM models in the experiment  , we employ the linear SVM.Each thread in our corpus contains at least two posts and on average each thread consists of 4.46 posts. From the TripAdvisor data  , we randomly sampled 650 threads.With the advent of social coding tools like GitHub  , this has intensified. In open-source software  , developers also commonly contribute to multiple projects in the same time period  , bridging different communities 20  , 30.Given the finding that social links are not critical for identifying pins  , the most critical activity on Pinterest  , it is puzzling that its social network is counted amongst the fastest growing across all platforms 2 . We find evidence the Pinterest social network is useful for bonding and interaction.We treat BeerAdvocate as a 'development domain'  , because we used it for developing the models and experimental setting  , and RateBeer as a 'test domain' in which we validate our final models on previously unseen data. Each split used 70% of the data for training and 30% for testing.In this section  , we present a thorough analysis of the Pinterest users description by gender related to the context. 2007; Veltman 2006 .Recently  , an approximate index structure for summarizing the content of Linked Data sources has been proposed by Harth et al. Swoogle 8  , Sindice 23 and Watson 7  among the most successful.Figure 5and Figure 6show the results on the Letor TD2003 and TD2004 datasets. We tried treating 'partially relevant' as 'irrelevant'  , it did not work well for SVM map .the entire WT2g Dataset  , both for inLinks and outLinks. Using recently acquired hardware we have reduced this time to below 2 seconds per query.The similar shapes for training and validation suggest that we are not overfitting. Secondly these all peak at or close to an α of 0  , indicating that  , for LETOR OHSUMED at least  , we don't get any benefit from explicit use of the model's uncertainty information .14 The code used to create the LOTUS index is also publicly available. Code of the API functions and data from our experiments can be found on github.For open questions with no answer   , we infer the question posting time based on the latest activity timestamp on the question page. Since Quora does not show when a question is posted  , we estimate the posting time by the timestamp of its earliest answer.Each performance value on test sets shown in the figures is averaged using five-fold cross validation as the same way used in LETOR. By varying β from 0 to 1 with a step of 0.05  , the curves of the ranking performance of FocusedRank in terms of κ-NDCG 4 and κ-ERR are shown in Figure 1and Figure 2.Any Github user can participate in the discussion of any pull request. Projects that employ code reviews feature larger code bases and bigger team sizes than those that do not.For this dataset  , we also gathered information about each unique GitHub user associated with the set of pull requests. In total  , this includes 659 ,501 pull requests across the 12 ,482 projects.Because of this convenience and extensibility  , we have also recently launched Coagmento 2.0 on GitHub as an open source tool 4 . Any computer with PHP  , Laravel  , Node.js and a SQL database could be a Coagmento 2.0 server.We estimate the total number of questions in Quora for each month by looking at the largest qid of questions posted in that month. Since reading the question does not update this " latest activity " timestamp  , this timestamp can estimate posting time for unanswered questions.Automatic knowledge base population by extracting entity information from large-scale unstructured text data has been shown to be a very challenging task in the recent TAC KBP program 1 . A knowledge base is a centralized repository for information .Researchers can install PHP  , Laravel  , Node.js  , and a SQL framework and download the GitHub repository to get started with their instance of Coagmento. Because of this convenience and extensibility  , we have also recently launched Coagmento 2.0 on GitHub as an open source tool 4 .Dabbish et.al 10  found that Github's transparency helps developers manage their projects  , handle dependencies more effectively  , reduce communication needs  , and decide what requires their attention . Recently  , Github has been the target of numerous publications.From Figure 1b and Figure 2 b  , we actually cannot find evidences that social friend information is correlated with user interest similarity. Secondly  , in the Douban friend community  , we obtain totally different trends.This knowledge might prove its potential in a task such as linking user-generated data e.g.  , Pinterest pins to online webshops 7. Given such collection  , the goal is to find how these two language idioms colloquial vs. formal relate to each other.After deduplication   , there are about 886 million triples  , 175 million resources  , and 296 million literals. The dataset is the Billion Triple Challenge 2009 collection.6fshows that this result extends to measures of influence on Pinterest. Fig.Instead  , we assume that identities with higher fractions of blocked pins are more likely to be untrustworthy. We assume that a vast majority of the random Pinterest identities are indeed trustworthy  , and hence  , we do not consider all identities that posted a single blocked pin to be untrustworthy.We compare the NDCG-Annealing algorithm with linear ranking function described in section 3 with baselines provided in the LETOR 3.0 datasets. The NDCG-Annealing algorithm is general to be applied to both linear and non-linear ranking functions at test time.For example  , it takes two days for EM to finish for the RateBeer dataset  , whereas our method takes just two minutes. EM takes more than 1 ,000 times as long to execute.This setting is employed to fairly compare the method SRimp with SRexp. Suppose that user ui has n explicit social connections in the Douban dataset  , then we will choose the most similar n users as the implicit social connections in this method.To avoid the aforementioned implication  , these extra documents with low BM25 scores were dropped in the latest LETOR release 13. This is a highly counterintuitive outcome.To facilitate the development and advancement of video hyperlinking systems  , video hyperlinking has become a competition task since 2012 in MediaEval 6. Therefore  , video hyperlinking enables users to navigate between video segments in a large video collection 3.We focus on a popular black-market site called addmefast.com. There are multiple black-market sites where Pinterest repins or likes can be fraudulently obtained 6  , 7  , 8.Finally we also employ the OKKAM service. If the resource descriptions includes OWL inverse functional properties IFPs from a hardcoded list e.g.  , foaf:mbox and foaf:homepage  , then a Sindice index search for other resources having the same IFP value is performed.Figure 6also shows that to curate identities using Pinterest reputation signals alone  , we have to wait at least 15 months  , but by exploiting inter-domain reputation signals  , we can curate identities more than 10 months in advance. 13 The plot shows that the additionally curated identities are young identities that have probably not had time to gain sufficient reputation on Pinterest  , confirming our expecta- tions.We found that contributors have a strong interest in staying aware of project status to get inspiration and to avoid duplicating work  , but they do not actively try to propagate information about the pull requests they are preparing. Since GitHub hosts diverse projects developed by many different programmers  , it gives us the opportunity to learn from a variety of cases.Table 1shows the statistics of the datasets included in the LETOR 3.0 benchmark. For these datasets  , there are 64 features extracted for each query-document pair and a binary relevance judgment for each pair is provided.In total we have 107 ,372 untrustworthy identities the negative examples and slightly less than 1.6 million Pinterest identities that are not untrustworthy the positive examples. For identities that post malicious pins  , we consider the top 17 ,000 which corresponds to the 1% most untrustworthy Pinterest identities identities to be untrustworthy  , as ranked by their fraction of malicious pins.In this section  , we analyze the Quora social graph to understand the interplay between user social ties and Q&A activities. Therefore  , social relationships clearly affect Q&A activities  , and serve as a mechanism to lead users to valuable information.For all these reasons  , GitHub has successfully lowered the barrier to collaboration in open source. In fact  , GitHub is not simply offering a code hosting service  , like its competitors had been doing for a long time  , but also an easy-to-use and cheap or even free in its basic version online tool for collaborative software development and many features supporting the community of developers.The second data set further referred to as Hotel consists of reviews of hotels crawled from TripAdvisor 5 along with the meta-data of review authors   , such as location  , gender and age 6 . This first data set further referred to as Auto consists of reviews crawled from FordForum.com 4   , a public automobile on-line review website  , which provides the meta-data of review authors  , such as location  , gender and occupation in this work  , we are only interested in location and gender.Quora makes visible the list of upvoters  , but hides downvoters. In terms of votes  , both Quora and Stack Overflow allow users to upvote and downvote answers.Moreover  , all developers reported they felt comfortable—4 points on average on a 5-point Likert scale between very uncomfortable 1 and very comfortable 5—implementing the annotator in GERBIL. This result in itself is of high practical significance as it means that by using GERBIL  , developers can evaluate on currently 11 datasets using the same effort they needed for 1  , which is a gain of more than 1100%.It should be noted that for different classes of requests  , an application may deploy different termination ranges and control parameters and our API design can support such differentiation. Our experiments with two applications from Ask.com indicate the proposed techniques can effectively reduce response time and improve throughput in overloaded situations.However  , IMRank1 runs more than two orders of magnitude faster than PMIA and more than one order of magnitude faster than IRIE. On the DOUBAN network  , the four algorithms achieve comparable influence spread.It is possible to express SCOVO in OWL-DL  , if advanced reasoning is of necessity. 2  is currently defined in RDF- Schema.In our study  , we use more than 15M reviews from more than 3.5M users spanning three prominent travel sites  , Tripadvisor   , Hotels.com  , Booking.com spanning five years for each site. We provide True- View as a proof of concept that a cross-site analysis can significantly improve the information that the user sees.To obtain references to the roots of the static view entities  , the GHTorrent project follows the event stream. The Github API data come in two forms; a streaming data flow lists events  , such as forking or creating pull requests  , happening on repositories in real time  , while a static view contains the current state of entities.Table 2summarizes the total performance of BCDRW and BASIC methods in terms of precision and coverage on the aforementioned DouBan data set. The impact of using different values of α  , β and N is further studied in the second set of experiments reported in Section 4.3.2.However  , we have found little evidence  , at least for the LETOR OHSUMED data set  , that explicit use of the uncertainty information can improve model performance in terms of NDCG. The ability of our models to take into account different levels of uncertainty for different data produces effective models  , and  , for FITC-Rank in particular  , performance is consistent across experiments and gives significant improvements against the baseline models.We manually checked these users and found that they were legitimate accounts  , and come from various backgrounds such as CEOs  , cofounders   , bloggers  , students  , and were all very active Quora users. Finally  , a very small portion of users 27 or 0.01% followed more than 1000 topics.Nick Craswell developed software for extracting hyper-link connectivity information from WT2g. It is not known at this stage  , what proportion of the dead links those whose target lies outside WT2g are inter-server links and how many are references to same-server pages which happen to be missing from the VLC2 1 .Sindice is a offers a platform to index  , search and query documents with semantic markup in the web. Sig.ma20 is an entity search tool that uses Sindice11 to extract all related facts for a given entity.Some prolific developers are even considered "coding rockstars" by the overall community 5. Members of the GitHub community regard certain members as being at a higher standing.1 In both communities users provide ratings accompanied by short textual reviews of more than 60 ,000 different types of beer. For the purpose of this study we will employ data from two large beer review communities BeerAdvocate and RateBeer.The user-related and item-related contexts are the same with those used in Douban book data. 3 Douban music data 16  , which records 1 ,387 ,216 ratings from 29 ,287 users on 257 ,288 music items.In terms of votes  , both Quora and Stack Overflow allow users to upvote and downvote answers. We use this as a minimum threshold for our later analyses on social factors on system performance.We have obtained information about 2.19 million users and 5.68 million repositories. In this paper we have analyzed the events happening on GitHub  , the most popular repository for open source code  , for 18 months between March 11  , 2012 and September 11  , 2013.SRexp: this is the social regularization method described in Equation 3  , which utilizes the explicit social information in improving recommender systems. We compare the following three methods using Douban datasets: 1.We have shown very competitive results relative to the LETOR-provided baseline models. We have described an experimental method in which learnt uncertainty information can be used to guide design choices to avoid overfitting  , and have run a series of experiments on the benchmark LETOR OHSUMED data set for both types of model.The naive approach would be to consider each GitHub repository as its own separate project. Since our analysis focuses on multitasking across projects  , we need to conceptualize how we define the boundaries of a software project.To illustrate the effects of some of these design considerations figure 1shows three precision curves obtained using the WT2g collection and short queries. To be more concrete  , we present next some of the precision vs. pruning results using standard MAP and P@10 measures.We report on instrumentation overhead and on the number of times that the same crash needs to be encountered to recover the complete crash path. We implemented the technique using Jalangi 28  , and evaluated it on crashing executions of JavaScript applications available from GitHub.1 Such repositories are conceptually and technically related  , or even interde- pendent 7. However  , we observed that in some cases  , software projects are organized into multiple separate repositories on GitHub.Figure 3shows that around 46% of all articles have been shared on two platforms. Pinterest and the Q&A sites have the lowest levels of coverage and usage.At the end of 2012  , GitHub hosted over 4.6M repositories. Over the last couple of years GitHub 4   , which is the most popular repository hosting service for Git projects  , has taken the open source community by storm 19.11 Out of the 1.7M Pinterest identities  , we found that 74 ,549 have been suspended. We use this signal to identify suspended identities on Pinterest.Consequently  , curation on Pinterest remains a highly manual process as well. Similarly  , users' pinboards are highly personal and idiosyncratic represntations of their taste  , and furthermore   , users are free to choose to repin any image onto any pinboard .We expect the pairwise methods to perform better than point-wise approaches  , as the features collected from the error pairs are more meaningful as they define relative distances. We have tried using Support Vector Regression RankSVM with linear kernel for pairwise LETOR  , and were trained on a set of error pairs collected using the " web2013 " relevance judgments file.The method of choosing the WT2g subset collection was entirely heuristic. The second and third requirements ruled out a uniform 2 % sample.However  , in the environment of GitHub  , which is both transparent and equipped with social media functionality  , we also expect contributors to make use of the social connections that the environment makes salient. From conventional wisdom on open source software projects  , we expect to see some evidence for a "meritocracy"  , in that technical contribution norms should reign over other signals when considering contributions 26.Consider an image which has been introduced into Pinterest by an original pinner. Our goal is to make it easier to re-appropriate and re-categorise content for personal use.The CDX files required by ArchiveSpark were generated using the Internet Archive's CDX Generator  , which is available open source on GitHub 15 . HBase: Using Warcbase's ingestion tool For both ArchiveSpark and pure Spark approach  , WARC files from the collection were stored in Hadoop HDFS.While manually detecting irregularities for this data might be difficult  , examining the distribution of the pt values cf. 4 In Figure 7 we have already illustrated the distribution of ratings over time for the hotel Punta Cana Princess evaluated on TripAdvisor.These systems return flat lists of ontologies where ontologies are treated as if they were independent from each other while  , in reality  , they are implicitly related. Our view is that one of the issues hampering efficient ontology search is that the results generated by SWSEs  , such as Watson http://watson.kmi.open.ac.uk  , Swoogle http://swoogle.umbc.edu or Sindice http://sindice.com  , are not structured appropriately.We further refined the selection using the GitHub API to retrieve more detailed information about each repository with the following criteria: This selection included 185 ,342 repositories.Pull requests are enabled by default on all repositories opened on Github; however  , not all projects are using them to collaborate. In the GHTorrent dataset  , less than half 1 ,877 ,660 or 45% of the active repositories are original repositories.As we described in §2 and §3.1.3  , we can use a binary classifier to compute the probability of Pinterest identities to misbehave in the future. We compute the probability of Pinterest identities to misbehave in the future in two ways: first  , we only use intra-domain reputation signals  , and then we use both intra-domain and inter-domain reputation signals.In addition to the web and other blogs  , blog users typically interact on other electronic networks  , such as Instant Messenger IM and email. f Xanga web-link categoriesPinterest Figure 2: The fraction of topical followers to the total number of followers for the set of basketball players that were selected in the example of Fig. They proposed several features based on users contributions and graph influence.The results on seven datasets in LETOR 3.0 show that the NDCG-Annealing algorithm can outperform the baselines and it is more stable. We compare the NDCG-Annealing algorithm with linear ranking function described in section 3 with baselines provided in the LETOR 3.0 datasets.The first evaluation  , based on the LETOR datasets 17  , uses manual relevance assessments as ground-truth labels and synthetic clicks as feedback to BARACO. in two different ways.After eliminating projects aggregating multiple projects which are difficult to properly analyze  , a set of 1 ,254 projects remained. The process used by Github to select projects is not public  , but we believe it is orthogonal to our concerns  , and likely based on popularity and recency.We took SPARQL Endpoints from the SPARQLES survey 3  , vocabularies from Linked Open Vocabularies LOV 2 and prefix.cc  , and we augmented these data with spidered data from the Billion Triple Challenge BTC 2014 13 dataset. We made several approaches to ensure that we visited a large and representative section of the open Semantic Web.We have implemented most of our ranking algorithms implemented using Lucene. Our goal is set to design a system as simple as possible  , without using any external processing engine or resources  , other than the standard Indri toolkit and a third party LETOR toolkit.Figure 1shows a typical user profile on Pinterest. Personal profiles on Pinterest include a profile image  , a brief self-description  , and lists of the user's boards  , pins  , likes  , followers  , and friends i.e.  , those who the user follows.Note that streams for synthetic data differs from NASDAQ data in terms of the lag and the missing update distributions. The stream generation process is as follows: A stream would pick elements of the Z vector sequentially and could perform the following three operations: a Simulate missing update: Ignore the picked element and move to the next element with Bernouilli probability = pmiss k   , b Simulate independent error: Add Gaussian noise with precision β k > 1  , c Simulate Lag: Publish the noisy update after lag governed by Uniform distribution in the range 1 − 10.To answer these research questions  , we conduct an empirical investigation consisting of four separate studies. In Study 3 S3  , we analyze 100 randomly selected public GitHub repositories that use Java'sHowever  , LOTUS differs from these previous approaches in three ways: 1 its scale its index is about 100 times bigger than Sindice's was  , 2 the adaptability of its algorithms and data collection  , and 3 its integration with a novel Linked Data publishing and consumption ecosystem that does not depend on IRI dereferenceability. Centralized text search on the LOD Cloud is not new as Sindice 3 and LOD Cache 4 show.However  , any publishsubscribe system implementing the optimal centralized algorithm in XPath query processing 18 would require a single depth-first traversal of the document tree visiting  , in our example  , twice the nasdaq server. Publish-subscribe systems are more in-line with moving the processing to the data.LQ12 designed a spider framework to crawl websites from tripadvisor  , in order to collect candidate pages related to attractions  , restaurants etc. The similarities are computed based on the either the category or description of the suggestions.The six evaluation measures offered by GERBIL as well as the error count are expressed as qb:Measures. Each observation features the qb:Dimensions experiment type  , matching type  , annotator   , corpus  , and time.Unlike traditional social bookmarking  , pinning on Pinterest does not involve creating an explicit vocabulary of tags to describe the image. Towards this end  , we revisit the notion of agreement in the context of Pinterest.Quora is unique because it integrates an effective social network shown above into a tradition Q&A site. But neither channel appears to be the primary way of attracting answers  , and both channels appear to complement each other in this process.However  , in such a process  , many misleading words may also be extracted. One option is to extract all lexical information from the URI  , labels  , properties and property values of the LOD resources that are retrieved by Sindice search.Textual memes. Overall  , we consider 1 ,084 ,816 reviews from 4 ,432 users in BeerAdvocate  , and 2 ,016 ,861 reviews from 4 ,584 users in RateBeer.To do this the pipe needs to execute a Sindice 19 query which will return a set of documents likely containing the description of messages left by the user on possibly multiple Web sites. Case 3: SIOC Aggregation RSS feed Given a SHA1 a user's email  , the output is a list of messages that the user left on the internet in sites that expose SIOC 8 data.Table 2 shows the statistics of our test corpora. All data sets are integrated in GERBIL and strongly differ in document length and amount of entities per docu- ment.GER- BIL will regularly check whether new corpora are available and publish them for benchmarking after a manual quality assurance cycle which ensures their usability for the implemented configuration options. However  , GERBIL is currently only importing already available datasets.We highlight our contributions and key results below. In our study  , we use more than 15M reviews from more than 3.5M users spanning three prominent travel sites  , Tripadvisor   , Hotels.com  , Booking.com spanning five years for each site.The out-links file consisted of  , for each document d  , the document numbers of the documents d links to. Accordingly  , the connectivity data was also distributed by ftp in a highly compressed format based on WT2g document numbers.To create the seed set for Xanga we took advantage of the concept of " metros " : each metro corresponds to a geographical region in which users locate themselves. Xanga.The source tree ST is the only structure that our XPath evaluation and incremental maintenance algorithms require. From the source tree we can see that both fragments F2 and F3 are stored in the same site S2  , the nasdaq site.In question-answering sites  , e.g.  , Quora and Stack Overflow  , an important task is to route a newly posted question to the 'right' user with appropriate expertise and several methods based on link analysis have been proposed 45  , 6  , 46. The factorization technique can be naturally extended by adding biases  , temporal dynamics and varying confidence levels.The experimental results provided in the LETOR collection also confirm this. Note that it is commonly believed that Rank-Boost performs equally well as Ranking SVM.In most cases  , significant increases in effectiveness are found for other popular projection functions including SH and SKLSH across both datasets Tables 1-2. We find that the superior retrieval effectiveness of GRH+NPQ is maintained when the hashcode length is varied between 16-128 bits for both LSH and PCA projections Figure 3a-b on CIFAR-10.Code is another prominent example of revisioned content  , and one that is becoming common on the web  , thanks to the success of sites like GitHub  , where users can share their code repositories. present  , but not directly exposed to the viewer.We selected our subject programs based on issues reported on GitHub. These more complex scenarios might require longer crash paths and make Crowdie more expensive to use  , but extra complexity will also make the partial instrumentation of Crowdie even more tractable compared to naive full instrumentation.The basic units of data on Pinterest are the images and videos users pin to their boards. Pinterest pre-defines 33 categories  , varying from " Women's Fashion " and " Hair Beauty " to " Geek " and " Tattoos " .It crawls the web continuously to index new documents and update the indexed ones. Sindice is a offers a platform to index  , search and query documents with semantic markup in the web.With LETOR data  , since HP and NP are similar tasks but TD is rather different  , we conducted experiments on HP03- to-NP04 and NP03-to-TD04 adaptation  , where the former setting is for adapting to a similar domain and the latter for adapting to a distinct one. The free parameters λs and λt were set such that λs λt is inversely proportional to |Ds| |Dt|This is most common on Xanga which has the youngest users. In summary  , our experiments show a surprising willingness of users to make their private contact information available.They found that integrators are most concerned with quality and prioritization. They conducted a tworound survey with 21 and 749 GitHub integrators on what factors they consider in their decision making process to accept or reject a pull request.4 The Organic Data Science Framework can be set up for different communities. The Organic Data Science Framework software is open source and is released on GitHub under an Apache 2.0 license.Only 24 3% respondents added information using the 'other' field  , mostly providing clarifications. To ask respondents about their work habits before coding  , we provided them with a set of 7 questions based on our analysis of the literature and our vast GitHub experience with a 4-level Likert scale.ICWSM'2007 Boulder  , Colorado  , USA No one on Xanga mentioned Al-Qaeda.To adhere to ethical standards concerning incorporation of user data into research  , we decided to only use data that is publicly available – either as online profiles Quora  , Health Q&A  , or as datasets used in numerous other studies AOL. As a first data source  , we used the AOL query log collected between March  Ethics.Thus  , these results indicate that training over a collection of given characteristics cannot always lead to an effective ranking function when the function is deployed to rank documents in a collection of radically different characteristics. The retrieval performance achieved was at least as good as the LETOR 4.0 baselines.can be reconstructed in a unique manner in future works. Hence  , by using GERBIL for experiments  , tool developers can ensure that the settings for their experiments measures  , datasets  , versions of the reference frameworks  , etc.Table 1summarizes the statistics of this dataset  , where Words per review represents the text length of a review and Distinct Words per review represents the number of distinct word units that occur in a review. Because only the most popular tags are listed for the books in DouBan  , we obtained merely 135 distinct tags.The CIFAR-10 dataset 11 consists of 60 ,000 color images drawn from the 80M tiny image collection 29. We evaluate our method on two standard large image datasets with semantic labels: CIFAR-10 11  and NUS- WIDE 3.New LOD resources are incrementally categorized and indexed at the server-side for a scalable performance 9. For example  , using a crawler and Sindice  , LOD resources can be categorized offline by the proposed fuzzy retrieval model 8  , or other clustering methods also UMBEL linked data mappings can be used.This is because for most classes T in the API framework  , GitHub contains many more usage samples than can be extracted from web pages. Structured call sequences are extracted from open-source projects on GitHub.We focus in particular on how annotators and datasets can be added to GERBIL and give a short overview of the annotators and tools that are currently included in the framework. Thereafter  , we present the GERBIL framework.For example  , users with lots of followers were treated as local celebrities. The number of followers a GitHub user possesses is used as a signal of standing 5 within the community.The y-axis of the Pinterest scatter plot captures the cosine similarity between each user's Pinterest LIWC-vector and the network LIWC-vector for Pinterest. We refer to this as the " Identity " axis.In the figure  , we plotted the results for an exemplary hotel from the TripAdvisor database. In Figure 4  , we analyze the effect of a varying λ on the runtime.Identities with pins that are blocked: Each pin on Pinterest has an associated URL that redirects the user to the page hosting the image. We gathered 1 ,706 such untrustworthy identities.The Pinterest website is a complex Javascript application  , so we leveraged PhantomJS to crawl the site. To address these challenges  , we built a distributed crawler that collected pins from the selected users every day.We never attempted to identify the individuals whose profiles we analyzed. To adhere to ethical standards concerning incorporation of user data into research  , we decided to only use data that is publicly available – either as online profiles Quora  , Health Q&A  , or as datasets used in numerous other studies AOL.The Billion Triple Challenge 1 is a collection of crawled Linked Data that is publicly available and that is often used in Big Data research. Large Linked Datasets.8 we observe that the results share the similar trends with Douban data based experiments. From Fig.However  , GERBIL is currently only importing already available datasets. 28 The extensibility of the datasets in GERBIL is furthermore ensured by allowing users to upload or use already available NIF datasets from DataHub.The ability of our models to take into account different levels of uncertainty for different data produces effective models  , and  , for FITC-Rank in particular  , performance is consistent across experiments and gives significant improvements against the baseline models. We have shown very competitive results relative to the LETOR-provided baseline models.Letor OHSUMED dataset consists of articles from medical journals . In the first experiment  , we used the Letor benchmark datasets 18: OHSUMED  , TD2003  , and TD2004.Thus  , using inter-domain reputation signals allows us to curate more identities and enables us to do it faster. Figure 6also shows that to curate identities using Pinterest reputation signals alone  , we have to wait at least 15 months  , but by exploiting inter-domain reputation signals  , we can curate identities more than 10 months in advance.Since the growth of documents in Sindice was closely related to upgrades in their technical infrastructure in the past  , we cannot reliably use their growth rate. It stores 37.72 million documents  , which accounts for slightly more than 0.1% of all WWW documents .The dataset as well as custom-built Ruby and R analysis tools are available on the Github repository gousiosg/pullreqs  , along with instructions on how to use them. Last but not least  , our dataset provides a rich body of information on open source software development.Our study necessitates highresolution timestamps  , thus we need to crawl pins while the timestamps are displayed in hours. The 24-hour requirement stems from the fact that Pinterest displays relative timestamps with decreasing resolution  , i.e.  , a pin from an hour ago will display " posted 1 hour ago  , " whereas a pin from yesterday will display " posted 1 day ago. "Aggregated Search of Data and Services12 proposes to answer an SQL-like data query on XML datasets and RDBMS and propose relevant services to the latter. Both Sig.ma and Sindice are document-based and don't offer SWS discovery features or search for data using SWS.For larger distances  , the distribution increases again  , showing a big presence of intercontinental links. The sudden drop at x = 5000 km is due to the ocean separating North America and Europe  , that are the two regions where GitHub is mostly popular.Hence  , Douban is an ideal source for our research on measuring the correlations between social friend and user interest similarity. This means that most of the friends on Douban actually know each other offline.Features in Letor OHSUMED dataset consists of 'low-level' features and 'high-level' features. In Letor  , the data is represented as feature vectors and their corresponding relevance labels .We can report that the SWSE Semantic Web Search Engine 4 will also soon be serving data obtained thanks to dumps downloaded using this extension. At consumer level and as discussed earlier  , the Sindice Semantic Web indexing engine adopts the protocol 3 and thanks to it has indexed  , as today  , more than 26 million RDF documents.For example  , most of the 10 news sites  , which are used for the current GeoTopics  , have sidebars and footers in their articles  , which cause falsematching problems e.g.  , 'NASDAQ' was ranked high because it is appeared on the side bars in many of the news articles. Although the high-level processing steps are the same extracting articles  , filtering and classifying them  , and generating the HTML report  , the selection and coordination of the information management services need to be flexible and reconfigurable to handle dynamic situations.The corresponding GERBIL result sheet is available on the GERBIL website 4 and can be used to make comparisons to our approach in future evaluations. Table 3 shows the F1 values in comparison to the competitor systems on all data sets.Currently  , GERBIL offers 9 entity annotation systems with a variety of features  , capabilities and experiments. Furthermore  , we were not able to find a running webservice or source code for this approach.Our LETOR algorithms behave differently on some topics  , but Condorcet method tends to ignore high votes from the minority  , but instead prefer weak votes from the majority. This observation is similar to that in 22  , and it is likely to be the case that false positives that are common in all 4 posting lists will likely to receive higher ranking than true positives that are supported by a subset of posting lists.At consumer level and as discussed earlier  , the Sindice Semantic Web indexing engine adopts the protocol 3 and thanks to it has indexed  , as today  , more than 26 million RDF documents. Most large datasets provide a Semantic Sitemap and in general we report that data producers have been very keen to add one when requested given the very low overhead and the perceived lack of negative conse- quences.In other words  , Pinterest users can be seen as performing a massive distributed human computation  , categorising images found on the Web onto an extremely coarse-grained global taxonomy of 32 categories. Thus  , even though each pinboard may be exclusive to a user  , the act of pinning implicitly categorises the image.From the source data  , we generated two datasets for question identification. 1 We obtained 1 ,212 ,153 threads from TripAdvisor forum 6 ; 2 We obtained 86 ,772 threads from LonelyPlanet forum 7 ; 3 We obtained 25 ,298 threads from BootsnAll Network 8 .Without existing benchmark dataset  , we used Review Spider to collect reviews from a Chinese website DouBan to form our experiment dataset. Then we only need to invert the matrix once in the first iteration  , but not in subsequent iterations.Each Quora user has a profile that displays her bio information  , previous questions and answers  , followed topics  , and social connections followers and followees. In addition  , users can follow topics they are interested in  , and receive updates on questions and answers under this topic.A metro has anywhere from a single user to hundreds of thousands of users listed within it. To create the seed set for Xanga we took advantage of the concept of " metros " : each metro corresponds to a geographical region in which users locate themselves.We find that this lower dimension approximation of Pinterest has several desirable properties: First  , for a given image  , a remarkable ≈75% of repins tend to agree on the majority category  , although the level of agreement varies with the category. In other words  , Pinterest users can be seen as performing a massive distributed human computation  , categorising images found on the Web onto an extremely coarse-grained global taxonomy of 32 categories.It stores 37.72 million documents  , which accounts for slightly more than 0.1% of all WWW documents . The currently most complete index of Semantic Web data is probably Sindice 4 .Answers  , Stack- Overflow or Quora. Crowdsourcing  , where a problem or task is broadcast to a crowd of potential contributors for solution  , is a rapidly growing online phenomenon being used in applications ranging from seeking solutions to challenging projects such as in Innocentive or TopCoder  , all the way to crowdsourced content such as on online Q&A forums like Y!Additionally  , several contributors fear that rejection of their PRs may harm their reputation. Some of our respondents also indicated that contributions to GitHub benefit their career growth e.g.  , " My contribution to projects allowed me to obtain a job within my favorite subjects " r437.Most participants were from North America or Europe. Having targeted only users of GitHub  , this was a surprising result.We use this as a minimum threshold for our later analyses on social factors on system performance. In addition  , 99% of questions end up with less than 10 answers  , and 20% of all Quora questions managed to collect ≥4 answers.Again  , there is a clear relationship between products' overall popularity and the extent to which experts prefer them; non-alcoholic beer is naturally not highly rated on a beer rating website  , while lambics and IPAs are more in favor. The results are highly consistent across BeerAdvocate and RateBeer  , in spite of the differing product categorizations used by the two sites Kvass is a form of low-alcohol beer  , Kristallweizen is a form of wheat beer  , IPA is a form of strong ale  , and Gueuze is a type of lambic.We study the extent to which follow acts are reciprocated and become bidirectional. On some services like Pinterest  , users follow others unilaterally  , creating directional links.Using normalized hyper-parameters described in Section 2.6  , the best hyper-parameters are selected by using the validation set of CIFAR-10. For both CIFAR-10 and NUS-WIDE datasets  , we randomly sample 1 ,000 points as query set  , 1 ,000 points as validation set  , and all the remaining points as training set.Finally  , six applications were collected by searching GitHub for Fortran applications  , then selecting the ones that also contain C. Table 140. Nine applications were collected from a paper on global climate models 23.We also performed test runs that calculated the performance measure Mean Reciprocal Rank MRR in addition to MAP during the " See also " evaluation. The code to calculate MRR is included in the GitHub repository for this paper.We observe an interesting behavior: Starting from very small values of λ  , an increase in λ also increases the runtime. In the figure  , we plotted the results for an exemplary hotel from the TripAdvisor database.The first is to explore the website and follow users they find interesting. Users can create connections to other users on Pinterest in two ways.Pinterest also has many social components: users add boards to subject categories ,'repin' objects from other users to their own boards  , " like " or comment on objects  , and " follow " boards and other user's activity. Images uploaded via the bookmarklet contain a link back to the source website  , but perhaps not to the original  , as images may be used and reused several times on the Web.For example  , contributions that introduced new features were expected to include tests. 23 found in their study of the testing culture in GitHub that project managers would demand that contributions include tests in certain cases.We recruited eight participants from GitHub  , randomly selecting from the 68 ,949 GitHub users who had made at least one contribution in the previous twelve months  , used Java in at least one of their projects  , and had published their email address. Duplicate sentences selected by more than one approach were only shown to participants once.To alleviate this problem  , GERBIL allows adding additional measures to evaluate the results of annotators regarding the heterogeneous landscape of gold standard datasets. At the moment  , those measures ignore NIL annotations   , i.e.  , if a gold standard dataset contains entities that are not contained in the target knowledge base K and an annotator detects the entity and links it to any URI  , emerging novel URI or NIL  , this will always result in a falsepositive evaluation.We noticed that some developers are interested in borrowing emerging technologies e.g.  , GitHub and bringing them to their own working environments. While pull-based development e.g.  , via GitHub is gaining popularity among distributed software development community  , the need to continue studying and supporting the evolution of large long-lived OSS projects remains as important as ever.We conclude with a discussion of the current state of GERBIL and a presentation of future work. We then present an evaluation of the framework that aims to quantify the effort necessary to include novel annotators and datasets to the framework.However  , our sample of programs could be biased by skew in the projects returned by Github. We picked all projects that we could retrieve given the Github API  , and selected from these only based on constraints of building and testing.Subsequently  , we were interested in understanding the challenges that contributors experience when working with the pull-based model in GitHub. This exploration is needed to guide future work in this area and led to our last research question: RQ2: What are the challenges of contributing in social coding sites using the pull-based development model ?However  , the social interaction among Quora users could impact voting in various ways. By positioning good answers at the top of the questions page  , Quora allows users to focus on valuable content.The images are 32 × 32 pixels and we represent them with 512-D GIST descriptors. The CIFAR-10 data set contains 60 ,000 tiny images that have been manually grouped into 10 concepts e.g.  , airplane  , bird  , cat  , deer.As of August 2013  , Github reports more than 7 million repositories and 4 million users. Pull request usage is increasing in absolute numbers  , even though the proportion of repositories using pull requests has decreased slightly.regression trees on large data sets  , since the required tree depth grows with increasing data set size. We observe up to 25 fold speedups in this distributed setting for the Microsoft LETOR data set.Singhal and Kaszkiel 4 looked at average in-and out-links  , within and across hosts  , between the smaller WT2g corpus and their own large crawl. To answer that  , we first need to understand more about what the web looks like.The popularity of GitHub among developers living in the USA is really prominent  , as 3 users out of 10 are based there. 8 GitHub user profiles  , confirm this consideration.Also  , the infrastructure we used for the analysis is available open source as a GitHub repository 5. The list of repositories we used for our analysis is available online 11.NIST assessors referred to the WT2g collection during the process of ad hoc topic generation. Naturally  , there may be considerable variation from one topic to another.Bio2RDF dataset vocabularies and their SIO-mappings are stored in separate OWL ontologies on the bio2rdf-mapping GitHub repository 8 . rdfs:subClassOf  , owl:SubObjectPropertyOf.Conflicts can be resolved by either the contributor or a core team member; however  , pull request etiquette dictates that the contributor takes care of bringing the pull request back into a state where there are no conflicts. Github automatically detects conflicting pull requests and marks them as such.There were two t ypes of content-and-link runs used; a very simple sibling relationship implementation  , and another version that aimed to overcome some of the simpler run's short- comings. Sibling relationships were only identiied if the siblings and the parent that links to them were all present in the WT2G collection.We also perform a dataset analysis and develop a cost model that provide insight into why particular strategies are effective for Web Data. Experiments are performed on Web data taken from the Billion Triple Challenge and the Web Data Commons datasets.Peterson 25  finds that open source software OSS development on Github works mostly similarly to traditional OSS development   , with the exception of faster turnaround times. Dabbish et.al 10  found that Github's transparency helps developers manage their projects  , handle dependencies more effectively  , reduce communication needs  , and decide what requires their attention .The Github API data come in two forms; a streaming data flow lists events  , such as forking or creating pull requests  , happening on repositories in real time  , while a static view contains the current state of entities. We used Github data as provided through our GHTorrent project 16  , an off-line mirror of the data offered through the Github API.While these programs are widely used  , they may not be representative of all programs and likewise the reported bugs that we investigated may not be representative either. We selected our subject programs based on issues reported on GitHub.First 100 elements obtained from three different ranking methods  , tf -idf   , BM 25  , and Rejection are pair-wise compared in Figure 5. Documents in both D1 and D2 Figure 5 are drawn from dataset collection WT2G where |D1| = |D2| = 2500  , |T1| = 50961 and |T2| = 127487.Detailed results are also provided 1112 . Results of the experiments run on the Gerbil platform are shown in Table 2. LETOR: For comparison purposes  , a LETOR-like document selection methodology is also employed. Hedge finds many relevant documents " common " to various retrieval systems   , thus documents likely to contain many of the query words.This is a difficult question to answer  , given Quora's own lack of transparency on its inner workings. So how does Quora succeed in directing the attention of its users to the appropriate content  , either to questions they are uniquely qualified to answer  , or to entertaining or informative answers of interest ?Askers post new questions and assign them to categories selected from a predefined taxonomy  , such as Pets > Dogs in the example shown in Figure 1 . Answers is a question-centric CQA site  , as opposed to more social-centric sites such as Quora.Some of these queries have produced quite impressive results using the WT2g dataset and associated connectivity data. Due to the lack of In addition to topics 401-450  , we have executed a number of manual queries on the software.We proposed two strategies to collect data from About.me. To accurately establish this mapping  , we employ the emerging social services such as About.me 3 and Quora 4   , where they encourage users to explicitly list their multiple social accounts on one profile.The user who introduces an image into Pinterest is called its pinner; others who re-appropriate it for their own pinboards are repinners. Users on Pinterest.com collect so-called pins  , which are images   , together with associated URLs of webpages where they are found.52 % of these links reference another document within WT2g but only 0.12 % reference a different server within WT2g. On average  , each document within the collection includes 9.13 outgoing links.First  , we seek a deeper understanding of multitasking and its effects for software developers active on GitHub. Our study was guided by two research questions.5 on GitHub  , we know that when core members evaluate pull requests  , they look for the inclusion of test cases as a signal of the thoroughness of the contribution. From the prior work of Dabbish et al.Figure5f illustrates that the percentage of users that share any IM contact decreases with age. Thus  , although over a sixth of Xanga users have provided email addresses  , we cannot use it when trying to match users across networks.Further  , our ongoing work focuses on broadening the deployment base available 17   , making converters from and to SCOVO available  , and extending the framework itself. For example  , one part of the UN data set—the Commodity Trade Statistics Database COMTRADE—alone provides commodity trade data for all available countries and areas since 1962  , containing almost 1.1 billion records.We choose the Douban data 8 because it contains not only time/date related and other inferred contextual information  , but also social relationships information  , thus is suitable for evaluating the performance of SoCo  , which utilizes various types of information. Note that we only use explicit ratings  , i.e.  , the " wish " expressions are not considered to be ratings.Threats due to sampling bias: To ensure representativeness of our samples  , we opted to use search results from the Github repository of Java projects that use the Maven build system. While we have used 100 trials each for each observation  , the possibility of bias does exist.Therefore  , we might expect that the ability of social networks to provide access to new informationwould be important on Pinterest. A core function of interest-based and content-driven sites such as Pinterest is to enable users to find the information that suits their interests.We find evidence the Pinterest social network is useful for bonding and interaction. In this section  , we address the issue of which users make social links  , and why it is important .We compute the probability of Pinterest identities to misbehave in the future in two ways: first  , we only use intra-domain reputation signals  , and then we use both intra-domain and inter-domain reputation signals. We then pick the top n trustworthy identities such that the purity remains within a target purity level.Next to individual configurable experiments  , GERBIL offers an overview of recent experiment results belonging to the same experiment and matching type in the form of a Table 5: Results of an example experiment. Offering such detailed and structured experimental results opens new research avenues in terms of tool and dataset diagnostics to increase decision makers' ability to choose the right settings for the right use case.Therefore  , we have adopted Reciprocal Rank as the data fusion techniques in our final submissions. Our LETOR algorithms behave differently on some topics  , but Condorcet method tends to ignore high votes from the minority  , but instead prefer weak votes from the majority.We analyzed development activity and perceptions of prolific GitHub developers. To answer our research questions  , we followed a mixedmethods approach characterized by a sequential explanatory strategy 15.The second challenge occurs because Pinterest does not have a public API for gathering pins with timestamps in bulk. Our study necessitates highresolution timestamps  , thus we need to crawl pins while the timestamps are displayed in hours.Experimental results manifest that RSRank not only achieves good sparsity in practice  , but also exhibits a high level of performance in comparison with several proposed baseline algorithms. Finally  , we evaluate the proposed method on LETOR 3.0 benchmark collections1.While pull-based development e.g.  , via GitHub is gaining popularity among distributed software development community  , the need to continue studying and supporting the evolution of large long-lived OSS projects remains as important as ever. Most recent studies were either conducted at Microsoft 4 or focused on the pull-based development model 12.See Figure 4for an example of the results generated by a query "Vegetable Soup Recipes". Some of these queries have produced quite impressive results using the WT2g dataset and associated connectivity data.The related question graph provides an easy way for users to browse through Quora's repository of questions with similarity as a distance metric. This effectively creates a related question graph  , where nodes represent questions  , and links represent a measure of similarity as determined by Quora.Ranking functions exhibit their second worst performance when trained over data sets constructed according to the LETOR-like document selection methodology. the performance of RankBoost  , Regression and RankNet with the hidden layer.The results also suggest that query terms are valuable information for sake of ranking. Experimental results  , obtained using the LETOR benchmark  , indicate that methods that learn to rank at query-time outperform the state-ofthe-art methods.We now describe the parameter setting used for the model. For the free parameters in our Sequential Dependence SD sub-models we estimate the parameters using training data from the TAC KBP 2010 entity linking data  , resulting in settingsResearchers can follow the Laravel framework to create new Web pages for user interaction and define new data types e.g. Researchers can install PHP  , Laravel  , Node.js  , and a SQL framework and download the GitHub repository to get started with their instance of Coagmento.In both our question set and our interpretation of the results  , we avoided direct references to GitHub's implementation of the mechanism. While this model remains the same across all these sites and the social features are similar  , the implementation of several GitHub features might influence the developer's opinions of the model.In the case of GitHub  , external services are available to enable continuous integration e.g.  , Travis and code quality e.g.  , Code Climate monitoring on a per contribution basis. This can include code style compliance checks and perhaps more sophisticated static analysis tools.This context provides the hint that the user may not be interested in the search service provided by www.ask.com but instead be interested in the background information of the company. ask.com before query " Ask Jeeves " .These data sets were chosen because they are publicly available  , include several baseline results  , and provide evaluation tools to ensure accurate comparison between methods. For meta search aggregation problem we use the LETOR 14  benchmark datasets.Similarly to such tasks  , our dataset is composed of a large set of triples coming from LOD datasets  , while our queries consist of entities extracted from news articles and the gold standard is manually created by experts. Most of the proposed systems for this task see for example 6 exploit IR indexing and ranking techniques over the RDF dataset used at the Billion Triple Challenge 2009.Since the document relevance inferred from the PCC and DBN models is better than that from the CCM model in the above two experiments  , we only consider the PCC and DBN models in this part of experiment. For each query and document  , we extract about three hundred of features in the experiment  , where the features are similar to those defined in LETOR16.As we argue next  , BeerAdvocate and RateBeer exhibit multiple features that make them suitable for the analysis of linguistic change. 1 In both communities users provide ratings accompanied by short textual reviews of more than 60 ,000 different types of beer.The crawls follow a BFS pattern through the related questions links for each question. We followed the advice from a Quora data scientist 3 and start our question crawls using 120 randomly selected questions roughly evenly distributed over 19 of the most popular question topics.On the other three collections  , the performance of all the three PRoc models is very close. In addition  , from Table 4 we observe that PRoc3 outperforms the other two on the WT2G collection.The novelty lays in the decoupling of the development effort from the decision to incorporate the results of the development in the code base. Pull requests as a distributed development model in general  , and as implemented by Github in particular  , form a new method for collaborating on distributed software development.As Quora and its repository of data continues to grow in size and mature  , our results suggest that these unique features will help Quora users continue find valuable and relevant content. Finally  , the userto-user social network attracts views  , and leverages social ties to encourage votes and additional high quality answers.We collected blogs and profiles of 250K users from Blogger  , 300K users from Live- Journal and 780K users from Xanga. The data was parsed and used to construct a graph  , where each node corresponds to a blog user and a directed edge between two nodes corresponds to a blog entry of one of the users having a link to the other user's blog or entry therein.As shown in figure 4  , Pinterest users tend to follow others entirely and this behavior is not mediated by gender. .If  , otherwise  , the later is true  , then there is a subset of categories with commercially-appealing content -and these are not the ones users pin the most. If the first hypothesis is true  , then the shoppers will be a subset of users who use Pinterest differently from the others  , either for selling or for buying content.As previously explained  , a user follows other users in order to be regularly updated about events regarding them e.g.  , forks  , created repositories  , starred repositories  , and so on. In other words  , establishing links has high cost in GitHub  , as people do not " follow-back " unless they are professionally interested in the activity of their followers.However  , we observed that in some cases  , software projects are organized into multiple separate repositories on GitHub. The naive approach would be to consider each GitHub repository as its own separate project.For example  , NASDAQ real-time data feeds include 3 ,000 to 6 ,000 messages per second in the pre-market hours 43; Network and application monitoring systems such as Net- Logger can also receive up to a thousand messages per sec- ond 44. Depending on the application  , the number of messages per second ranges from several to thousands.Surprisingly  , for a goal-oriented and interestbased social network  , a non-trivial proportion of information seeking happens through non-social means which indicates a decreased importance of social ties in content discovery on Pinterest. Findings.More research is needed to explore options concerning process policies. A GitHub-wide acceptance process definition and enforcement mechanism might be beneficial to both integrators and contributors and might deter one-off  , low-quality contributions.Further developers were invited to complete the survey  , which is available at our project website . Moreover  , all developers reported they felt comfortable—4 points on average on a 5-point Likert scale between very uncomfortable 1 and very comfortable 5—implementing the annotator in GERBIL.Usually  , the discussion occurs between core team members trying to understand the changes introduced by the pull request and community members often  , the pull request creator who explain it. Any Github user can participate in the discussion of any pull request.5 showed that developers are able to make a variety of subtle inferences about other developers and projects using the social media cues. Previous qualitative research on GitHub by Dabbish et al.The earlier can be used to capture more information pertaining to the creation of a particular statistical item; – Defining sub-properties of using SCOVO-min and max. The latter is of particular help if an existing taxonomy or thesaurus is used as a base.For the free parameters in our Sequential Dependence SD sub-models we estimate the parameters using training data from the TAC KBP 2010 entity linking data  , resulting in settings It is important to note that we only used background term statistics from the training time range.To minimize this threat  , we use systems from different domain from Github and Apache  , having a substantial variation in age  , size and ratio of bugs to overall lines see table 1. External Validity concerns generalizability of our result.How many of those small changes can be synthesized in an automated manner ? Let us have a look at any bug fix of less than 10 lines in a source code repository  , for instance on Github.In GitHub a user can create code repositories and push code to them. GitHub is based on the Git revision control system 6 .In social networks  , a common measure of user popularity and influence is given by the in-degree Wasserman and Faust 1994 . Even if it is not possible to provide definitive evidence about that  , in the following we will show some interesting correlations between the activity of a user and some indirect rewards in terms of " social prestige " in GitHub.We choose hotels in Amish Country because during our initial investigation many potentially suspicious hotels were present. We choose the top 20 hotels in Amish Country  , Lancaster County  , PA from Hotels.com and TripAdvisor.Thus  , we focus on the coordinate ascent approach for the remainder of this paper. For example  , it takes two days for EM to finish for the RateBeer dataset  , whereas our method takes just two minutes.We also extract the topics of the questions in the cluster and rank the topics based on how many questions they are associated with. This cluster contains 43 questions  , and all questions are related to " Quora. "Over the course of 10 years the BeerAdvocate and RateBeer communities have evolved both in terms of their user base as well as ways in which users review and discuss beer. User lifespan.We asked users about their software development experience in general  , and with GitHub; which factors influence their contributing to new repositories; what makes them switch between projects; and their perceptions of the impacts of contributing to multiple projects. The survey included multiple choice  , Likert scale  , and open-ended questions.Sibling relationships were only identiied if the siblings and the parent that links to them were all present in the WT2G collection. Therefore  , if A is relevant and B  , A's sibling  , has similar content to A then it is likely that B is relevant a s w ell.With this work  , our goal is to deepen our understanding of how information in transparent open source software environments is used to evaluate contributions. GitHub is an example of a new class of work environment that offers greater transparency of work actions and social relationships.During this search  , we used the entity-document ED centric approach because we were interested in finding entity across multiple contexts 4  , 5. the Sindice dump for each entity candidate.While the results are based only on open source Java programs hosted on Github  , and using the popular Maven build system  , it is likely that our findings apply at minimum to many other Java projects  , and may well apply to other languages as well. This paper draws from the evaluation of hundreds of open source projects.We used the Github Archive database 4 to make a list of the most-watched Rails-associated repositories. Selecting Applications.Let M be the output annotations of an entity disambiguation system on the same input. Note that in all the results reported  , mentions that contain NIL or empty ground truth entities are discarded before the evaluation; this decision is taken as well in Gerbil version 1.1.4.We have proposed a vocabulary  , SCOVO  , and discussed good practice guidelines for publishing statistical data on the Web in this paper. When the data is present in a table with a certain layout  , it turns out to be advantageous to not only repurpose and link the data  , but also reuse the data table in the author's intended form.We now evaluate the potential for inter-domain trust transfer to reason about the trustworthiness of identities. Table 1 : Source domain distribution for random  , suspended and black market identities in Pinterest.Previous work 8  , 9  , 24 studied effectively finding previously answered questions that are relevant to a new question asked by a user. Answers and Quora.Besides metadata properties like titles  , descriptions and authors  , the source files of the open datasets themselves are linked as dcat:Distributions  , allowing Table 2: Datasets and their formats. GERBIL uses the recently proposed DataID 2 ontology that combines VoID 1 and DCAT 21  metadata with Prov- O 20 provenance information and ODRL 23  licenses to describe datasets.However  , each pinboard may be associated to one of 32 categories defined globally for all users by Pinterest. Unlike traditional social bookmarking  , pinning on Pinterest does not involve creating an explicit vocabulary of tags to describe the image.When the properties of the above document selection methodologies are considered  , one can see that infAP creates a representative selection of documents  , statAP and depthk pooling aim at identifying more relevant documents utilizing the knowledge that retrieval systems return relevant documents at higher ranks  , the LETOR-like method aims at selecting as many relevant documents according to BM25 as possible  , hedge aims at selecting only relevant documents  , and MTC greedily selects discriminative documents. The LETOR-like selection methodology also selects very similar documents  , since the documents selected are those that give high BM25 values and thus have similar characteristics.First  , the organization itself can create an account  , set up Pinboards  , and add pins. Institutional content can be collected on Pinterest in two ways.Actually  , the results of Ranking SVM are already provided in LETOR. In comparison with this baseline  , we can see whether Relational Ranking SVM can effectively leverage relation information to perform better ranking.However  , these algorithms can be integrated at any time as soon as their webservices are available. The AIDA annotator as well as the " Illinois Wikifier " will not be available in GERBIL since we restrict ourselves to webservices.JavaScript has been selected as the most popular programming language for three consecutive years 42 and it is the most used language on GitHub 23. Our results show that using Sahand helps developers perform program comprehension tasks three times more accurately. Number of reported bugs. 3 For client-side projects  , we select from the most popular JavaScript projects on GitHub.From the TripAdvisor data  , we randomly sampled 650 threads. From the source data  , we generated two datasets for question identification.Both lines increase smoothly without gaps  , suggesting that Quora did not reset qid in the past and the questions we crawled are not biased to a certain time period. We plot two lines for Quora  , a black dashed line for the total number of questions estimated by qid  , and the blue dashed line is the number of questions we crawled from each month.We observe up to 25 fold speedups in this distributed setting for the Microsoft LETOR data set. Fold 1 n=723K Set 1 n=473K Set 2 n=35K Perfect Figure 4: The speedups of pGBRT on the cluster as a function of CPU cores.Table 7: Optimal hyper-parameter on all retrieval methods over both types of verbose queries tuned for MAP on WT2g. Figure 2: Performance trend MAP as the single smoothing hyper-parameter λ  , µ  , and ω changes for each language model on the WT2g tuning collection for description only queries top and for description and narrative queries bottom.We crawled all the users in these groups  , and used these users as seeds to further crawl their social networks with their movie ratings. At the time when were crawling Douban web site November 2009  , there were more than 700 groups under the " Movie " subcategory.That possibly returns to the different nature of the usage of both sites. This is interestingly in contrast with 20  , which found that the most frequent sites on Pinterest had low Alexa Global Ranking.Some of the more popular open source software projects that GitHub hosts include Ruby on Rails and jQuery. The site offers both free open source project hosting and paid private hosting and is home to over ten million repositories 1.In fact  , contributing to as many GitHub projects as possible is an accomplishment  , valued by peers and employers alike 32. It is not uncommon to find prolific developers contributing code to 5-10 GitHub projects in the same week.Since the data is from many different semantic data sources  , it contains many different ontologies. The dataset for the ELC task is the Billion Triple Challenge dataset 2 .The framework aims at supporting people to publish their statistics on the Web of Data in an effective and efficient manner. We have proposed a vocabulary  , SCOVO  , and discussed good practice guidelines for publishing statistical data on the Web in this paper.Having targeted only users of GitHub  , this was a surprising result. Yet  , in our view  , the most relevant quality of our participants was that they were not only novice or hobby programmers  , but instead professional developers working in software companies .And we hopped to be able to generate weighted distribution of words that could potentially identify multiple topics of a query from the top ranked documents  , and by using these approximations of multiples topics  , we can perform multiple searches for the same query with different expansions  , followed by separate LETOR for each expanded query  , and eventually merge the results with data fusion. Originally  , this was performed after the first pass when most of the relevant documents are assumed to be retrieved by using BM25 and Indri with pseudo relevance feedback .Figure 4shows the results on Letor OHSUMED dataset in terms of MAP and NDCG  , averaged over five trials. We conducted 5-fold cross validation experiments  , following the guideline of Letor.The nature of GP algorithms is also prone to overfitting. According to the authors  , GP based LETOR was able to achieve competitive performance with RankSVM and RankBoost  , but its computational cost is higher.13 The plot shows that the additionally curated identities are young identities that have probably not had time to gain sufficient reputation on Pinterest  , confirming our expecta- tions. Figure 6compares the CDF of the age of the accounts on Pinterest for identities that are curated using intra-domain reputation signals  , and the additionally curated identities.We adopt the consumer purchasing records dataset from Shop.com 1 for model evaluation  , because an important information source leveraged in our framework is the quantity of product that a consumer purchased in each transaction   , which is absent in many of the public datasets. These amount to roughly 100k transactions by 34k consumers on 30k products in the testing dataset.On Pinterest  , we then collected all identities that had liked or repinned two or more to improve the likelihood of discovering untrustworthy identities of the 135 collected pins. We subscribed to the site and collected a list of 135 such pins in one day.For meta search aggregation problem we use the LETOR 14  benchmark datasets. Given an aggregate ranking π  , and relevance levels L  , NDCG is defined as:Considering all projects  , not just those hosted on GitHub  , our survey participants reported contributing to an average of 2.7 projects per day median 2; range 0–10. Still  , almost all developers 98%; 1 ,165 out of 1 ,193 contributed to multiple projects per day at least once.Coverage: To estimate and compare the coverage for a given target purity level  , we apply the two classifiers on the test data and we rank all the Pinterest identities according to the probabilities returned by the classifier. We then study what kinds of identities benefit the most from inter-domain reputation signals.Several other users may want to repin this onto their own pinboards. Consider an image which has been introduced into Pinterest by an original pinner.For merged pull requests  , an important property is the time required to process and merge them. This result is higher than the overall we calculated for Github; we attribute this to the fact that the dataset generation process employs heuristics to detect merges in addition to those happening with Github facilities.Our experiments on LETOR 3.0 benchmark dataset show that the  NDCG-Annealing algorithm outperforms the state-of-theart algorithms both in terms of performance and stability. As an instance of the method  , we optimize NDCG in this paper  , but other metrics in ranking can also be applied directly.We gathered our Quora dataset through web-based crawls between August and early September 2012. The basic statistics of both datasets are shown in Table 1Quora.the person who uploaded a photo that has been pinned on Pinterest may hold the original and may host it elsewhere online  , these would be difficult to obtain by the user if their collection was lost even if simply because it's hard to remember what's in the collection . There is no digital original under the user's control  , and while duplicates exist e.g.BM25 slightly outperforms LM with Dirichlet prior on the WT2G collection. Therefore   , it is fair to compare them on these four collections.Respondents reported challenges regarding the tools and model less frequently. Without threading it can be hard to follow a conversation " r102   , " effectively communicating with other users over github " r329.Thus  , even though each pinboard may be exclusive to a user  , the act of pinning implicitly categorises the image. However  , each pinboard may be associated to one of 32 categories defined globally for all users by Pinterest.For identities that posted malicious pins  , we use a threshold for the fraction of malicious pins posted  , which corresponds to the top 1% most untrustworthy identities. Figure 4 compares the CDFs of various reputation signals for random Pinterest identities and four different kinds of untrustworthy Pinterest identities.Previous work has revealed that most GitHub repositories are inactive and have a single user 25  , 31 . Sampling projects and candidate respondents.The WT2g connectivity data see http://pastime.anu.edu.au/WAR/WT2g_Links/ilink_WTonly.gz and the Small Web qrels file were used to find the set of documents which link directly to relevant documents. ACSys has attempted to determine whether this was the case by looking at the indirectly relevant documents retrieved by the runs listed in Table 7.In Figure 4we present a representative set of Semantic Web vocabularies that are relevant for the desktop  , grouped by their application domain. Semantic search engines  , such as Sindice 14 and Swoogle 5  , or index sites for the Semantic Web 4 are good starting points to search for existing vocabularies.In this work we examined how social and technical information in the transparent open source software environment of GitHub is used to make contribution decisions. Our findings may also inform how project managers should change their evaluation policies based on what signals are important.There are 106 queries in the collection. Letor OHSUMED dataset consists of articles from medical journals .Each data set is partitioned on queries to perform 5 fold cross-validation. The results of RankSVM  , RankBoost  , AdaRank and FRank are reported in the Letor data set.More information can be found at our project webpage http:// gerbil.aksw.org and at the code repository page https: //github.com/AKSW/gerbil. We conclude with a discussion of the current state of GERBIL and a presentation of future work.A key observation is that given the broad and growing number of topics in Quora  , identifying the most interesting and useful content  , i.e. Despite their different topics of interest  , Quora and Stack Overflow share many similarities in distribution of content and activity.We focus on questions with some minimum number of user interactions ≥4 answers   , which filters out all but 87K 20% questions from our # of Followers and Followees Followers Followees dataset. Unfortunately we could not do the same for question page views  , because Quora only reveals the identity of users who answer questions   , but not those who browse each question.Our study focuses on gender-based analysis of user behavior and our contributions are the following:  We develop a distributed crawler to collect a large dataset from Pinterest. To our knowledge this is the first study to conduct a large scale analysis of Pinterest.With this information we propose a simple algorithm to detect users who use Pinterest to promote their external website  , hereby called self promoters . the source entropy of the users  , we are able to determine which is the main source of pins from each user  , just by observing the domain with the highest probability p i .Although Pinterest is primarly on image-based OSN  , users may write typically brief freeform textual descriptions for each pin. Third  , we compare the language used in pin descriptions and tweets.Figure 5shows the coverage vs. the level of Figure 5: Coverage of the curated set for a given purity level for identities curated using all signals  , only Pinterest signals  , and identities curated at random. Coverage: To estimate and compare the coverage for a given target purity level  , we apply the two classifiers on the test data and we rank all the Pinterest identities according to the probabilities returned by the classifier.Pull requests and shared repositories are equally used among projects. RQ1: 14% of repositories are using pull requests on Github.The level of influence of a user is merely the activity of other users directed towards that user  , i.e.  , the number of repins and likes received by that user for her pins. To quantify the level of user activity on Pinterest  , we employ three different measures: the numbers of boards created  , pins made including repins of other users' pins  , and likes of others' pins.The full list of public events that have happened on GitHub is available on the GitHub Archive website 8 . For our static analyses we consider these networks as they appear on the final day of the time window we take into con- sideration.The second evaluation  , based on the WSDM 2014 Web search personalization challenge  , 1 uses dwell time as ground-truth labels and real clicks as feedback to BARACO. The first evaluation  , based on the LETOR datasets 17  , uses manual relevance assessments as ground-truth labels and synthetic clicks as feedback to BARACO.Our findings inform how software developers and project managers make use of information in social work environments such as GitHub and imply a variety of ways that social features in work environments can support software development. Well-established projects were more conservative when evaluating pull requests  , perhaps due to audience pressures.We hypothesize that for a hybrid service like GitHub  , both a social network and a collaboration network  , some kind of indirect reward mechanism might and potentially underpin user activity. 2012.Using SCOVO in voiD allows a simple and extendable description of statistical information  , however  , a shortcoming has been identified: as scovo:Items are grouped into scovo:Datasets  , there is an implicit assumption that all items in such a dataset share the same dimensions. SCOVO is used in voiD  , the " Vocabulary of Interlinked Datasets " 1  to express information about the number of triples  , resources and so forth.We perform Hamming ranking using the generated binary codes on the CIFAR-10 and NUS-WIDE datasets. This is because the number of iterations needed to learn U decreases as the code length increases.The classic Rocchio's model  , fails to obtain improvement on the WT2G collection. The effectiveness of pseudo relevance feedback is reconfirmed in this set of experiments.They might  , however  , rely on subtle social signals that environments like GitHub provide  , without realizing it. This situation raises questions about whether social features are useful to contributors.A main advantage of our work is that we do not rely on one source of information  , but rather combine three di↵erent sources SO  , GitHub projects  , and developer surveys. 26 that summarizes the techniques used in this area.From those terms  , chemical entities are extracted and synonyms for the identified chemical entities are also included from PubChem. TF–IDF scores are chosen for each to construct the queries.Currently  , only very few web-based tools use tables for representing Linked Data. As an example  , the popular Semantic Web search engine Sindice 8 is practically unusable for people without a deep understanding of semantic technologies.All project code is available in a Github repository at https://github.com/medusa-project. As of April 2013  , the Medusa development team has implemented a functioning collection registry  , bit-level ingest feature  , and an object-level PREMIS packager.Next we consider how experience relates to user retention. We mention the parallel work of 9  , which also studies BeerAdvocate and RateBeer data: there  , a user's failure to adopt the linguistic norms of a community is considered as a factor that may influence whether they will abandon that community.Table 9gives the numbers of directly and indirectly relevant documents. The WT2g connectivity data see http://pastime.anu.edu.au/WAR/WT2g_Links/ilink_WTonly.gz and the Small Web qrels file were used to find the set of documents which link directly to relevant documents.Therefore  , we compare our approach with two competitive systems from RepLab 2013:  Best RepLab 34. The differences we have detected could be irrelevant or misleading if both our baseline and contrastive systems were below state-of-the-art results.EM algorithm. Using parallelization with 20 threads  , our model could be fit on our largest dataset RateBeer of 2 million total events within two minutes.The first way is pinning  , which imports from a URL external to pinterest.com. Images added on Pinterest are termed pins and can be created in two ways. LETOR: Using only statistical features associated with matched terms features L1−10 and H1−3 in Tab. 1.With LETOR  , in contrast  , features capture general properties of query-document compatibility . For example  , while the word " dog " might be very important to the current query  , RF on this query cannot tell us anything about how important this word should be for other queries.We have described an experimental method in which learnt uncertainty information can be used to guide design choices to avoid overfitting  , and have run a series of experiments on the benchmark LETOR OHSUMED data set for both types of model. The Gaussian process allows the smoothing uncertainties in SoftRank to reflect modelling uncertainty in the learnt score function.If our service returns a NIL annotation  , GERBIL treats it like " not annotated " . We note that the GERBIL version that we use does not consider NIL annotations when computing the F1  , recall and precision values.On Pinterest  , as on other interest-and goal-oriented sites Baird and Fisher 2005   , the social network does play an important role in creating and fostering community formation. In summary  , these results show that  , in fact  , the previous literature results on interest-based social networks do not contradict each other.It is not known at this stage  , what proportion of the dead links those whose target lies outside WT2g are inter-server links and how many are references to same-server pages which happen to be missing from the VLC2 1 . 52 % of these links reference another document within WT2g but only 0.12 % reference a different server within WT2g.Github is currently the most popular repository for open source code and its transparent environment implies a suitable basis for evaluating reuse and collaboration among developers 21. The participants where selected from the community of Semantic Web SW developers on Github who have had at least one active SW-related repository.The goal of this work is to obtain a deep understanding of the pull-based software development model  , as used for many important open source projects hosted on Github. The dataset as well as custom-built Ruby and R analysis tools are available on the Github repository gousiosg/pullreqs  , along with instructions on how to use them.For technology survey  , we proposed a chemical terminology expansion algorithm with the professional chemical domain information from two chemical websites  , ChemID plus and PubChem. 3how to deal with long queries in Prior Art PA task ?com/srinathsridhar/graph-matching-source Recall that the partition algorithm split the graph into multiple graphs and found matchings using an implementation of Hopcroft-Karp 13 in these smaller graphs which were then combined into a recommendation subgraph. The code used conduct these experiments can be found at https://github.For example  , impressions of general coding ability could be gleamed from the contents of a GitHub user's profile. 19 found that when GitHub developers engage in information-seeking behaviors  , they use signals in the environment to form impressions of users and projects.Each database shard included a dimensional data model for its portion of the collection  , and a dimensional index of PubChem 8 terminology for synonym identification. For example  , one shard for EP 000000  , one shard for EP 000001  , one shard for US 020060  , etc.This hinders the effective discussion of high-level concerns e.g.  , system design and has a negative impact on the centralization of information about a contribution. A significant portion of both integrators and contributors find that the communication facilities afforded by the GitHub PR mechanism are lacking in terms of immediacy and structure.GitHub is also a popular code hosting site with a large user base that could provide a relatively diverse pool of potential participants. In previous work 13  , we were able to recruit such participants from GitHub 3 .The Wookieepedia collection provides two distinct quality taxonomies. These are the two Wikia encyclopedias with the largest number of articles evaluated by users regarding their quality.These repositories span several programming languages: Java  , C  , C++  , JavaScript  , and Python. We collected SVN repositories from Source- Forge as and Git repositories from GitHub.We ran additional experiments using the NYT topic model described in section 4.1  , and noticed that for the topics which were captured in the other latent model as well  , we observe similar trends and dependencies in the results. The results presented in the experimental section were obtained using the Quora topic model as the background knowledge model.the usage of SCOVO  , let us assume we want to model airline on-time arrivals and departures. We note that the complete example  , including the exemplary queries in an executable form  , is available at http://purl.org/NET/scovoIn the following  , we present nine well-known and publicly available data sets which are integrated in GERBIL and are used in our evaluation. The reported results of our approach and competitive systems are based on this platform and serve as comparable results for future systems.26 examined the testing practices of projects on Github and found that the lower barriers to submission hinders high-quality testing as the work load on project member increases. Pham et al.Since this includes a significant fraction of all identities  , in the same way as for identities with blocked pins  , we assume that identities with higher fractions of low WoT reputation pins are more likely to be untrustworthy. There are 1 ,083 ,951 such Pinterest identities that have at least 1 pin with a low WoT reputation score or no pin with a WoT score.We use Sindice Search API to search the WoD and Lucene for indexing/fuzzy retrieval model. Client-side personalization is also scalable and computationally efficient since the workload is distributed to the clients and network traffic is significantly reduced.dataset by merging the original partitions into a single set  , and splitting the sorted queries into 5 folds  , distributed using the same proportions: 3 folds for training  , 1 for validation and 1 for test. For comparative purposes  , considering that the Microsoft and LETOR datasets were designed for a folded cross-validation procedure  , we applied this same strategy to the YA- HOO!In the empirical study  , we selected 8 GitHub 5 Java projects that have been widely used in software testing research 23– 25 . As this empirical study is designed to investigate the influences of test addition  , the columns " Ft1 " and " Ft2 " presents the numbers of faults used for theThe survey included multiple choice  , Likert scale  , and open-ended questions. We sent an online survey to 851 GitHub users selected from the set of prolific developers described earlier.Lucene IR framework is utilized for indexing of concepts and at the implementation of the fuzzy retrieval model. In particular  , we use Sindice search for querying the WoD and Sindice Cache for retrieving RDF descriptions of LOD resources 2.Crowdsourcing sensitivity and domain judgements. We trained 3 LDA models  , using the Mallet topic modeling toolkit: i with 500 topics  , on 600K Quora posts we crawled ii with 200 topics  , on 3M posts from health Q&A online forums  , and iii with 500 topics  , on a sample of 700K articles from the New York Times NYT news archive.Figure 6shows the number of categorized sessions per user in our dataset. The category for a Pinterest session is simply the most frequent category among the pins in that session.In Pinterest  , user interest is conveyed by the images a user pins and repins in different boards  , each of which is tagged with a category. Second  , we investigate the interests of users on these two different platforms .We use a non-linear Random Forest regression model for our experiments. To create features for the selection framework  , we use the published test runs 1 for these rankers to obtain the document scores for top 10 ranking documents  , and the list of 64 features that are available as part of LETOR.1b we examine the entire history of activities of all users  , as they " age " in Pinterest by accumulating more activities. In Fig.For each query in the query set  , all the points in the training set are ranked according to the Hamming distance between their binary codes and the query's. We perform Hamming ranking using the generated binary codes on the CIFAR-10 and NUS-WIDE datasets.Second  , does the presence of popular users correlate with high quality questions or answers ? First  , what triggers Quora users to form social ties ?23 found in their study of the testing culture in GitHub that project managers would demand that contributions include tests in certain cases. Pham et al.On GitHub  , users can indicate whether they are available for hire: 80 respondents said they were for hire and 171 said they were not. The number of accounts people followed ranged from 0 to 2 ,600.There are 724 ,672 Pinterest identities with at least one blocked pin  , which includes 43% of all Pinterest identities. We refer to pins with blocked URLs as blocked pins.Structured call sequences are extracted from open-source projects on GitHub. Using structured call sequences allows the synthesizer to generate code which covers the suggested APIs from the natural language to API mapper  , and at the same time  , obeys common coding conventions.In this section  , we model the interaction between Quora users and topics using a user-topic graph  , and examine the impact of such interactions on question answering and viewing activities. A question  , once created or updated under a topic  , will be pushed to the newsfeeds of users who follow the topic.The list-wise approach was proved to be more effective than pairwise and point-wise approaches  , as its optimization criterion is closer to the actual evaluation metrics. For list-wise LETOR  , we are using ListNet 6  , which uses a simple one layer Neural Network with Gradient Decent to optimize a defined list-wise loss function based on " top one probability " .The currently most complete index of Semantic Web data is probably Sindice 4 . We tried to relate this to the growth of the Semantic Web.Furthermore  , unlike on LETOR where the performance of ActiveAda-S-T converges more quickly than others  , we do not observe any trend of convergence up to the point with 2000 selected queries. It is more likely that these cross-domain relevant knowledge in source domain are even more helpful than those most informative target queries identified by Active-T.5kudos to Andreas Langegger for the screen shot  , that generates statistics for datasets behind SPARQL-endpoints and RDF documents. Further  , we have gathered that SCOVO is used in the RDFStats framework 15   , see Fig.Workers are expected to answer product-related questions in a biased manner  , and in some cases post dummy questions that are immediately answered by other colluding workers. Finally  , " Q&A " involves posting and answering questions on social Q&A sites like Quora quora.com.The sources of the stored documentation are thus very varied ; in the case of the existing prototype mediaeval history of France the sources include : original documents  , learned contemporary works  , articles from journals  , etc. Firstly  , the information stored in the system's database is not in the form of "documents" in the usual sense of the term "full text" or bibliographical references but in the form of "facts" : every "episode" in the lives of our personages which it is possible to collect and represent.We then define the social repin network  , as the subgraph of links in the Pinterest network over which at least one social repin happens in our data. To measure this effect  , we first define the concept of a social repin  , which is a repin in which a user repins a pin of someone whom she follows.3 For client-side projects  , we select from the most popular JavaScript projects on GitHub. For node.js projects  , we select modules that are the most depended-on modules in the npm repository .The SVMRank 5 algorithm was used in this task and five-folds cross validation was done. Since a lot of features of LETOR we cannot get  , we droped those columns and then trained the ranking model.In Section 7.1 we directly compare the approaches on the basis of its results achieved with GERBIL. link to a KB task.We begin by examining the follower and followee statistics of Quora users. editors  , actors and CEOs.Pinterest users organize objects by selecting an image from the webpage where the object exists using a browser bookmarklet or by uploading an image from their computer. Pinterest also has many social components: users add boards to subject categories ,'repin' objects from other users to their own boards  , " like " or comment on objects  , and " follow " boards and other user's activity.27 found that integrators struggle to maintain the quality of their projects. In a survey of integrators of busy projects in GitHub  , Gousios et al.Sindice  , Falcons and Hermes are formally evaluated over hundreds of millions of statements  , while Semplore is evaluated over tens of millions of statements. Existing systems operate on data collections of varying size.By activity  , we mean the amount of content generated. As stated before  , Pinterest is all about pins  , thus our first analysis focuses on the activity of the users.To our knowledge this is the first study to conduct a large scale analysis of Pinterest. Moreover  , there is no official public API available for data collection  , which makes the process even more laborious.In Figure 1  , the performance variations on graded MQ2007 are represented as curves with open symbols while that on0.0 0 . Each performance value on test sets shown in the figures is averaged using five-fold cross validation as the same way used in LETOR.The evaluation of our framework by contributors suggests that adding an annotator to  GERBIL demands 1 to 2 hours of work. Moreover  , 6 novel annotators were added to the platform.These surrogates are then saved in personal collections  , called " pinboards " on Pinterest. Users of a social collecting site create and annotate surrogates of digital objects found on the Web  , such as photographs or webpages.The second collection is the largest provided by the Wikia service  , Wookieepedia  , about the Starwars universe. In this article  , we refer to this sample as WPEDIA.26 To this end  , GERBIL implements a Java-based NIF 15 reader and writer module which enables loading arbitrary NIF document collections  , as well as the communication to NIF-based webservices. Moreover  , we capitalize upon the uptake of publicly available  , NIF based corpora over the last years 40  , 36.From the Wikia service  , we selected the encyclopedias Wookieepedia  , about the Star Wars universe  , and Muppet  , about the TV series " The Muppet Show " . From now on  , we refer to this encyclopedia as WPEDIA.Furthermore  , the combination of GRH+NPQ outperforms the adaptive thresholds allocation model VBQ of 3 by a relative margin of 27%. For example  , for LSH projections GRH+NPQ gains a relative increase in AUPRC of 60% over NPQ and 28% over GRH on CIFAR-10.Overall  , we consider 1 ,084 ,816 reviews from 4 ,432 users in BeerAdvocate  , and 2 ,016 ,861 reviews from 4 ,584 users in RateBeer. For a similar reason  , we discard beers which are individual events in our setting that have been reviewed by fewer than 50 users.The best system in the official RepLab 2013 evaluation campaign 2. Therefore  , we compare our approach with two competitive systems from RepLab 2013:  Best RepLab 34.This is because we were counting on topic modelling based query expansion to improve diversity performance  , such that we have not defined a dedicated list-wise optimization criterion on top of the rank list that addresses diversity. It is also worth noticing that even though most of these features are directly consistent to the relevance of a document to a query  , none of our LETOR methods include diversity into account .Social coding  , as performed on GitHub  , and cloud computing come to mind  , but other new ways to drive progress surely remain to be discovered. In addition  , the looming end of progress in semiconductor manufacturing driven by Moore's Law 35 means that corresponding advancement of software development practices based on its fruits will also stall; we will need to come up with other  , more frugal or different  , sources of innovation.Our goal is to make it easier to re-appropriate and re-categorise content for personal use. Consequently  , curation on Pinterest remains a highly manual process as well.We can observe that the PLM improves performance on WT2G and FR clearly and consistently  , which shows that  , similar to general passage retrieval  , the PLM can bring added benefits to document retrieval when documents are relatively long. The results are shown in Figure 4  , where we vary the smoothing parameters for both smoothing methods on all the four data sets.We do suggest caution being taken when reviewing the Small Web Task to take the results in the context of the WT2g dataset  , lest one conclude that Connectivity Analysis does not improve precision in any case. It is our understanding that any implementation of these approaches would not succeed in improving precision to any usable extent  , if at all when the experiments were based on the WT2g dataset  , due to the lack of Functional links.However  , the relationship between the number of reviews and the number of hotels Figure 3c is below an ideal straight line for the first few points  , since there are surprisingly few hotels with fewer than 50 reviews. TripAdvisor 1-star  , 2-star  , 3-star  , 4-star  , 5-star distribution of the number of reviews per reviewer Figures 4c also follows a power law.Second  , we will use the rank of spots on TripAdvisor and the rate of the reviews as the indicators of spots' quality  , it embodies the commonness of recommendation system  , while we use the probability of user interest for each category and the classification label of each user‐spots pairs as the reflecting of the user personalized interest  , it embodies the  Rest of the spots sorting First of all  , we sort the probability of user interest of dislike for each category in ascending way. First of all  , the recommended spots should conform to the requirements of location in context  , so we will use location as a criterion of the recommendation system.The dataset is the Billion Triple Challenge 2009 collection. We evaluate our approach using the evaluation framework used in the Semantic Search Challenge 2010 3 .We also used the API to gather information on all issues and comments for each repository. This set of user information includes 95 ,270 unique GitHub user accounts.We investigated the effort to implement a BAT-framework adapter in contrast to evaluation efforts done without a structured evaluation framework in Section 4. Due to the community effort behind GERBIL  , we could raise the number of published annotators from 5 to 9.One option was to use Sindice for dynamic querying. For non-adaptive baseline systems  , we used the same dataset.This leads to the question: do users share the same linguistic style across pin descriptions and tweets ? Although Pinterest is primarly on image-based OSN  , users may write typically brief freeform textual descriptions for each pin.These long requests are often kept running because the number of such requests is small  , and derived results can be cached for future use. For example in Ask.com search site  , some uncached requests may take over one second but such a query will be answered quickly next time from a result cache.The Organic Data Science Framework software is open source and is released on GitHub under an Apache 2.0 license. 3 Other external systems that we plan to integrate into the Organic Data Science framework include data repositories  , software repositories  , collaboration networks  , and publication repositories.We find that users who are influential  , measured by repins  , tend to have lower copy ratios. 6fshows that this result extends to measures of influence on Pinterest.Example 2 shows a similar problem in a different domain. If the NASDAQ Computer Index were further divided into software  , hardware  , services  , etc.  , one can further analyze comparisons with them.The server side is implemented with Java Servlets and uses Jena. We use Sindice Search API to search the WoD and Lucene for indexing/fuzzy retrieval model.We employ five different document selection methodologies that are well studied in the context of evaluation  , along with the method used in LETOR for comparison purposes. If yes  , which one of these methods is better for this purpose ? "Due to the community effort behind GERBIL  , we could raise the number of published annotators from 5 to 9. Since GERBIL is based on the BAT-framework  , annotators of this framework can be added to GERBIL easily.Beyond the social values associated with the online forums  , the owners of the forums also directly benefit from the traffic of active forums  , e.g. discussing travel experiences in TripAdvisor.In this paper  , we perform a detailed measurement study of Quora  , and use our analyses to shed light on how its internal structures contribute to its success. A simple search on Quora about how it works produces numerous unanswered questions about Quora's size  , mechanisms  , algorithms  , and user behavior.Users may find out about the new pin externally to the website and upload the pin themselves. 2013; Zhong  , Karamshuk  , and Sastry 2015  have found that creating new pins or repins  is by far the most common activity on Pinterest  , and presents a quintessential information seeking activity.The open source Sindice any23 4 parser is used to extract RDF data from many different formats. Sources are then fetched in parallel in a process mediated by multiple cache levels  , e.g.  , making ample use of the Sindice public cache.The BTC dataset contains 10 million quadruples  , but we used smaller excerpts containing 100  , 250 and 500 thousand unique quadruples. In our experiments we used real data that were taken from the Billion Triple Challenge BTC dataset small crawl 6 .The CIFAR-10 data set contains 60 ,000 tiny images that have been manually grouped into 10 concepts e.g.  , airplane  , bird  , cat  , deer. Given a query image  , the images sharing at least one common concept with the query image are regarded as the relevant ones.Second  , Pinterest users can pin an organization's content to their personal pinboards. First  , the organization itself can create an account  , set up Pinboards  , and add pins.For reference  , we report the baseline score comparison in the following format: 3. 4 Our RankBoost baseline is comparable but different from LETOR18  , mainly due to different feature normalization mean-variance vs. 0  , 1 scaling.We use this signal to identify suspended identities on Pinterest. Since this includes a significant fraction of all identities  , in the same way as for identities with blocked pins  , we assume that identities with higher fractions of low WoT reputation pins are more likely to be untrustworthy.For both CIFAR-10 and NUS-WIDE datasets  , we randomly sample 1 ,000 points as query set  , 1 ,000 points as validation set  , and all the remaining points as training set. All our experiments are conducted on a workstation with 24 Intel Xeon CPU cores and 64 GB RAM.If the resource descriptions includes OWL inverse functional properties IFPs from a hardcoded list e.g.  , foaf:mbox and foaf:homepage  , then a Sindice index search for other resources having the same IFP value is performed. If the resource descriptions include any owl:sameAs links  , then the target URIs are considered.For SourceForge we used its own internal ranking metric to select the top ranked repositories. For GitHub we selected the top ranked repositories  , i.e.  , repositories that have been marked as favorites by developers and/or have been forked the most.Microsoft has a supercategory Computer and video game companies with the same head lemma. The category Microsoft has a homonymous page  , categorized under Companies listed on NASDAQ which has the head lemma companies.Our analysis reveals interesting details about the operations of Quora. This further supports our hypothesis that Quora's social graph and question graph have been extremely effective at focusing user attention and input on a small subset of valuable questions.The feature semantic_jaccard is similarly defined by the Best RepLab system 34  , detailed in §3.5. Analogously to term features  , we compute the semantic features semantic_jaccard  , semantic_lin_cf and semantic_lin_tfidf over the bag-of-entities tweet representation.It is our understanding that any implementation of these approaches would not succeed in improving precision to any usable extent  , if at all when the experiments were based on the WT2g dataset  , due to the lack of Functional links. We didn't implement any of these approaches  , as we felt that more was to be gained from developing our own ideas  , with the knowledge that the other methods existed.Using these input queries  , our system search the WoD by utilizing Sindice search API 2 and initial search results from the Sindice search are presented to users with no categorization. Users can provide keyword or URI based queries to the system.Then structured queries are formed to do retrieval over different fields of documents with different weights. From those terms  , chemical entities are extracted and synonyms for the identified chemical entities are also included from PubChem.The chances that those contributions will get accepted are higher with pull requests; across Github  , more than 70% of external contributions are merged 40% in other studies 29  , 32 . With pull requests  , developers can contribute to any repository  , without loss of authorship information .We examine how the social repin network selectively samples the underlying network of Pinterest. We then define the social repin network  , as the subgraph of links in the Pinterest network over which at least one social repin happens in our data.As with our first batch of results presented for Ro- bust04  , we again assume the user provides correct feedback. Since we are only training on a single topic  , resulting accuracy is far lower than what typically published LETOR results.Since we are only training on a single topic  , resulting accuracy is far lower than what typically published LETOR results. Instead  , for each topic we train on it alone and evaluate on all other topics  , then we average this over all topics.This is a highly counterintuitive outcome. When the LETOR collection was built  , the fact that documents with low BM25 score were selected only if they were relevant resulted in BM25 being negatively correlated with relevance in the LETOR collection.Figure 6plots exposure generation time against lines of source code for each of these applications . We ran the exposure generation step only on the 1000 most-watched Rails applications on Github.A significant portion of both integrators and contributors find that the communication facilities afforded by the GitHub PR mechanism are lacking in terms of immediacy and structure. Communication tooling.However  , accurate estimation of visit probabilities is impossibile due to the lack of login and browsing data of TripAdvisor users. Meanwhile   , we want to obtain a visit probability sequence that is similar at least in trend to the real data.2013 that focus on quantifying and analyzing Pinterest user behavior. As Pinterest has grown  , there have been a number recent studies e.g.  , Feng et al.This work provides a first look into this matter on a relative new social network that grew quickly in importance and became one of the most popular and peculiar social network. To our knowledge  , no research paper focused on user behavior  , based on gender  , was conducted in a heavy image-based network such as Pinterest.1 Crawled during February/March 2009  , it comprises about 1.14 billion RDF statements. The data collection we use is the Billion Triple Challenge 2009 dataset.The assessors checked the number of relevant documents in the Web collection once they had a candidate topic from searching the ad hoc collection. NIST assessors referred to the WT2g collection during the process of ad hoc topic generation.Users can create connections to other users on Pinterest in two ways. Pinterest incorporates social networking features to allow users to connect with other users with similar interests.Thus  , the results reported here refer to non-normalized data. We also tried different strategies to normalize our feature vectors  , including L2-norm  , z-score and the LETOR normalization procedure 17  , with no improvements.In both experimental setups  , i.e.  , the LETOR and WSDM setup  , both BARACO and MT have good performance in most cases and high agreement with the ground truth. The estimated difference between rankers is strongly correlated with the ground truth in the WSDM dataset  , suggesting that both methods can estimate the difference between rankers well given the logged user interactions with the production ranker.Meanwhile  , we collected tags and brief introductions from DouBan in order to evaluate the coverage performance of our system. After filtering by Syntactic Filter  , this collection contained 10 authors  , 48 books  , 757 reviews and 13 ,606 distinct words.To evaluate the effectiveness of the proposed method  , we performed a systematic set of experiments using the LETOR benchmark collections OHSUMED  , TD2004  , and TD2003 and several evaluation measures MAP  , NDCG and precision . This information may turn the generated rules more discriminative and accurate.Pinterest developed an image search platform and thus they showed that content recommendation powered by visual search improves user engagement 10. Several prominent companies have already deployed their own image retrieval solutions.In the experiment we used data obtained from a commercial search engine. Note that we did not use the public LETOR data 15  , because the numbers of queries in the datasets are too small to conduct meaningful experiments on query dependent ranking.One explanation is that the 'best' products tend to be ones that require expertise to enjoy  , while novice users may be unable to appreciate them fully. Recall that in Figure 1we examined the same relationship on RateBeer data in more detail.Paul  , Hong  , and Chi found that  , on Quora  , users judge expertise and reputation of answers based on previous contributions 26. Expertise has been shown to be an important factor when people decide how and who to ask for information 6  , 12.At the time when were crawling Douban web site November 2009  , there were more than 700 groups under the " Movie " subcategory. Users on Douban can join different interesting groups.Table 1summarizes the properties of these data sets. For our experiments we work with three public data sets: TD2004 and MQ2007 from LETOR data sets 24 and the recently published MSLR-WEB10K data set from Microsoft Research 1.To compute these metrics we used the standard evaluation tool available for the LETOR 3.0 benchmark for binary datasets  , as well the tool available for the Microsoft dataset for all multi-label relevance judgment datasets 5 . The statistical tests are computed over the values for Mean Average Precision MAP and the Normalized Discounted Cumulative Gain at the top 10 retrieved documents hereafter   , NDCG@10  , the two most important and frequently used performance metrics to evaluate a given permutation of a ranked list using binary and multi-relevance order 31.Since Quora does not show when a question is posted  , we estimate the posting time by the timestamp of its earliest answer. Assuming we are correct about the use of qid  , we can plot an estimate of the growth of Quora and Stack Overflow   , by plotting qid against time.Section 5 evaluates SERT with application benchmarks from Ask.com. Section 4 describes our implementation.We conduct experiments on eight standard collections  , which include AP88-89 with queries 51-100  , AP88-90 with queries 51-150  , FBIS with queries 351-450  , FT91-94 with queries 301-400  , LA with queries 301-400  , SJMN1991 with queries 51-150  , WSJ87-92 with queries 151-200 and WT2G with queries 401-450. The number of topics Kt is set to be 400 as recommended in 15.There are various reasons why developers are more prolific on GitHub compared to other platforms. In fact  , contributing to as many GitHub projects as possible is an accomplishment  , valued by peers and employers alike 32.Not surprisingly  , questions under well-followed topics generally draw more answers and views. The user-topic interaction has considerable impact on question answering activities in Quora.These conclusions can be helpful to improve the performance of Semantic Search engine implementations based on Lucene  , such as Sindice  , Watson  , Falcons or SEMPLORE. Confirmed evidence of the reasons behind the bimodal distribution would make possible to propose better retrieval approaches that are able to enhance the performance of the queries for which the current approaches fail to provide satisfactory results.Our analysis relies on two key datasets. Out of the 264K extracted users  , we found that roughly 5000 1.9% profiles were no longer available  , likely deleted either by Quora or the user.17 That is  , the AIDA team discourages the use because they constantly switch the underlying entity repository  , and tune parameters. The authors publish a key-protected webservice 14 as well as their 43  , GERBIL will not use the webservice since it is not stable enough for regular replication purposes at the moment of this publication .Standard test collections are provided and metrics are defined for the evaluation of developed systems. To facilitate the development and advancement of video hyperlinking systems  , video hyperlinking has become a competition task since 2012 in MediaEval 6.According to a 2012 survey by the Pew Research Center   , Pinterest has attracted 15% of internet users to its virtual scrapbooking. Pinterest was launched on march of 2010 as an effort to compete in this new trend with an innovative and pioneering paradigm: a pinboard-style image sharing network for people with good taste Chafkin 2012.To validate our hypothesis  , we examine the correlation between a user's follower count and the quantity and quality of her answers to questions. Thus our hypothesis is that  , outside of the small portion of celebrities who get followers just by their mere presence  , the majority of Quora users attract followers by contributing a large number of high-quality answers.We chose subject programs by looking at bug reports for popular JavaScript projects on GitHub. Selection Criteria.On SemSearch ES  , ListSearch and INEX-LD  , where the queries are keyword queries like 'Charles Darwin'  , LeToR methods show significant improvements over FSDM. The overall improvements on all queries can be as large as 8%.To achieve this goal  , we surveyed the workload necessary to implement a novel annotator into GERBIL compared to the implementation into previous diverse frameworks. To ensure the practicability and convenience of the GER- BIL framework  , we investigated the effort needed to use GERBIL for the evaluation of novel annotators.In the breadth-of-interest model from Section 3.3.3  , we set the parameter k to 0.3  , i.e. The latter two models were trained on NYT and Quora corpora described in Section 4.We note that the complete example  , including the exemplary queries in an executable form  , is available at http://purl.org/NET/scovo 4—shows the list of high-performing airports along with the time period  , starting with the best airport in terms of " on-timeness " .Quora is a question and answer site where users can ask and answer questions and comment on or vote for existing answers. Quora.Experimental results. We treat BeerAdvocate as a 'development domain'  , because we used it for developing the models and experimental setting  , and RateBeer as a 'test domain' in which we validate our final models on previously unseen data.Multiple LETOR methods have been tried  , which are different in many ways and we expect them to be complimentary during the final fusion. There are also features taken from the query that are independent from documents  , including query length  , the average  , minimum  , maximum of the collection frequencies of the query terms.In this section  , we introduce Quora  , using Stack Overflow as a basis for comparison. Quora is a question and answer site with a fully integrated social network connecting its users.For each mention  , the entity linker provides a distribution over the top fifty most probable entities. The entity mentions detected by Factorie are linked to the knowledge base using our state-of-the-art entity linking system  , KB Bridge 11  , which is trained on the TAC KBP entity linking data from 2009- 2012.By calculating the most used pin source of each user and comparing it with the user's personal website  , available in her description  , we are able to identify self-promoters  , people who use Pinterest to promote their outside webpage. Food Drink and DIY Crafts.However  , copying continues to be important for the creation of native links over which interaction happens  , even in networks like Pinterest  , where copying appears to be governed by norms of social closeness – Fig. Thus  , while there is no universal pattern for how users on different target networks copy links  , it appears that in both cases  , the links  , and hence the target communities  , tend to become more interest-based over time.NPQ is orthogonal to existing approaches for improving the accuracy of LSH  , for example multi-probe LSH 7  , and can be applied alongside these techniques to further improve retrieval performance. Figure 3: 1 LSH PR curve for 22k Labelme 2 LSH AUPRC on 22k Labelme 3 LSH PR curve for CIFAR-10 4 LSH AUPRC for CIFAR-10 5 LSH PR curve for 100k TinyImages 6 LSH AUPRC for 100k TinyImages ment of quantisation thresholds.In GERBIL  , we make use of the D2KB task  , which evaluates entity disambiguation only. To evaluate DoSeR as well as the competitive disambiguation systems we use the GERBIL -General Entity Annotator Benchmark 23  which offers an easy-touse platform for the agile comparison of annotators using multiple data sets.Contrary  , in AOL the temporal component takes over. Many Quora users seem to frequently post replies prompted by others rather than by their personal situation ; hence the lower impact of the temporal component.Segments in curly brackets denote whole URLs that match predefined URL patterns   , such as GitHub URLs as denoted by {github}. The classes and segments are shown in Table 1.Our definition may overly combine repositories  , but we believe it makes context switches more likely to be between distinct entities. Given the ease with which different projects can depend on each other on GitHub  , determining the exact boundaries of a project is difficult.Nevertheless  , all systems benefit similarly from the normalization and it does not produce any change in the official ranking is the performance of our systems on a case-per-case basis. It is probably more practical to do failure analysis and study where the challenges of the task lie and what 7 Note that R  , S and F1R  , S for the two RepLab systems reported are different than the official scores 2  , because we are excluding unrelated tweets from our evaluation  , and we are excluding also near-duplicates as described in 3.1.2012 an in-depth qualitative user study is conducted on a small group of GitHub users  , aimed at understanding the motivations that are the basis of online collaboration and the consequences of using a transparent large-scale tool on the practice of software development . In Dabbish et al.Although none of these sites are represented in the WT2g dataset  , we had to take this possibility into account. Regardless of the topic in question these sites would be ranked highest due to the number of inLinks associated with them.On the other hand  , we found that only 10% of the analyzed GitHub projects implement some form of user authentication . In S2  , we observed that storing and authenticating user login is the most common task needed by participants S2- Obs.1.Based on the results shown in section 5.1 we used the 5 uncorrelated measures Russell-Rao  , Yule  , Forbes  , Simpson and Manhattan for calculating the similarity values. For the user study  , we have randomly chosen 10 query entities from PubChem  , each of them representing one feedback cycle inside the system.In the Shop.com dataset  , however  , we have both the product price information and the quantity that a consumer purchased in each record. We adopt the consumer purchasing records dataset from Shop.com 1 for model evaluation  , because an important information source leveraged in our framework is the quantity of product that a consumer purchased in each transaction   , which is absent in many of the public datasets.In order to avoid clutter  , only a representative subset of baselines is shown  , including the best and the worst of them. Figure 3b compares FITC-Rank with the LETOR base- lines 9 .GitHub is a project-hosting site started in 2008 that brands itself as "Social Coding." In addition  , participants have a profile page that lists personal information as well as activityrelated information such as the repositories they own and watch as well as the participants that they follow.This latter question is a matter of some interest  , as the MAP scores for LETOR 3 approach the 65% considered achievable with human-adjudicated relevance 5. So the meta-learner constitutes the best known method  , and the result raises the lower bound of what is known to be learnable from the dataset.After filtering out locations not appearing in our corpus  , we built a location set consisting of 36 locations  , based on which pair-wise location similarities were computed as describe in Section 2.4.1 to form a location similarity graph. We first collected the top destinations recommended by TripAdvisor 8 for four travel intentions including Beaches & Sun  , Casinos  , History & Culture  , and Skiing.Second  , do super users get more votes  , and do these votes mainly come from their followers ? First  , do user votes have a large impact on the ranking of answers in Quora ?The AIDA annotator as well as the " Illinois Wikifier " will not be available in GERBIL since we restrict ourselves to webservices. 's initial work 7 in 2014  , GERBIL's community effort led to the implementation of overall 6 new annotators as well as the before mentioned generic NIF-based annotator.When the user searches " Peso " as his query  , we could correctly interpret the intent as Philippine Peso instead of Mexico Peso. For example  , when the user types " P " in a search box  , we can accurately suggest query " Peso " or " Philippine Peso " instead of " Pinterest " or " Paypal "   , which are more likely to be suggested by current search engines.Feature examples include TF  , IDF  , LMIR and BM25 considering  , result title  , abstract  , body  , url and pagerank values. The training features are the ones used in LETOR benchmark 2 and are described in 2.We ask whether we can observe evidence for the different roles of social ties in interest-based social networks. To answer this  , we examine the complete activity history of ∼50k randomly selected users on Pinterest .com as a case study.In addition   , we also introduce our failed attempt of using topic models to perform query expansion to capture documents of multiple topics in section 5  , and a brief reflection on why this approach did not work. In the rest of this paper  , we will introduce the general pipeline of our retrieval system in Section 2  , followed by an introduction to novel Language Modelling approaches in Section 3 that were used to generate features  , and later in Section 4 we introduce all other features and the LETOR algorithms.We gathered 1 ,706 such untrustworthy identities. On Pinterest  , we then collected all identities that had liked or repinned two or more to improve the likelihood of discovering untrustworthy identities of the 135 collected pins.Identities with pins that have low reputation URLs: We measure reputation of URLs associated with pins using the Web of Trust WoT 15  website; which computes the reputation of different websites based on various metrics  , and input from the community . For example  , a small fraction 1% of Pinterest identities have a vast majority 65% of their pins blocked  , and these identities are more likely to be untrustworthy.User-Topic Graph: Quora users follow different topics  , and receive updates about questions under topics they follow. 1.This allows for a quick comparison of tools and datasets on recently run experiments without additional computational effort. It is accessible at http://gerbil.aksw.org/gerbil/ experiment ?id=201503050003 visualizations  , 30 see Figure 2 .Second  , having identified the important multitasking and focus switching effectors on programmer productivity  , we proceed to investigate how these dimensions interact  , and which tradeoffs between them exist. First  , we seek a deeper understanding of multitasking and its effects for software developers active on GitHub.ChemXSeer relies on a highly complex process extracting chemical formulas in an automated way out of 150000 RSC publications and links them to the documents 1  , 2. Prime examples are the substance database PubChem 1 combining several chemical entity data sources and the document search engine ChemXSeer 2 .Note that not all questions remain on the site  , as Quora actively deletes spam and redundant questions 5. The largest qid from our crawled questions is 761030  , leading us to estimate that Quora had roughly 760K questions at the time of our crawl  , and our crawl covered roughly 58% of all questions.Table 8shows the results of all of the single-pass retrieval methods on three collections. Table 7: Optimal hyper-parameter on all retrieval methods over both types of verbose queries tuned for MAP on WT2g.The project should include a clear articulation of what is expected from a pull request  , for example tests or localized changes  , on a prominent location in the project's Github page. To avoid development concurrency related issues  , core team members could ask contributors to communicate their indented changes by opening an issue that is then augmented by code and converted to a pull request.Social collecting is the collection  , categorization  , and representation of a digital object in a system that is accessible via the Web. We define a site like Pinterest  , that combines social and collecting capabilities  , as a " social collecting " website.In addition to the work on semantic search engines  , there have been multiple attempts to extend existing SPARQL endpoints with more advanced NLP tooling such as fuzzy string matching and ranking over results 9 ,12 ,15. With Sindice being discontinued in 2014  , no text-based Semantic Web search engine is widely available to the Semantic Web community today.This set of user information includes 95 ,270 unique GitHub user accounts. For this dataset  , we also gathered information about each unique GitHub user associated with the set of pull requests.However  , the sixth kind of interaction  , in which a program written in one language executes another program written in a different language Execution 38  , raises more issues about comprehending  , analyzing  , and evolving programs. The survey of GitHub repositories identified these five kinds of interactions to be the most com- mon 37.The low graph density and average degree indicate that on GitHub the follow action is associated with a high cost  , as following many developers results in receiving many notifications from them. The followers graph G F we obtain has a total of 671 ,751 nodes and 2 ,027 ,564 edges  , with a resulting graph density of 4.4932e-06 and an average degree of 3.019.To do our first experiment  , we took a random 1‰ sample of the PubChem database resulting in around 48.000 chemical entities. Therefore  , we computed for each combination of fingerprint  , chemical entity and top-x the 16 fingerprint based similarity measures resulting in around 88 million similarity values.In calculation of MAP  , we viewed 'definitely' and 'partially relevant' as relevant. Figure 4shows the results on Letor OHSUMED dataset in terms of MAP and NDCG  , averaged over five trials.They concluded that CORI  , and a modified version of the CORI algorithm  , performed reasonably effectively at the server selection task. 5 evaluated CORI  , vGlOSS  , and CVV in a testbed based on the 2GB  , 956 server WT2g crawl of the Web.GERBIL can be used with systems and datasets from any domain. compared more than 15 systems on 20 different datasets.Hence  , while keeping the implementation effort previously required to evaluate on a single dataset  , we allow developers to evaluate on currently  11 times more datasets. The evaluation of our framework by contributors suggests that adding an annotator to  GERBIL demands 1 to 2 hours of work.Each review provides a general rating of the hotel  , plus provides seven individual ratings on the following service characteristics: Value  , Room  , Location  , Cleanliness  , Service  , Check-in  , and Business Service. Hotel service characteristics: We extracted the service characteristics from the reviews from TripAdvisor.This estimate might provide an upper bound of actual number of questions  , and our coverage of 58% would be a lower bound. Note that not all questions remain on the site  , as Quora actively deletes spam and redundant questions 5.Among the dissimilarities  , the following are noteworthy: a Information services/goods and network services have many more parameters other than just price and quantity  , which describe the products and services. Nasdaq.On the DOUBAN network  , the four algorithms achieve comparable influence spread. Here we only give the results under the WIC model.Our study was guided by two research questions. We frame our study in the context of multitasking across GitHub projects  , i.e.  , switching back and forth between multiple projects that one contributes to  , within a short period of time our operationalization below is one week.We conduced 5-fold cross validation experiments  , using the partitions in LETOR. The idea is similar to that of sitemap based relevance propagation 24.This presents us with an unprecedented opportunity to study linguistic change over users' entire lifespans  , from the moment they joined the community—which we define as the time of their first post 2 — to the moment they abandon the community. Over the course of 10 years the BeerAdvocate and RateBeer communities have evolved both in terms of their user base as well as ways in which users review and discuss beer.TS task's queries are one or two sentences long  , which show research demanding of companies or experts. Therefore  , we integrated the professional chemical information from the suggested website ChemID plus 5 and PubChem 6 in our Algorithm 1.The study of long term programming practice evolution can be expanded on a number of fronts. Social coding  , as performed on GitHub  , and cloud computing come to mind  , but other new ways to drive progress surely remain to be discovered.The second question we ask is: how do users distribute their content across categories ? Our target population intentionally contains many avid Pinterest users  , which is reflected in the popularity of the design  , food  , and beauty categories.Additionally  , from the application of SCOVO in voiD we have learned that there is a demand for aggregates. It is for sure possible to concatenate single dimensions used on the scovo:Item-level—for example concluding from the range of the four quarters ex:Q12006 to ex:Q42006 that the dataset actually is referring to the year 2006.However  , these datasets do not include multilingual CH metadata. GERBIL can be used with systems and datasets from any domain.We then ask whether time matters: i.e.  , Do social repins become more important as the user matures and conducts more activities on Pinterest ? However   , the striking result is that across all kinds of information seeking  , whether for the first pins in new boards/categories  , or for subsequent pins  , non-social means of finding information from other users dominate over social repins.As a concession to ease of analysis  , only projects using the popular Maven 4 build system were considered. Projects were taken from Github 15  , one of the largest public repositories of Java projects.It is accessible at http://gerbil.aksw.org/gerbil/ experiment ?id=201503050003 visualizations  , 30 see Figure 2 . Next to individual configurable experiments  , GERBIL offers an overview of recent experiment results belonging to the same experiment and matching type in the form of a Table 5: Results of an example experiment.The first challenge is to identify a set of initial sources that describe the entity sought for by the user. The open source Sindice any23 4 parser is used to extract RDF data from many different formats.Interestingly  , such reappropriation and curation of content discovered by other users termed as " repins "  is by far the most common activity on Pinterest  , constituting about 90% of user actions  , as compared to directly discovering and pinning new images  , which constitutes only 10% of actions 1 . Users on Pinterest can copy images pinned by other users  , and " repin " onto their own pinboards.Our survey comprised five developers with expert-level programming skills in Java. To achieve this goal  , we surveyed the workload necessary to implement a novel annotator into GERBIL compared to the implementation into previous diverse frameworks.Since this paper focuses on the recommendation in ecommerce sites  , we collect a dataset from a typical e-commerce website  , shop.com  , for our experiments. The method is denoted as SV Dmatrix.This phenomenon is the most pronounced on RateBeer Figure 5: Experienced users agree more about their ratings than beginners. One explanation is that the 'best' products tend to be ones that require expertise to enjoy  , while novice users may be unable to appreciate them fully.In contrast  , Stack Overflow anonymizes all voters and only displays the accumulated number of votes  , which can be negative Sorted Topic Bucket By # of Followers Thus in our analysis of Quora  , we only refer to upvotes and disregard downvotes .This cluster contains 43 questions  , and all questions are related to " Quora. " Table 4shows an example of one generated cluster.Additionally  , these datasets contain textual reviews  , which we used to understand and describe the results of our method. The data consists of the IDs of the products/services to be rated as well as the related user IDs who evaluated them with star rating scores from 1 up to 5 at different timesteps in the case of TripAdvisor  , the rating scores range from 0 up to 5.In shop.com dataset  , the short-head 20% involves 0.814% of popular products. The 80:20 rule 7  is commonly used to divide between long-tail products and popular ones.This activity does not require the consent or knowledge of the organization  , and the context of social collecting allows reusing other's materials 3. Second  , Pinterest users can pin an organization's content to their personal pinboards.This means  , for example  , that if the PageRank feature is important for the current query  , there is a good chance it will be important for other queries as well. With LETOR  , in contrast  , features capture general properties of query-document compatibility .Table 1summarizes the performance of all models when different datasets are used. In the same way  , we set latent dimensionality to 30 for Douban data α f = 0.005  , αc = 0.00005  , λ1 = 0.01  , λ2 = 0.0001  , and 35 for Douban music data α f = 0.005  , αc = 0.00005  , λ1 = 0.04  , λ2 = 0.0001.We find that the superior retrieval effectiveness of GRH+NPQ is maintained when the hashcode length is varied between 16-128 bits for both LSH and PCA projections Figure 3a-b on CIFAR-10. Each of these increases are found to be statistically significant using a Wilcoxon signed rank test p-value < 0.01.The user-related contexts include the number of friends  , the number of " wish 6 " issued and the number of ratings provided; the book-related contexts include the number of " wish " received and the number of ratings got. 2 Douban 5 book data 16  , which records 1 ,097 ,148 ratings from 33 ,523 users on 381 ,767 books.To do so  , we test against three publicly available image datasets: 22k Labelme consisting of 22 ,019 images represented as 512 dimensional Gist descriptors 8; CIFAR-10 a dataset of 60 ,000 images represented as 512 dimensional Gist descriptors ; and 100k TinyImages a collection consisting of 100 ,000 images  , represented by 384 dimensional Gist descriptors  , randomly sub-sampled from the original 80 million tiny images dataset. We evaluate the effectiveness of NPQ in the domain of image retrieval  , although our approach is general and can be used for other types of data for example  , text  , video.Figure 15 plots the complementary cumulative distribution function CCDF for both the incoming degree follower and outgoing degree followee. We begin by examining the follower and followee statistics of Quora users.In addition  , we invited developers in the most active threequartiles by total count of days active for the user survey. Note that our definition of project as a collection of repositories owned by the same GitHub user is broader than the definition of project as a main repository together with all its forks  , proposed in the literature 25.Thus  , although over a sixth of Xanga users have provided email addresses  , we cannot use it when trying to match users across networks. Xanga treats email addresses differently: users can provide their email address to Xanga  , and visitors can use the website to send email  , without the address being visible directly.For the purpose of this study we will employ data from two large beer review communities BeerAdvocate and RateBeer. The framework presented in this paper is targeted at large and active online communities  , where individuals interact through written text visible to all members of the community .SCOVO is used in voiD  , the " Vocabulary of Interlinked Datasets " 1  to express information about the number of triples  , resources and so forth. 5kudos to Andreas Langegger for the screen shot  , that generates statistics for datasets behind SPARQL-endpoints and RDF documents.For GitHub we selected the top ranked repositories  , i.e.  , repositories that have been marked as favorites by developers and/or have been forked the most. These repositories span several programming languages: Java  , C  , C++  , JavaScript  , and Python.MAP is then computed by averaging AP over all queries. All presented NDCG  , Precision and MAP results are averaged across the test queries and were obtained using the evaluation script available on the LETOR website.46 found that stakeholders external to the project may influence the evaluation discussions while power plays are in effect. By focusing on how discussions affect contribution evaluation in GitHub  , Tsay et al.To ensure that our sample consisted of repositories that make effective and large-scale use of PRs  , we selected all repositories in the GHTorrent dataset 24 that have received at least one PR per week during the year 2013 3 ,400 repositories. Previous work has revealed that most GitHub repositories are inactive and have a single user 25  , 31 .The second source of information is trade-level data for over 8000 publically traded companies on the NYSE  , AMEX and NASDAQ exchanges. 6 6 We do not consider the many important news stories that appear " after the bell  , " focusing here only on stories for which we have trading data.The Web Data Commons project extracts all Microformat  , Microdata and RDFa data from the Common Crawl Web corpus  , the largest and most up-to-data Web corpus that is currently available to the public  , and provides the extracted data for download in the form of RDF-quads and also in the form of CSV-tables for common entity types e.g.  , products  , organizations  , locations  , etc. The Billion Triple Challenge dataset was crawled based on datasets provided by Falcon-S  , Sindice  , Swoogle  , SWSE  , and Watson using the MultiCrawler/SWSE framework.Over half of Xanga users list some URL under the Webpage category; however on closer examination the URLs listed we saw that a large number do not refer to personal webpages but rather to popular or favorite websites   , e.g. works  , while Blogger users are the most discrete among the three networks: none of the examined Blogger users had listed and made visible their email address under the Email category.Thus our hypothesis is that  , outside of the small portion of celebrities who get followers just by their mere presence  , the majority of Quora users attract followers by contributing a large number of high-quality answers. According to a recent survey of Quora users 31  , they tend to follow users who they consider interesting and knowledgeable .This result confirms that the number of votes is the dominating feature for selecting best answers. We see that for 85% of the questions  , Quora's best answers also ranked the highest in votes  , and for 96% of the questions   , the best answers from Quora are among the top-2 most votes.To analyse users' activities and understand how they accumulate and use social capital  , we first created a dataset by crawling the entire pinning activity history of 50 ,000 users from the time they joined Pinterest until an ar-bitrarily chosen end date of April 1  , 2014. Dataset.The selected features are split into three categories: Pull request characteristics. The feature selection was based on prior work in the areas of patch submission and acceptance 24  , 4  , 32  , 3  , code reviewing 28  , bug triaging 1  , 14  and also on semistructured interviews of Github developers 9  , 26  , 22.For this year's task is based on Billion Triple Challenge 2009 dataset. Also  , they have to be located in the Semantic Web.Douban.com provide a community service  , which is called " Douban Group " . As another result  , Douban.com can also help one to find other users with similar tastes and interests  , so they can get connected and communicate with each other.19 found that when GitHub developers engage in information-seeking behaviors  , they use signals in the environment to form impressions of users and projects. Marlow et al.Awareness can be increased by contacting the development team using real-time communication channels e.g.  , IRC or its evolved counterpart GITTER  , which is better integrated in GitHub or by following the minimal PR idiom 7  depending on project preferences. Maximizing awareness.The negative correlation in the informational setting of NP2003 dataset is due to a heavily skewed distribution of candidate rankers when the production ranker is at a Figure 4: The ROC curves for BARACO and MT  , using DBN for generation and interpretation  , TD2004 dataset  , informational user model LETOR evaluation. These results show that BARACO again outperforms the EM-based method.The top blogs on Xanga from our data include blogs of celebrities  , mostly from Hong Kong MandyStarz  , kellyjackie and stephy tang. The striking differences in the nature of what is most popular on each blogging server gives a sense of the community of the users on each.While AGDISTIS has been in the source code of the BAT-Framework provided by a third-party after publication of Cornolti et al. Table 1compares the implemented annotation systems of GERBIL and the BAT-Framework.The Web Data Commons project extracts all Microformat  , Microdata and RDFa data from the Common Crawl Web corpus and provides the extracted data for download in the form of RDF-quads or CSV-tables for common entity types e.g.  , products  , organizations   , locations  , etc. The Billion Triple Challenge dataset was created based on datasets provided by Falcon-S  , Sindice  , Swoogle  , SWSE  , and Watson using the MultiCrawler/SWSE framework.Some of our respondents also indicated that contributions to GitHub benefit their career growth e.g.  , " My contribution to projects allowed me to obtain a job within my favorite subjects " r437. This incentive increases in strength as the audience's visibility into the performance increases 33.While developing GERBIL  , we spotted several flaws in the formal model underlying previous benchmarking frameworks which we aim to tackle in the future. More information about GERBIL and its source code can be found at the project's website.A publicly available dataset periodically released by Stack Overflow  , and a dataset crawled  from Quora that contains multiple groups of data on users  , questions   , topics and votes. Our analysis relies on two key datasets.Rare exceptions like the new Ask.com has a feature to erase the past searches.The task is to link users' pins posted on the social media site Pinterest .com given by their textual description to a set of relevant webshops where the user might search for or buy the " pinned " product. To evaluate the utility of the new multi-idiomatic topic model  , we perform the same retrieval task as proposed in 7.The intensity of color in Figure 11captures the number of users with a given set of similarity scores. Conversely  , a user at position 1 ,1 in the Pinterest plot would have 1 exact similarity between the LIWC of their own pins and tweets  , and 2 exact similarity between the LIWC of their pins and the pins of other Pinterest users.To allow semantic search engines to efficiently and effectively process the dataset it is advisable to use proper announcement mechanisms such as the semantic crawler sitemap extension protocol 8. For example offering an RDF dump in N-Triples for semantic search engines such as Sindice 26 along a SPARQL-endpoint for cross-site query is a typical pattern.By this approach we conclude that roughly two in each ten users who have a webpage linked in their profiles are in fact selfpromoters   , and the proportion of males in this situation is higher than females. By calculating the most used pin source of each user and comparing it with the user's personal website  , available in her description  , we are able to identify self-promoters  , people who use Pinterest to promote their outside webpage.As shown in Figure 2  , the documents selected by the two methods also exhibit very high similarity to each other. Both hedge and LETOR-like document selection methodology   , by design  , select as many relevant documents as possible .We also considered the barriers that make it difficult for new contributors to participate. Subsequently  , we were interested in understanding the challenges that contributors experience when working with the pull-based model in GitHub.Being a web-based platform it can be also used to publish the disambiguation results. 29  proposed GERBIL - General Entity Annotator Benchmark  , an easy-to-use platform for the agile comparison of annotators using multiple data sets and uniform measuring approaches.All the rest are long-tail prod- ucts. In shop.com dataset  , the short-head 20% involves 0.814% of popular products.We also see a noticeably high number of potentially duplicated profiles across sites  , sometimes due to setting up multiple blogs one for family  , one for friends  , perhaps due to wanting to " start over " afresh. This is most common on Xanga which has the youngest users.Attracting participants. We sent them an email if their address was registered with GitHub and if they were not integrators in the same repository; we collected 4 ,617 emails.Thus  , we decided to index a particular dataset for stable and comparative evaluations. However  , Sindice search results may change due to dynamic indexing.We imported the Shapefiles into a PostGIS database and created virtual geospatial RDF views on top of them using Ontop-spatial  , as described at https://github. However  , it was more convenient for us to download the most up-todate original OpenStreetMap data about Bremen  , available as Shapefiles 10 .Pinterest is a photo sharing website that allows users to store and categorise images. 4 This setting has been changed in April 2013.Each of the images in the datasets are thus implicitly labeled by users with one of the 32 categories. We recall that a Pinterest user may have several different pinboards each assigned to one of 32 globally defined categories.We choose the top 20 hotels in Amish Country  , Lancaster County  , PA from Hotels.com and TripAdvisor. Case study: Finding hotels in Amish Country.Secondly  , in the Douban friend community  , we obtain totally different trends. 2.The category Microsoft has a homonymous page  , categorized under Companies listed on NASDAQ which has the head lemma companies. An example is provided in Figure 2.They find that people use GitHub for several reasons: to learn how to code better  , to follow popular developers   , to find new interesting projects  , and to promote themselves and their work. 2012 an in-depth qualitative user study is conducted on a small group of GitHub users  , aimed at understanding the motivations that are the basis of online collaboration and the consequences of using a transparent large-scale tool on the practice of software development .We call social links created in this way native links. The social graph of Pinterest is created through users following other users or boards they find interesting.§3 gives a brief background of Pinterest and our dataset. §2 presents related work.We use the 5-fold cross validation partitioning from LETOR 10. The optimal parameters for the final GBRT model are picked using cross validation for each data set.All these systems have the aim of collecting and indexing ontologies from the web and providing  , based on keywords or other inputs  , efficient mechanisms to retrieve ontologies and semantic data. Most of the research work related to the ontology search task concerns the development of SWSE systems 7  , including: Watson 8  , Sindice 28  , Swoogle 11  , OntoSelect 4  , ontokhoj 5 and OntoSearch 32.One very important issue is what we call " statisticalpresentation fidelity " . Further  , our ongoing work focuses on broadening the deployment base available 17   , making converters from and to SCOVO available  , and extending the framework itself.We first collected the top destinations recommended by TripAdvisor 8 for four travel intentions including Beaches & Sun  , Casinos  , History & Culture  , and Skiing. Comparing the two graphs in Figure  6a andTable 11shows the accuracy of FACTO. The result pages of Ask.com with fact answers can be accessed at http://lepton.research.microsoft.com/facto/doc/ask_answer.zip.We see in prior work about GitHub that there are certain contribution norms that signal a technically well-prepared contribution. H1: Contributions that show signs of following technical contribution norms are more likely to be accepted.Each row in the table corresponds to one bug report and one debugging scenario. Each bug reporter has spent time manually creating these Table 1identify the selected subject programs and their associated bug reports all taken from GitHub.The participants where selected from the community of Semantic Web SW developers on Github who have had at least one active SW-related repository. In order to understand the current pitfalls of LDA UI design  , we conducted a survey targeting active Semantic Web developers 2 .For comparative purposes  , considering that the Microsoft and LETOR datasets were designed for a folded cross-validation procedure  , we applied this same strategy to the YA- HOO! Similarly to the WEB10K benchmark  , these datasets are partitioned into 5 folds to be used in a folded cross-validation procedure.We have tried using Support Vector Regression RankSVM with linear kernel for pairwise LETOR  , and were trained on a set of error pairs collected using the " web2013 " relevance judgments file. Our intuition is that rank lists generated by point-wise methods are better at the top potions  , but the precision drops quickly if we go further down the list  , as they are prone to over-fit to certain features that are most dominating.We developed a Ruby script to automatically clone each repository in the resulting list  , check that it contains a Rails application  , install its dependencies  , and run the application. We used the Github Archive database 4 to make a list of the most-watched Rails-associated repositories.Thus it is important to understand how social ties affect Q&A activities. Quora is unique because it integrates an effective social network shown above into a tradition Q&A site.We observe similar trends in Quora. 60% of Stack Overflow users did not post any questions or answers  , while less than 1% of active users post more than 1000 questions or answers.We have found evidence for such positive effects of knowledge transfers on productivity past experience with a programming language during prior work on GitHub 10. Similarly  , exposure to more projects brings about exposure to different environments   , providing opportunities to develop transferrable skills.In 2012  , we consolidated the set Bio2RDF open source 5 scripts into a single GitHub repository bio2rdf-scripts 6 . Thirty PHP scripts  , one Java program and a Ruby gem are now available for any use including commercial   , modification and redistribution by anyone wishing to generate BioRDF data  , or to improve the quality of RDF conversions currently used in Bio2RDF.An exception was BROOF gradient which converged at about 100 iterations for the largest datasets. On average  , our strategies converge at about 15 iterations on the LETOR datasets  , and around 5 to 10 iterations on the multi-relevance judgment datasets.Empty query results are indicators for missing in-links. We estimate the number of in-links by iterating over all elements in AC and querying the Sindice 9 SPARQL endpoint for triples containing the concept's URI in the object part.For our experiments we work with three public data sets: TD2004 and MQ2007 from LETOR data sets 24 and the recently published MSLR-WEB10K data set from Microsoft Research 1. All three data sets are pre–folded and come with evaluation scripts that allow fair comparison of different ranking algorithms.Semantic search engines  , such as Sindice 14 and Swoogle 5  , or index sites for the Semantic Web 4 are good starting points to search for existing vocabularies. There already exist a number of widely used vocabularies  , many of which are applicable for desktop data.One option is to extract all lexical information from the URI  , labels  , properties and property values of the LOD resources that are retrieved by Sindice search. To achieve this  , the concepts of LOD resources should be understood  , where lexical information about LOD resources can be used to mine such knowledge.Even in cases where there is a document  , an evaluation based on document rankings is not able to measure some of the key advantages of semantic search such as being able to give precise answers to factual questions or that answers can be computed by aggregating knowledge from different documents. This is the case for example with search engines that crawl and index Linked Data such as Sindice 19.The goal of our workflow is to generate enriched index pages for all documents within the collection. The most comprehensive open access database for the area of chemistry is PubChem 14 .By positioning good answers at the top of the questions page  , Quora allows users to focus on valuable content. Quora applies a voting system that leverages crowdsourced efforts to promote good answers.The largest qid from our crawled questions is 761030  , leading us to estimate that Quora had roughly 760K questions at the time of our crawl  , and our crawl covered roughly 58% of all questions. The result   , discussed below  , provides further support that this qid can be used as an estimate of total questions in the system.More information about GERBIL and its source code can be found at the project's website. In comparison to earlier frameworks  , it extends the stateof-the-art benchmarks by the capability of considering the influence of NIL attributes and the ability of dealing with data sets and annotators that link to different knowledge bases.To our knowledge  , no research paper focused on user behavior  , based on gender  , was conducted in a heavy image-based network such as Pinterest. Most existing works focus in popular social networks where direct interactions and textual communication are of paramount importance.We validate TermPicker's recommendation quality by performing one evaluation on the DyLDO 21 9 dataset and a second evaluation on the Billion Triple Challenge BTC 2014 dataset 22 10 crawl no. in the following way: the first two recommendations are irrelevant  , and the first relevant recommendation is at the third rank of the result list.GERBIL is not just a new framework wrapping existing technology. The persistent URIs enhance the long term quotation in the field of information extraction.Although we felt that the 100GB collection would be more useful as a research tool  , we didn't have the storage capacity available to handle such a large dataset at that time. Our approach was based on using the WT2g dataset  , consisting of 247 ,491 HTML documents at 2GB storage requirements.However  , bias in the contributors' answers could not be completely eradicated  , as can be witnessed by the fact that many open-ended answers included direct references to GitHub or tools in its ecosystem e.g.  , Travis CI. In both our question set and our interpretation of the results  , we avoided direct references to GitHub's implementation of the mechanism.We assume that a vast majority of the random Pinterest identities are indeed trustworthy  , and hence  , we do not consider all identities that posted a single blocked pin to be untrustworthy. There are 724 ,672 Pinterest identities with at least one blocked pin  , which includes 43% of all Pinterest identities.Figure 3below shows the precision at 5 -1000 documents returned from running the modified queries on WT2g. We hope that the 10GB dataset next year will contain a higher percentage of Functional links.This yields to complex SPARQL expressions  , as it will often require a verbose check to make sure that an item has only certain dimensions and no others. Using SCOVO in voiD allows a simple and extendable description of statistical information  , however  , a shortcoming has been identified: as scovo:Items are grouped into scovo:Datasets  , there is an implicit assumption that all items in such a dataset share the same dimensions.Our goal is set to design a system as simple as possible  , without using any external processing engine or resources  , other than the standard Indri toolkit and a third party LETOR toolkit. How to optimize towards diversity under the context LETOR is yet another problem to be studied in future.Hotel service characteristics: We extracted the service characteristics from the reviews from TripAdvisor. We extracted these characteristics within an area of 0.25-mile  , 0.5 mile  , 1-mile  , and 2-mile radius.Before diving into main analytical results of our work  , we begin in this section by first describing our data gathering methodology and presenting some preliminary results. We also analyze some high level metrics of the Quora data  , while using Stack Overflow as a baseline for comparison.iii Ground truth information about untrustworthy identities in Pinterest   , which enables us to evaluate how well we can reason about trustworthiness of identities in the target domain. We leverage these signals to reason about the trustworthiness of the matching identities in Pinterest.Because only the most popular tags are listed for the books in DouBan  , we obtained merely 135 distinct tags. Meanwhile  , we collected tags and brief introductions from DouBan in order to evaluate the coverage performance of our system.RQ1 To assess the popularity of the pull-based development model  , we provide and analyze descriptive statistics on the use of pull requests in Github. Below  , we present how we approached each research question.Maximizing awareness. In the case of GitHub  , external services are available to enable continuous integration e.g.  , Travis and code quality e.g.  , Code Climate monitoring on a per contribution basis.The features of Letor TD2003 and TD2004 datasets include low-level features such as term frequency tf  , inverse document frequency idf  , and document length dl  , as well as high-level features such as BM25  , LMIR  , PageRank  , and HITS. Each query document pair is given a binary judgment: relevant or irrelevant.With GERBIL  , we aim to push annotation system developers to better quality and wider use of their frameworks. In this paper  , we presented and evaluated GERBIL  , a platform for the evaluation of annotation frameworks.Services already exist to support the backup of Pinterest boards  , tweets and blogs  , and this can take advantage of the curation that has already occurred online. Collections of other-generated content are vulnerable to loss  , and so implications chiefly relate to supporting their backup.Each user can provide ratings ranging from one star to five stars to books  , movies and music  , indicating his/her preference on the item. Douban 7 is one of the largest Chinese social platforms for sharing reviews and recommendations for books  , movies and music.Through Github facilities. The versatility of Git enables pull requests to be merged in three ways  , presented below sorted by the amount of preservation of the original source code properties: 1.pins for majority to appear Figure 2: Emergence of consensus in Pinterest: a The category chosen by the ith pinner is independent of the category chosen by the previous i − 1 pinners  , and is the same as the category chosen by the majority of repinners with a remarkably high probability ≈0.75. a Probability of majority pin b Levels of agreement in categories c No.We also find statistically significant gains in performance on the larger CIFAR-10 and 100k TinyImages datasets. This result is statistically significant based upon a paired t-test across 10 random training/testing partitions of the dataset p-value: ≤ 1.7 × 10 −5 .2 For use with the graphs described above  , the weights in the initialization vector u are the click frequencies of the corresponding documents in the session under examination  , that is  , We used a custom implementation of the algorithm  , available on GitHub.This step is necessary in order to make pins and tweets directly comparable: on Pinterest  , all pins fall into 1 of 33 pre-defined categories  , while tweets are freeform text. The next step in our methodology is to classify tweets from our target users with category labels.worked on snippet generation for a semantic search engine Sindice that indexes instance data 2. In a Web search setting  , Bai et al.Since " Illinois Wikifier " is currently only available as local binary and GERBIL is solely based on webservices we excluded it from GER- BIL for the sake of comparability and server load. The authors provide their datasets 9 as well as their software " Illinois Wikifier " 10 online.We also tried different strategies to normalize our feature vectors  , including L2-norm  , z-score and the LETOR normalization procedure 17  , with no improvements. Using cross-validation in V  , we also varied cost j between 10 −3 and 10 3   , finding that the best choice was j=100  , in most cases.Downvotes are processed and only contribute to determining the order answers appear in. Quora makes visible the list of upvoters  , but hides downvoters.PhantomJS is a headless version of the WebKit browser engine that can be automated using Javascript. The Pinterest website is a complex Javascript application  , so we leveraged PhantomJS to crawl the site.First  , the consolidation of scripts into a single GitHub repository will make it easier for the community to report problems  , contribute code fixes  , or contribute new scripts to add more data into the Bio2RDF network of linked data for the life sciences. Bio2RDF Release 2 marks several important milestones for the open source Bio2RDF project.Exactly how existing systems extract keywords from RDF data is largely undocumented. Falcons  , Semplore  , SWSE and Sindice search for schema and data alike.To answer this  , we examine the complete activity history of ∼50k randomly selected users on Pinterest .com as a case study. In light of these conflicting results  , it is natural to ask what is the value of social networks on interest-based and contentdriven sites.Thus  , we choose a 60 day period from 01/01/2009 to 03/01/2009 for our experiments. In TripAdvisor   , t win is about 60 days.For instance  , on Pinterest  , perhaps the most prominent content curation site  , users can collect and categorise images and the URLs of the webpages that contain them by " pinning " them onto so-called " pinboards " . Following on the heels of the information glut created by the user-generated content revolution  , an interesting new phenomenon that has been termed content curation has emerged: Rather than create new content  , content curation involves categorising and organising collections of content created by others.We used a custom implementation of the algorithm  , available on GitHub. For all of our experiments  , we used a restart factor of c = 0.2  , a convergence distance of = 0.005  , and a max iteration cap of ρ = 1000.In Ranking SVM plus relation  , we make use of both content information and relation information. Actually  , the results of Ranking SVM are already provided in LETOR.For each supported type  , swim extracts structured call sequences from the source files in the code corpus. This is because for most classes T in the API framework  , GitHub contains many more usage samples than can be extracted from web pages.First  , we ask what proportion of a user's reciprocated and directed unreciprocated links have incurred repins. We examine how the social repin network selectively samples the underlying network of Pinterest.Because of this UI design decision in Pinterest  , we expect that a user's choice of the Pinterest category to associate with a pin is made independently of other users or the system itself. Even the owner of the board is only shown the category on the page for editing a board's details not normally seen when the owner views her board.We examine the relation between the length of a sequence and the duration measured by the number of events that the sequence spends at each stage. The length of sequence can be of great interest in many datasets; for example  , it represents how actively a user enters reviews on BeerAdvocate and RateBeer  , how popular a phrase is in NIFTY  , or the skill of a player on Wikispeedia.In the context of sub-question 3  , we will perform various crowdsourcing tasks e.g. The " Open Knowledge Extraction " challenge at ESWC 7 and frameworks such as GERBIL 28 are good systems to validate our approach.2013; Zhong  , Karamshuk  , and Sastry 2015  have found that creating new pins or repins  is by far the most common activity on Pinterest  , and presents a quintessential information seeking activity. Previous studies Zhong et al.A distributed development workflow is effective if pull requests are eventually accepted  , and it is efficient if the time this takes is as short as possible. Moreover  , the review mechanism that Github incorporates has the additional effect of improving awareness 9 ; core developers can access in an efficient way all information that relates to a pull request and solicit opinions of the community  " crowd-source "  about the merging de- cision.Even if it is not possible to provide definitive evidence about that  , in the following we will show some interesting correlations between the activity of a user and some indirect rewards in terms of " social prestige " in GitHub. We hypothesize that for a hybrid service like GitHub  , both a social network and a collaboration network  , some kind of indirect reward mechanism might and potentially underpin user activity.Such non-social repins are not hard to find: Pinterest highlights the most recent pins on the platform on its home page. Thus  , given access to the homepage which proves to be a simple and easy to find source of interesting information  , social-based information seeking becomes less critical.It turned out that ruling out terms Figure 1 : MAP and P@10 for short queries at different pruning levels  , baseline and different settings WT2g collection   , as those terms have a negative score for every document.Since the majority of Quora profiles contain hundreds of posts  , to ensure that proper care is given to evaluating them  , we collected the judgements employing 19 students from our institutions. To evaluate the AOL and Health Q&A datasets  , we employed AMT master workers from the USA and collected 5 judgements for each of the profiles.We also confirmed our overall result by studying entire evolutionary history of all the projects  , analyzed with 6 months snapshot interval. To minimize this threat  , we use systems from different domain from Github and Apache  , having a substantial variation in age  , size and ratio of bugs to overall lines see table 1.As a " silver standard " for evaluating suite quality  , mutation testing is used  , as identifying real faults of hundreds of Java projects was clearly infeasible. While the results are based only on open source Java programs hosted on Github  , and using the popular Maven build system  , it is likely that our findings apply at minimum to many other Java projects  , and may well apply to other languages as well.For each query and document  , we extract about three hundred of features in the experiment  , where the features are similar to those defined in LETOR16. We follow the RankNet 5 method which is a pairwise ranking algorithm receiving the pairwise preferences to optimize the ranking function.To accurately establish this mapping  , we employ the emerging social services such as About.me 3 and Quora 4   , where they encourage users to explicitly list their multiple social accounts on one profile. To represent the same users with multiple sources  , we need to first tackle the problem of " Social Account Mapping "   , which aims to align the same users across different social networks by linking their multiple social accounts 1.Section 6 summarizes related work. Section 5 evaluates SERT with application benchmarks from Ask.com.From the pull requests that have been opened in 2013  , 73 ,07% have been merged using Github facilities  , thereby indicating that pull requests in principle can work as a means for obtaining external contributions. Projects exists   , such as Ruby on Rails and the Homebrew package manager  , that have more that 5 ,000 pull requests.Github automatically detects conflicting pull requests and marks them as such. Merging such a pull request will result in conflicts.Our selection of projects and contributors to GitHub projects using the pull-based model may not be indicative of the average project. Generalizability – Transferability.Construct: Are we asking the right questions ? Also  , the infrastructure we used for the analysis is available open source as a GitHub repository 5.As an example  , the popular Semantic Web search engine Sindice 8 is practically unusable for people without a deep understanding of semantic technologies. The majority of current tools are not aimed at non-expert users.We run a 10-fold crossvalidation on this sample. We start by building a pairwise classification model using linear kernel SVM 4 20 We randomly sample 80 ,000 pairs of tweets from the RepLab 2013 training dataset  , keeping the true and false classes balanced.Both hedge and LETOR-like document selection methodology   , by design  , select as many relevant documents as possible . Furthermore   , when relevant and non-relevant documents in the training data set are very similar to each other  , performance of the resulting ranking functions decline.ask.com before query " Ask Jeeves " . However  , the vlHMM notices that the user input query " ask.com " and clicked www.We then examine 291 carefully selected Ruby  , Python  , Java and Scala projects in total  , 166 ,884 pull requests  , and identify  , using qualitative and quantitative analysis  , the factors that affect pull request lifetime  , merging and rejection. Using it  , we first explore the use of almost 2 million pull requests across all projects in Github.This potential participant can then request that code changes in their personal copy be merged into the project's main repository. GitHub allows potential project contributors to "fork" or make a personal copy of any public project where they can make changes to  , add  , or alter functionality  , without disturbing the code in the original branch.We also showed an application of the proposed method in an online ad serving system for matching and ranking ads for a given Web page which indicates the applicability of the proposed algorithm in real online applications as we improved the CTR and RPM significantly in the online bucket tests. Our experiments on LETOR 3.0 benchmark dataset show that the  NDCG-Annealing algorithm outperforms the state-of-theart algorithms both in terms of performance and stability.Results of the experiments run on the Gerbil platform are shown in Table 2. All these methods are tested in the setting where a fixed set of mentions is given as input  , without requiring the mention detection step.This is because Quora recommends topics during the sign-up process. First  , the large majority 95% of users have followed at least 1 topic.29  proposed GERBIL - General Entity Annotator Benchmark  , an easy-to-use platform for the agile comparison of annotators using multiple data sets and uniform measuring approaches. To avoid this problem  , the authors of Uzbeck et al.Pinterest's users comprise mainly young people  , the well-educated  , those with higher income  , and women. According to a 2012 survey by the Pew Research Center   , Pinterest has attracted 15% of internet users to its virtual scrapbooking.Subsets of documents are chosen according to the six methods at different percentages of the complete document collection in our case the depth-100 pool  , and features are extracted from the selected query-document pairs. We employ five different document selection methodologies that are well studied in the context of evaluation  , along with the method used in LETOR for comparison purposes.To study this  , we first compare social vs. non-social means of acquiring new infor- mation. Therefore  , we might expect that the ability of social networks to provide access to new informationwould be important on Pinterest.We used Github APIs to search 3 for SW repositories and to collect contact information for the corresponding contributors when available. Github is currently the most popular repository for open source code and its transparent environment implies a suitable basis for evaluating reuse and collaboration among developers 21.The two key issues which arise in the context of crowdsourcing are quality— is the obtained solution or set of contributions of high quality ?— as well as participation— there is a nonzero effort or cost associated with making a contribution of any quality in a crowdsourcing environment which can be avoided by simply choosing to not participate  , and indeed many sites have too little content . Answers  , Stack- Overflow or Quora.For these reasons  , we used GitHub in our recruiting efforts. GitHub is also a popular code hosting site with a large user base that could provide a relatively diverse pool of potential participants.We conducted 5-fold cross validation experiments  , following the guideline of Letor. In total  , there are 44 features.We used synonyms from PubChem for chemicals that have been identified  , used simple entity recognition to extract information that is later used to increment or decrement weights of some terms and to filter out documents from the ranked list. of patents and documents in a weighted way.Thus  , for each theme  , sentences have a representation that depends on the theme while the associated relevance judgment depends on the topic in hand. By extracting a generic query for each theme defined as the most frequent terms of that theme  , we then characterize sentences in the latter by taking 12 features used in the Letor datasets 6 as well as a feature produced by a bigram language model proposed in the top performing system at DUC 2006 4.The document collection is a subset of MEDLINE  , a database on medical publications. The OHSUMED data set in LETOR has been derived from the OHSUMED benchmark data 16 for information retrieval research.We have implemented a URI-Key Generator  , more than one CDX Profiler  , and a script to merge profiles and published the code on GitHub 3 . The latter approaches involve more steps and setup  , but scale well.The contrasting associations between popular projects and collaborators may indicate that audience pressure is a factor when project managers evaluate pull requests. Number of stars  , our proxy for project popularity  , is used by members of the GitHub community as a signal for project quality  , which project managers are aware of 5.For popular projects  , the transparent nature of GitHub means project managers are aware  , at least in part  , of the identity of users of their project 5. The contrasting associations between popular projects and collaborators may indicate that audience pressure is a factor when project managers evaluate pull requests.After creating the data files  , we investigated projects where the pull request merge ratio was significantly less than the one we calculated across Github 73%  , and in any case less than 40%  , as this means that our heuristics are not good enough for this project. If none of the above heuristics identifies a merge  , we mark the pull request as unmerged.By these means  , we allow benchmarking tools against reference datasets from any domain grounded in any reference knowledge base.  With GERBIL we introduce the notion of knowledge base-agnostic benchmarking of entity annotation systems through generalized experiment types.We are surprised to find that the curves from Stack Overflow and Quora are nearly identical. Next  , we plot the distribution of views and answers per question in Figure 5and Figure 6.In total  , 1 ,000 ,000 collaborative GitHub projects i.e.  , 45% of all collaborative projects used at least one pull request during their lifetime. As Figure 1 shows  , its popularity is constantly growing; in January 2016  , 135 ,000 repositories on the GitHub social coding site received more than 600 ,000 pull requests.Our dataset is derived from a previous study 38  , and includes nearly all activities on Pinterest between Jan 3–21 2013. Dataset.We collected 250 attractions in Paris from the TripAdvisor website . The second dataset is used to generate the second feature representation described in Section 4.1.2.We ran the exposure generation step only on the 1000 most-watched Rails applications on Github. Since exposure generation time dominates verification time  , we performed an additional experiment to test the scalability of the exposure generator more thoroughly.Accordingly   , let IDCGp be the maximum possible discounted cumulative gain for a given query. We chose to standardize this issue  , using the same criterion used by most evaluation tools  , e.g.  , those available for the Letor 3.0 and 4.0 and Microsoft datasets  , in order to allow fairer comparisons.The result pages of Ask.com with fact answers can be accessed at http://lepton.research.microsoft.com/facto/doc/ask_answer.zip. For example  , for query {raven symone gives birth} it answers " Raven-Symoné is not and has never been pregnant according to reports "   , which shows it knows what has not happened besides what has.However  , the absolute number indicates that semantic representations are not yet common in today'line in Figure 2cloud. Since the growth of documents in Sindice was closely related to upgrades in their technical infrastructure in the past  , we cannot reliably use their growth rate.These contributions may be less technically sound  , more complicated to evaluate  , or simply controversial in terms of project direction or implementation strategy. Changes that required high amounts of discussion tend to be more closely scrutinized by more members of the site  , as GitHub users would look at discussion on a contribution as a signal of controversy.Both other approaches are not capable of representing historical data and only provide statistics for one point-in-time. The most distinguishing feature of SCOVO is the ability to express complex statistics over time while still keeping the structural complexity very low.On all evaluation metrics the ranking perceptron achieves scores comparable to SVM on the OHSUMED and TD2003 datasets  , and comparable to RankBoost on TD2004. However  , to get an estimate for the accuracy of the methods we implemented  , we evaluated the ranking perceptron see Section 3  , on the Letor dataset 21.The URLs used in the experiment  , source code and response headers of all requests are available at https://github. Another important finding is that response patterns vary for different topics – sensitive topics result in a larger number of 403 forbidden responses.While it is public knowledge that Quora differs from its competitors in its use of social networks and real identities  , few additional details or quantitative measures are known about its operations. This is a difficult question to answer  , given Quora's own lack of transparency on its inner workings.For example in Ask.com search site  , some uncached requests may take over one second but such a query will be answered quickly next time from a result cache. meet the soft deadline.We utilized a GitHub dataset collected during prior work that contains information on prolific developers with a long and active contribution history 10. Prolific Developers.This discrepancy could be due to the domain of the projects analyzed. On the other hand  , we found that only 10% of the analyzed GitHub projects implement some form of user authentication .Images added on Pinterest are termed pins and can be created in two ways. Pinterest is a photo sharing website that allows users to store and categorise images.Examples include Pinterest boards  , blogs  , and even collections of tweets. A second category refers to content that primarily exists and is curated online.After filtering by Syntactic Filter  , this collection contained 10 authors  , 48 books  , 757 reviews and 13 ,606 distinct words. Without existing benchmark dataset  , we used Review Spider to collect reviews from a Chinese website DouBan to form our experiment dataset.To achieve this  , the concepts of LOD resources should be understood  , where lexical information about LOD resources can be used to mine such knowledge. In order to generate concept-based search results  , first the retrieved LOD resources from the Sindice search need to be categorized under UMBEL concepts.Elastic Block Storage EBS volumes of 350G were allocated for each compute instance to accommodate the size of the index and the need to insure persistence of the database if a compute instance was restarted. Each database shard included a dimensional data model for its portion of the collection  , and a dimensional index of PubChem 8 terminology for synonym identification.In comparison to earlier frameworks  , it extends the stateof-the-art benchmarks by the capability of considering the influence of NIL attributes and the ability of dealing with data sets and annotators that link to different knowledge bases. GERBIL is not just a new framework wrapping existing technology.We computed Fleiss' Kappa to quantify the global interannotator agreement across all the topics. Since the majority of Quora profiles contain hundreds of posts  , to ensure that proper care is given to evaluating them  , we collected the judgements employing 19 students from our institutions.Falcons  , Semplore  , SWSE and Sindice search for schema and data alike. Hermes performs keyword-based matching and ranking for schema resources such as classes and object properties.We first fix the iteration number to 10  , and show MAE and RMSE with varying dimensionality of latent factor vector see Fig.2SoReg is slightly better than RPMF indicates that carefully processed social network information contributes more to a recommendation model at least on the Douban dataset. Before comparison  , we determine two important parameters  , i.e.  , latent factor vector dimensionality and the number of iterations for matrix factorization based models.The Billion Triple Challenge dataset was crawled based on datasets provided by Falcon-S  , Sindice  , Swoogle  , SWSE  , and Watson using the MultiCrawler/SWSE framework. They represent two very different kinds of RDF data.To ensure that the sample was as unbiased as possible  , the user IDs were randomly sampled from a near complete snapshot of the Pinterest social network collected and provided by Zhong et al. To analyse users' activities and understand how they accumulate and use social capital  , we first created a dataset by crawling the entire pinning activity history of 50 ,000 users from the time they joined Pinterest until an ar-bitrarily chosen end date of April 1  , 2014.This approach was introduced in 25 in 2008 and is based on different facts like prior probabilities  , context relatedness and quality  , which are then combined and tuned using a classifier. 7 They provide the source code for their approach as well as a webservice 8 which is available in GERBIL.According to a recent survey of Quora users 31  , they tend to follow users who they consider interesting and knowledgeable . To understand how Quora's social network functions  , a basic question of interest is how users choose their followees.We bootstrapped this system by transferring the learned model from TAC KBP 2010 thereby circumventing the need for training examples. We use a scalable and highly flexible system  , Elementary to perform relation extraction.For AIDA we downloaded the default entity repository that is suggested as reference for comparison. Spotlight and WAT are integrated in GERBIL by default  , whereas we manually downloaded Wikifier and AIDA and installed them on our server with its best settings.For instance  , even with Pinterest restrictions for social communication  , we show that such communication still happens in the form of lightweight interactions such as likes and repins. In this study we report significant findings.In particular  , we use Sindice search for querying the WoD and Sindice Cache for retrieving RDF descriptions of LOD resources 2. Given that indexing and caching of WoD is very expensive  , our approach is based on existing 3 rd party serives.According to this methodology  , documents in the complete collection are first ranked by their BM25 scores for each query and the top-k documents are then selected for feature extraction.  LETOR: For comparison purposes  , a LETOR-like document selection methodology is also employed.For datasets  , we used MQ2007 and MQ2008  , a collection of benchmarks released in 2009 by Microsoft Research Asia research.microsoft.com/en-us/um/beijing/projects/letor/. The depth of the complete solution is d = 8.As a result  , the NDCG-Annealing algorithm is more stable and pronounced compared to the baselines in LETOR 3.0 dataset. We also see from Figure 4 that our NDCG-Annealing algorithm outperforms all the other baseline algorithms on this dataset.However  , not all those projects are active: in the period Feb 2012 — Aug 2013  , the GHTorrent dataset captured events initiated by approximately 2 ,281 ,000 users affecting 4 ,887 ,500 repositories. As of August 2013  , Github reports more than 7 million repositories and 4 million users.Douban is a Chinese Web 2.0 Web site providing user rating   , review and recommendation services for movies  , books and music. We use the Douban 3 dataset in this subsection since in addition to the user-item rating matrix  , it also contains a social friend network between users.The questionnaires and the script for the semi-structured interviews are available in a technical report 16. The final set of themes that emerged informed the third phase of our research: a validation survey sent to 10 ,000 GitHub users  , receiving over 1 ,200 responses.For example offering an RDF dump in N-Triples for semantic search engines such as Sindice 26 along a SPARQL-endpoint for cross-site query is a typical pattern. Note that in practice very often the approaches listed above are used in combination.Pinterest incorporates social networking features to allow users to connect with other users with similar interests. Most of pinboards are associated with one of 32 categories such as 'Design'  , 'Products'  , 'Home Decor'  , 'Animals and Pets'  , etc.  , which are globally recognised on Pinterest.Note that  , this pre-defined hard categorization can also be used to improve ranking by applying the same method in Section 3.3. The statistics of queries for three categories in LETOR 3.0 can be found in 16.This paper also contributes to image analysis and understanding. 20  , who propose a model for recommending boards to Pinterest users.We randomly sample a subset of CIFAR-10 with 5000 points for evaluation. To get a deeper comparison  , we perform another experiment on smaller datasets where the full supervised information can be used for training.The results of the state-ofthe-art algorithms are provided in the LETOR 3.0. In LETOR 3.0 package  , each dataset is partitioned into five for five-fold cross validation and each fold includes training   , testing and validation sets.Applications of social influence in social media. We adapt the E-M algorithm of Saito  , Nakano  , and Kimura 2008 to extract social influence in TripAdvisor  , and use it as input to our participation maximization algorithm.1 We obtained 1 ,212 ,153 threads from TripAdvisor forum 6 ; 2 We obtained 86 ,772 threads from LonelyPlanet forum 7 ; 3 We obtained 25 ,298 threads from BootsnAll Network 8 . We selected three forums of different scales to obtain source data.We now turn to the experiments on the Topic Detection Task. Although the absolute performance of the best learned function seems low 0.63 accuracy  , we will see in the following sections that  , once the classification confidence is used as similarity measure  , it leads to the best topic detection performance reported on the RepLab dataset so far.The final set of themes that emerged informed the third phase of our research: a validation survey sent to 10 ,000 GitHub users  , receiving over 1 ,200 responses. We then employed axial coding  , iterating through our exploratory survey responses and interview transcripts  , to answer our research questions.Depending on the user's option  , three possible scenarios can be generated from this pattern. With further customization  , the user can enable three possible methods for refreshing data from Nasdaq.The site offers both free open source project hosting and paid private hosting and is home to over ten million repositories 1. GitHub is a project-hosting site started in 2008 that brands itself as "Social Coding."Despite their different topics of interest  , Quora and Stack Overflow share many similarities in distribution of content and activity. This is the focus of the rest of our paper  , where we will study different Quora mechanisms to understand which  , if any  , can keep the site useful by consistently guiding users to valuable information.It is also the largest online book  , movie and music database and one of the largest online communities in China. Douban  , launched on March 6  , 2005  , is a Chinese Web 2.0 web site providing user rating  , review and recommendation services for movies  , books and music.However  , the mean is a poor statistic to describe the power-law distributions of links on the web; average linkage is dominated by the many pages with few links and gives little insight into the topology. They concluded that linkage in WT2g was inadequate for web experiments.Projects were taken from Github 15  , one of the largest public repositories of Java projects. for functional languages — would be less justified.The first evaluation is based on the LETOR datasets 17  , which include manual relevance assessments. The rankers are compared using the metric rrMetric 3.The source code for the implementation is available from GitHub 1 . The feature extraction and validation job builds upon the MapReduce programming model  , using Jpylyzer and SCAPE Control Policies.Ask.com has a feature to erase the past searches. Search engines typically record the search strings entered by users and some search sites even make the history of past searches available to the user.Github can automatically verify whether a pull request can be merged without conflicts to the base repository. Through Github facilities.8 GitHub user profiles  , confirm this consideration. In Fig.It was obtained by repeatedly crawling Pinterest: To discover new pins  , each of the 32 category pages was visited once every 5 minutes   , and the latest pins of that category were collected. Our dataset is derived from a previous study 38  , and includes nearly all activities on Pinterest between Jan 3–21 2013.Events include participating in issues  , pull requests  , and commenting on various GitHub artifacts. To measure prior interaction  , we counted the number of events before a particular pull request that the user has participated in for this project.Unfortunately  , the LDA based topic mining approach has failed in this task. And we hopped to be able to generate weighted distribution of words that could potentially identify multiple topics of a query from the top ranked documents  , and by using these approximations of multiples topics  , we can perform multiple searches for the same query with different expansions  , followed by separate LETOR for each expanded query  , and eventually merge the results with data fusion.Both sites are built around members evaluating and discussing beer. We use this framework to study two large  , active online communities: RateBeer and BeerAdvocate.They conducted a tworound survey with 21 and 749 GitHub integrators on what factors they consider in their decision making process to accept or reject a pull request. 12 explored the practices of pull-based development model.Sindice 1  , Watson 2  adopt keyword-based search and ranked result lists presentation of traditional Information Retrieval IR  , which is not very efficient for large volumes of data 3 . However  , current approaches e.g.We use the Gerbil testing platform 37 version 1.1.4 with the D2KB setting in which a document together with a fixed set of mentions to be annotated are given as input. Further   , we show an empirical comparison between PBoH and well known or recent competitive entity disambiguation systems .All experimental results are averaged over 10 independent rounds of random training / validation / query partitions. Using normalized hyper-parameters described in Section 2.6  , the best hyper-parameters are selected by using the validation set of CIFAR-10.To that end  , we have conducted a statistical analysis of millions of pull requests  , as well of a carefully composed set of hunders of thousands of pull requests from projects actively using the pull-based model. The goal of this work is to obtain a deep understanding of the pull-based software development model  , as used for many important open source projects hosted on Github.We also introduced an algorithm using the collection's information in prior art task for keyword selection. For technology survey  , we proposed a chemical terminology expansion algorithm with the professional chemical domain information from two chemical websites  , ChemID plus and PubChem.This is because the LETOR data set offers results of Linear Ranking SVM. For all the SVM models in the experiment  , we employed Linear SVM.We find that all three of its internal graphs  , a user-topic follow graph  , a userto-user social graph  , and a related question graph  , serve complementary roles in improving effective content discovery on Quora. In this paper  , we use a data-driven study to analyze the impact of Quora's internal mechanisms that address this challenge.We evaluate our algorithm on the purchase history from an e-commerce website shop.com. Applying our utility function to SVD leads to a new utility function SV D util in this paper.compared more than 15 systems on 20 different datasets. Using GERBIL  , Usbeck et al.This dataset contains the purchase history from 2004-01-01 to 2009-03-08. Since this paper focuses on the recommendation in ecommerce sites  , we collect a dataset from a typical e-commerce website  , shop.com  , for our experiments.We computed Fleiss' Kappa to measure the inter-annotator agreement for this task  , obtaining 0.241 for the Quora topics   , 0.294 for the HF topics  , and 0.157 for the NYT topics. The first condition can capture  , for instance   , words related to diseases  , the second can capture words related to political or religious positions.For our evaluation we used a dump of the PubChem database 4 containing around 31.5 million chemical entities. For each of these documents we extracted the chemical entities and their roles within a reaction.Thus in our analysis of Quora  , we only refer to upvotes and disregard downvotes . Downvotes are processed and only contribute to determining the order answers appear in.This research targeted users of GitHub  , a popular code sharing site. The interviewees were from 9 geographic regions: North America  , Middle America  , South America; Europe; Africa; West Asia  , Central Asia  , East Asia; and Australia / New Zealand.Douban  , launched on March 6  , 2005  , is a Chinese Web 2.0 web site providing user rating  , review and recommendation services for movies  , books and music. The first data source we choose is Douban 1 dataset.Figure 4depicts the novel process we developed to categorize tweets. This step is necessary in order to make pins and tweets directly comparable: on Pinterest  , all pins fall into 1 of 33 pre-defined categories  , while tweets are freeform text.In order to determine the benefits of a close-knit structure  , we examine one of the most popular activities on the Pinterest network   , repinning. While these properties are expected to improve social interaction 18  , 26  , we ask whether the benefits of these structural properties are seen in the social interactions of the target network.From the work of Kleinberg in 7  , it is generally accepted that for queries on broad topics  , Connectivity Analysis will allow for the selection of the most popular densely linked documents from within a WWW community in response to a query  , in addition to automatic result clustering. We do suggest caution being taken when reviewing the Small Web Task to take the results in the context of the WT2g dataset  , lest one conclude that Connectivity Analysis does not improve precision in any case.To answer these questions  , we performed an analysis of contribution from thousands of projects on the social open source project-hosting site GitHub. For example  , site designers may choose to make important signals more salient to developers.They also highlight that there is plenty of room for collaboration between IR and Semantic Search. These conclusions can be helpful to improve the performance of Semantic Search engine implementations based on Lucene  , such as Sindice  , Watson  , Falcons or SEMPLORE.To ensure compliance with lmer's modeling assumptions  , we also checked the QQ-plot for our model  , which showed good match with a normal of the current week  , relative to one's first ever recorded GitHub contribution . We conclude collinearity between our variables is not an issue.4 In Figure 7 we have already illustrated the distribution of ratings over time for the hotel Punta Cana Princess evaluated on TripAdvisor. However  , reviews shortly after the second anomaly note that " .. they are now doing some construction to try and fix things .. "   , giving hint to an improvement of the airport which may have caused the better evaluation almost no 1 star ratings at the end of the rating behavior.The best results in Table 2are highlighted in bold. Table 2summarizes the total performance of BCDRW and BASIC methods in terms of precision and coverage on the aforementioned DouBan data set.The results of RankSVM  , RankBoost  , AdaRank and FRank are reported in the Letor data set. For AdaRank  , we use the version for optimizing the mean average precision for comparison in this study.We are not surprised that our systems did not work well on diversity metrics as shown in Table 3  , because the diversity module of our system was not functioning as we expected and eventually we chose to not to include it in our pipeline. This also suggests that our LETOR framework is effective in improving the overall precision.In total 68.7 million Pinterest users and 3.8 billion directed edges between them were obtained. To obtain the Pinterest social graph  , we used a snowball sampling technique  , starting to crawl from a seed set of 1.6 million users which we collected in advance.The BTC data set has been crawled from the web in a typical web spider fashion and contains about 1.44 billion triples. For our empirical analysis  , we use the different segments of the data set provided for the Billion Triple Challenge BTC 2012.The coordination mechanism allows an additional filter to be added to filter out the sidebars and footers  , and to return only the pure article text. For example  , most of the 10 news sites  , which are used for the current GeoTopics  , have sidebars and footers in their articles  , which cause falsematching problems e.g.  , 'NASDAQ' was ranked high because it is appeared on the side bars in many of the news articles.Dataset. The user who introduces an image into Pinterest is its pinner; others who copy onto their own pinboards are repinners.Thirty PHP scripts  , one Java program and a Ruby gem are now available for any use including commercial   , modification and redistribution by anyone wishing to generate BioRDF data  , or to improve the quality of RDF conversions currently used in Bio2RDF. GitHub facilitates collaborative development through project forking  , pull requests  , code commenting  , and merging.They do not realize that the danger of getting lost concerns a substantial part of the comparatively recent written record. In hearing about paper preservation " they think primarily in terms of mediaeval manuscripts  , precious editions and old documents.Experience versus rating variance when rating the same product. This phenomenon is the most pronounced on RateBeer Figure 5: Experienced users agree more about their ratings than beginners.Which identities benefit the most ? Figure 6 : Age of curated Pinterest identities: identities curated using Pinterest reputation signals vs additionally curated identities using all signals.P -perfect user model setting  , I -informational  , N -navigational LETOR eval- uation. The error bars are standard errors of the means.com/ConstantB/ontop-spatial/wiki/Shapefiles. We imported the Shapefiles into a PostGIS database and created virtual geospatial RDF views on top of them using Ontop-spatial  , as described at https://github.The motivation in this case was to find queries of a similar type e.g.  , navigational or information queries  , but no improvements were observed with smaller training sets such as Letor. There have been some attempts to do this 1  , 4.Our analysis suggests that while following technical contribution norms for pull requests is associated with acceptance  , the social connections behind pull requests have even stronger associations. However  , in the environment of GitHub  , which is both transparent and equipped with social media functionality  , we also expect contributors to make use of the social connections that the environment makes salient.We found moderate to strong correlations between journal-level altmetrics except with Pinterest and the Q&A site  , which is  The absence of high correlations between altmetrics and citationbased metrics shows the existence of differences between scholarly and social importance. All correlations were significant at p < 0.01.25 quantitatively investigated the characteristics of contributions in GitHub  , finding that contributions are relatively small 20 lines and processed very quickly submissions are accepted in less than a day. Gousios et al.Further details regarding the implementation of VmVm  , including a more detailed and technical discussion of the instrumentation passes performed  , are available in our accompanying technical report 8 or directly on GitHub 7. Both the ant and maven hooks that we wrote consist of only a single line of code: VirtualRuntime.reset  , which triggers the reinitialization process.The user-topic interaction has considerable impact on question answering activities in Quora. Following the right topics can introduce users to valuable questions and answers  , but is not the only way to access questions.33  proposed an expertise modeling algorithm for Pinterest. Recently  , Popescu et al.This technological affordance 3 makes it easy to reuse and share images. Pinterest users organize objects by selecting an image from the webpage where the object exists using a browser bookmarklet or by uploading an image from their computer.To ensure the practicability and convenience of the GER- BIL framework  , we investigated the effort needed to use GERBIL for the evaluation of novel annotators. The results of this experiment are shown in Figure 4.For brevity  , we report MAP as the measure of system performance . This latter question is a matter of some interest  , as the MAP scores for LETOR 3 approach the 65% considered achievable with human-adjudicated relevance 5.Even though small  , this evaluation suggests that implementing against GERBIL does not lead to any overhead. Further developers were invited to complete the survey  , which is available at our project website .The WT2G collection is a general Web crawl of Web documents  , which has 2 Gigabytes of uncompressed data. The Disk1&2  , Disk4&5 collection contains newswire articles from various sources  , such as Association Press AP  , Wall Street Journal WSJ  , Financial Times FT  , etc.  , which are usually considered as high-quality text data with little noise.We begin by briefly describing Pinterest  , our terminology  , and the dataset used in the rest of this paper: Pinterest is a photo sharing website that allows users to organise thematic collections of images. We ask what is the probability P repin_catp  , iThe key concern is users who have many followers can get their followers to vote for their answers  , thus gaining an " unfair advantage " over other users. However  , the social interaction among Quora users could impact voting in various ways.We compare the proposed context-aware biased MF with conventional biased MF and a representative context-aware model FM. The user-related and item-related contexts are the same with those used in Douban book data.We use the validation set to decide which kernels to use in the transductive system. Following LETOR convention  , each dataset is divided into 5 folds with a 3:1:1 ratio for training  , validation  , and test set.Table 4 : Performance improvement resulting from incrementally adding our linguistic change features to the 'activity' model for RateBeer  , our 'test community'. For all sites and w  , the full model significantly improves over the activity-only model according to a paired Wilcoxon signed rank test on the F1 scores p < 0.001.In Study 3 S3  , we analyze 100 randomly selected public GitHub repositories that use Java's Study 2 S2 is a pilot survey that gathers data from 11 developers who asked Java cryptography-related questions on Stack- Overflow.We used Github data as provided through our GHTorrent project 16  , an off-line mirror of the data offered through the Github API. Up to August 2013  , 1.9 million pull requests from more than two hundred thousand projects have been collected.The " Open Knowledge Extraction " challenge at ESWC 7 and frameworks such as GERBIL 28 are good systems to validate our approach. identification of locations  , actors  , times at hand.Combining each time different subsets to make the training  , the validation and the test set  , the LETOR authors create 5 different arrangements for five-fold cross validation. In LETOR  , data is partitioned in five subsets.The Billion Triple Challenge dataset was created based on datasets provided by Falcon-S  , Sindice  , Swoogle  , SWSE  , and Watson using the MultiCrawler/SWSE framework. They represent two very different kinds of RDF data.Whenever applicable  , We also used terms from SDMX extensions 19 which augment the Data Cube Vocabulary by defining URIs for common dimensions  , attributes and measures. It extends SCOVO 10 with the ability to explicitly describe the structure of the data and distinguishes between dimensions  , attributes and measures.The 24-hour requirement stems from the fact that Pinterest displays relative timestamps with decreasing resolution  , i.e.  , a pin from an hour ago will display " posted 1 hour ago  , " whereas a pin from yesterday will display " posted 1 day ago. " However  , collecting pins requires addressing two technical challenges: 1 each pin must be gathered within 24- hours after it was generated  , and 2 each pin must be gathered individually.The transparent nature of GitHub also led developers to become acutely aware that their work actions had an audience. In some cases  , multiple rounds of comments were necessary in order to establish shared understanding.We chose to standardize this issue  , using the same criterion used by most evaluation tools  , e.g.  , those available for the Letor 3.0 and 4.0 and Microsoft datasets  , in order to allow fairer comparisons. assume the value of 1 for these cases  , which may lead to higher values of NDCG 2.Experimental results  , obtained using the LETOR benchmark  , indicate that methods that learn to rank at query-time outperform the state-ofthe-art methods. By generating rules on a demand-driven basis  , depending on the documents to be ranked  , only the necessary information is extracted from the training data  , resulting in fast and effective ranking methods.The task of 'entity linking' to a knowledge base has received significant attention  , with one major venue being the Text Analysis Conference TAC Knowledge Base Population KBP Entity Linking Task 17. We bridge the gap between entities and text using automatic information extraction to identify entities and link them to a knowledge base.To ask respondents about their work habits before coding  , we provided them with a set of 7 questions based on our analysis of the literature and our vast GitHub experience with a 4-level Likert scale. r439 Work practices followed after coding.One approach to aggregated search is to use different vertical searches images  , video  , news  , etc. Sig.ma  , which is a search application built on top of Sindice  , is positioned in another area more closely related to the " Aggregated Search " paradigm  , since it provides an aggregated view of the relevant resources given a query 6.Recently  , but after our crawling period  , Pinterest enabled the possibility of creating secret boards: basically  , boards which only the owner has access Milam 2012. The user is able to create a collection of boards  , which is summarized in her profile along with a self description  , a profile picture  , and information about her activity and relationship with other users such as her pins  , likes  , board  , users that she follows and follows her  , as well the last fifty activities .We evaluated VmVm to determine the performance benefits that it can provide and show that it does not affect fault finding ability. We have integrated it directly with popular Java testing and build automation tools JUnit 2  , ant 5 and maven 6  , and it is available for download via GitHub 7.On one hand  , different clustering techniques such as HAC  , VOS clustering 9—a community detection algorithm—and K-star 33 were used by the participants. Besides the two systems described in detail in §3.5  , RepLab participation included both supervised and unsupervised techniques.the various categories. Figure 1: Number of events detected in the GitHub stream.Using a mixed-methods approach survey+quantitative analysis of mined data we study this phenomenon . With the advent of ecosystems like GitHub  , another tier of context-switching becomes possible: switching between projects.There are 106 queries in the collection split into five folds. We also analyze the results of our approach on a different dataset; OHSUMED 5 which is also available in Letor 16.Over a period of 50 days  , we collected more than 2 million profiles  , which comprise beyond 850 million images and videos pinned into more than 20 million boards. Our study focuses on gender-based analysis of user behavior and our contributions are the following:  We develop a distributed crawler to collect a large dataset from Pinterest.Pinterest is a pinboard-style image sharing social network designed to let users collect and share images and videos in an organized  , categorized way. 1 http://bit.ly/1jfjRHL 2 http://bit.ly/1ksdYHv 3 http://bit.ly/1dxEJSX 4 http://bit.ly/OFmPrj Figure 1: Pinterest profile of a famous designer/blogger.We describe details below. A publicly available dataset periodically released by Stack Overflow  , and a dataset crawled  from Quora that contains multiple groups of data on users  , questions   , topics and votes.The results presented in the experimental section were obtained using the Quora topic model as the background knowledge model. Training corpus changes.Most of pinboards are associated with one of 32 categories such as 'Design'  , 'Products'  , 'Home Decor'  , 'Animals and Pets'  , etc.  , which are globally recognised on Pinterest. lection of related pins e.g.  , one pinboard may have pins with images of different wedding dresses.GERBIL abides by a service-oriented architecture driven by the model-view-controller pattern see Figure 1. The output of experiments as well as descriptions of the various components are stored in a serverless database for fastWhat role do the " related questions " feature play ?  Given the rapid growth of questions on question-and-answer sites  , how does Quora help users find the most interesting and valuable questions and avoid spammy or low-value questions ?We have learned various lessons in our first attempt at this task. We bootstrapped this system by transferring the learned model from TAC KBP 2010 thereby circumventing the need for training examples.Before comparison  , we determine two important parameters  , i.e.  , latent factor vector dimensionality and the number of iterations for matrix factorization based models. Finally  , we compare the performance of SoCo with that of other recommender systems using the Douban dataset.We also applied the algorithm to rank ads with non-linear ranking function described in section 7 in contextual advertising in both online and offline scenarios. The results on seven datasets in LETOR 3.0 show that the NDCG-Annealing algorithm can outperform the baselines and it is more stable.Swoogle allows keyword-based search of Semantic Web documents . Several systems have implemented text-based search over Semantic Web data: Swoogle 8  , SemSearch 14  , Falcons 5  , Semplore 22  , SWSE 10  , Hermes 18  , Sindice/Sigma 19 .Previous work 25 found that the median number of PRs across repositories is 2; in our sample and considering the initial selection of projects  , the smallest project had more than 400. Our selection of projects and contributors to GitHub projects using the pull-based model may not be indicative of the average project.This is because some of their related questions were not crawled questions deleted by Quora and thus are not included as nodes. However  , there are 9% questions with degree less than 5.Unfortunately we could not do the same for question page views  , because Quora only reveals the identity of users who answer questions   , but not those who browse each question. We verify this intuition by examining for each question the percentage of answers that came from followers of the question's topics.We start with a macro-scale analysis of users with different kinds of social links  , and check whether the active users are also consistent  , by measuring user retention. Users with both types of repins 21% of all users contribute 71% of Pinterest activities.The Sindice index does not only allow search for keywords  , but also for URIs mentioned in documents. This is performed via textual or URI search on the Sindice index and yields a set of of source URLs that are added to the input source URL set.The only interactions supported by Pinterest are repins  , comments on pins  , and likes. Each pin is characterized by a relative timestamp e.g.  , " posted 22 hours ago "   , " posted 5 days ago "   , a description freeform text  , and a link to the source of the content if it originated from a third-party website.For example  , using a crawler and Sindice  , LOD resources can be categorized offline by the proposed fuzzy retrieval model 8  , or other clustering methods also UMBEL linked data mappings can be used. After receiving results  , our system augments the results with UMBEL categorizations  , which can be performed offline or dynamically 9.All features are calculated at the time a pull request has been closed or merged  , to evaluate the effect of intermediate updates to the pull request as a result of the ensuing discussion. 5  , presented evidence that social reputation has an impact on whether a patch will be merged; in our dataset  , the number of followers on Github can be seen as a proxy for reputation.To evaluate swim  , we trained the natural language model with 15 days of clickthrough data from Bing  , and learned structured call sequences from a corpus of 25 ,000 open-source projects from GitHub. This last thread is what is run online in response to a user query.A second difference concerns the objectives of the search procedures operating in the system. The sources of the stored documentation are thus very varied ; in the case of the existing prototype mediaeval history of France the sources include : original documents  , learned contemporary works  , articles from journals  , etc.We also conducted experiments to observe the training curve of PermuRank.MAP in terms of MAP on OHSUMED. Figure 5and Figure 6show the results on the Letor TD2003 and TD2004 datasets.To include further metadata  , annotator and corpus dimension properties link DataID 2 descriptions of the individual components. The six evaluation measures offered by GERBIL as well as the error count are expressed as qb:Measures.We compare our proposed NDCG-Annealing algorithm with those baselines provided in LETOR 3.0. As a result  , the NDCG-Annealing algorithm is more stable and pronounced compared to the baselines in LETOR 3.0 dataset.Falcons  , Swoogle and Sindice have at some point in time been available as public Web Services for users to query. Sindice  , Falcons and Hermes are formally evaluated over hundreds of millions of statements  , while Semplore is evaluated over tens of millions of statements.The process used by Github to select projects is not public  , but we believe it is orthogonal to our concerns  , and likely based on popularity and recency. Note that it is also not the full set of Maven projects  , since Github only returns 99 pages of search results.GitHub also provides a set of social networking features. Of course  , project managers may also ignore the contribution  , leaving the pull request "open".The importance of this collaboration platform seems to be increasing  , as its founder has plans to extend the use cases beyond software development Lunden 2013 . For all these reasons  , GitHub has successfully lowered the barrier to collaboration in open source.Since each Quora user lists the topics she follows in her profile  , we estimate the number of followers by examining user profiles in our crawled dataset. Next  , we rank the topics by the number of followers.They divide the abstract in two parts: the first  , static part showing statements related to the main topic of the document  , and weighted by the importance of the predicate of the triple  , while the second  , dynamic part shows statements ranked by their relevance to the query. worked on snippet generation for a semantic search engine Sindice that indexes instance data 2.The two methods described in this section focus the user's display on their current context e.g.  , mediaeval history. The use of this system is investigated in Section 5.purity when curating identities using all signals intra-domain and inter-domain reputation signals  , only Pinterest signals only intradomain reputation signals  , and by simply randomly picking identities . Figure 5shows the coverage vs. the level of Figure 5: Coverage of the curated set for a given purity level for identities curated using all signals  , only Pinterest signals  , and identities curated at random.Our manually-constructed disambiguation index is publicly available on the GitHub page. Semantic Entity Embeddings: We store the semantic embeddings created with Word2Vec and Doc2Vec in our index to provide fast access.The GHTorrent dataset covers a broad range of development activities on Github  , including pull requests and issues. The data is stored in unprocessed format  , in a MongoDB database  , while metadata is extracted and stored in a MySQL relational database.For list-wise LETOR  , we are using ListNet 6  , which uses a simple one layer Neural Network with Gradient Decent to optimize a defined list-wise loss function based on " top one probability " . We expect the pairwise methods to perform better than point-wise approaches  , as the features collected from the error pairs are more meaningful as they define relative distances.separating the wheat from the chaff  , is a very difficult problem. A key observation is that given the broad and growing number of topics in Quora  , identifying the most interesting and useful content  , i.e.Social coding sites e.g.  , GitHub 20  , Bitbucket 6   , and Gi- torious 21  offer the pull-based development model in conjunction with social media functions  , which allow users to subscribe to and/or visualize information about activities of projects and users and offer threaded asynchronous communication within PRs. Then the members of the project's core team the integrators are responsible for evaluating the quality of the contributions  , proposing corrections   , engaging in discussion with the contributors  , and eventually merging or rejecting the changes.All data sets are integrated in GERBIL and strongly differ in document length and amount of entities per docu- ment. In the following  , we present seven well-known and publicly available data sets which are used in our evaluation.These low values confirm that sensitivity is rather subjective . We computed Fleiss' Kappa to measure the inter-annotator agreement for this task  , obtaining 0.241 for the Quora topics   , 0.294 for the HF topics  , and 0.157 for the NYT topics.Bloggers that provide music codes to add to blogs which play music and video are also popular in Xanga XaNgA MuSiC  , Music Galore. The top blogs on Xanga from our data include blogs of celebrities  , mostly from Hong Kong MandyStarz  , kellyjackie and stephy tang.We sent an online survey to 851 GitHub users selected from the set of prolific developers described earlier. The survey participants reported development experience was 17.2 years on average median 15; range 7 to 40  , while their GitHub experience was 5.9 years on average median 6; range less than 1 to since GitHub was founded.All presented NDCG  , Precision and MAP results are averaged across the test queries and were obtained using the evaluation script available on the LETOR website. To compute P@k and MAP on the MQ datasets the relevance levels are binarised with 1 converted to 0 and 2 converted to 1.Note that our experiments setting is more challenging than the TAC-KBP competition 28 since we don't assume the availability of various kinds of annotations e.g. Therefore the queries are relatively long and the writing quality is good.Our experiments with two applications from Ask.com indicate the proposed techniques can effectively reduce response time and improve throughput in overloaded situations. Our design dynamically selects termination threshold  , adaptive to load condition and performs early termination safely.There are multiple black-market sites where Pinterest repins or likes can be fraudulently obtained 6  , 7  , 8. This has led to the emergence of a variety of black-market sites where one can buy services that help to artificially boost the popularity of their content.The LETOR-like selection achieves both high precision and recall at small percentages of data used for training up to 5% and then it drops to the levels of statAP and depth pooling. Since infAP is based on uniform random sampling  , the precision of infAP stays constant while the recall grows linearly with the sample percentage.For each type  , we extracted structured call sequences from 10 ,000 source files using the type. To evaluate swim  , we trained the natural language model with 15 days of clickthrough data from Bing  , and learned structured call sequences from a corpus of 25 ,000 open-source projects from GitHub.Figure 8 shows the results on the DOUBAN and LIVE- JOURNAL datasets. With similar running time  , IMRank2 achieves significant higher influence spread than that of PMIA and IRIE.We study in this paper the problem of attributing revisioned content to its author  , and more generally  , to the revision where it was originally introduced. Code is another prominent example of revisioned content  , and one that is becoming common on the web  , thanks to the success of sites like GitHub  , where users can share their code repositories.Each image of size 32 × 32 is represented by a 512-dimensional GIST feature vector. The CIFAR-10 dataset 11 consists of 60 ,000 color images drawn from the 80M tiny image collection 29.Sig.ma  , which is a search application built on top of Sindice  , is positioned in another area more closely related to the " Aggregated Search " paradigm  , since it provides an aggregated view of the relevant resources given a query 6. Semantic Web search engines  , such as SWSE 5  , Swoogle 4  , Falcons 2 or Sindice 7  , are based on the common search paradigm  , i.e.  , for a given keyword query or more advanced queries the goal is to return a list of ranked resources based on their relevance.We estimate the number of in-links by iterating over all elements in AC and querying the Sindice 9 SPARQL endpoint for triples containing the concept's URI in the object part. Estimating the number of in-links and identifying the concepts without any in-links  , can indicate the importance of a concept.The pull-based development model  , in conjunction with the social media functions offered by GitHub  , makes contributions and their authors more prominent than in other contribution models. Transparency.It is a good datasest for our experiments since we will be discovering patterns from features that have already been proven to work. The LETOR dataset conveniently extracts many stateof-the-art features from documents  , including BM25 22  , HITS 14  , and Language Model 34.Because the time between two pins may be widely different across users  , we measure user age in terms of repin steps  , the number of re-pins made since joining Pinterest. We then ask whether time matters: i.e.  , Do social repins become more important as the user matures and conducts more activities on Pinterest ?Note that we did not use the public LETOR data 15  , because the numbers of queries in the datasets are too small to conduct meaningful experiments on query dependent ranking. All the methods tested in this section are based on the same feature set.Followers – This measure is the number of followers a GitHub user has at time of data collection. For example  , users with lots of followers were treated as local celebrities.2013  has shown that behavior on Pinterest differs significantly by gender. Other work Ottoni et al.Finally  , we compare the performance of SoCo with that of other recommender systems using the Douban dataset. 8 and 9 and find that our proposed context-aware PCC reduces MAE/RMSE compared to original PCC by around 4.25%/5.46% on average book data  , movie data and music data.In hearing about paper preservation " they think primarily in terms of mediaeval manuscripts  , precious editions and old documents. But unfortunately the users -the scientists and scholars -often underestimate the scope and the urgency of the need for preservation work.From the table below we conclude further that SCOVO seems to be the best combination of flexibility and usability  , allowing to recreate the data-table structures with a reasonable degree of fidelity in another environment that is  , on the Web. Both other approaches are not capable of representing historical data and only provide statistics for one point-in-time.While it is difficult to prove causal relationships  , our data analysis shows strong correlative relationships between Quora's internal structures and user behavior. We find that all three of its internal graphs  , a user-topic follow graph  , a userto-user social graph  , and a related question graph  , serve complementary roles in improving effective content discovery on Quora.Our estimated number of questions in Quora for June 2012 is 700K  , which is consistent with previously reported estimates 24. Both lines increase smoothly without gaps  , suggesting that Quora did not reset qid in the past and the questions we crawled are not biased to a certain time period.We frame our study in the context of multitasking across GitHub projects  , i.e.  , switching back and forth between multiple projects that one contributes to  , within a short period of time our operationalization below is one week. Research Questions.Our empirical results show that this strategy performs best when taking into account the costs of materialization  , both on Web Data Commons and on Billion Triple Challenge data. The ultimate answer to this question depends on the exact data and queries used  , though based on our experimental analysis above  , we believe that an adaptive materialization strategy provides the best trade-off for running provenanceenabled queries over Web Data in general.We combined: 1 an analysis and regression modeling of repository data  , to quantitatively examine the effects of multitasking and focus switching on productivity; and 2 a user survey  , to garner additional qualitative insight into the developers' perceptions of multitasking  , focus switching  , and their effects. We analyzed development activity and perceptions of prolific GitHub developers.We then give details on the key Quora graph structures that connect different components together. In this section  , we introduce Quora  , using Stack Overflow as a basis for comparison.Then  , for each search result LOD URI  , parallel requests are sent to the server for categorization of LOD resources under UMBEL concepts. Using these input queries  , our system search the WoD by utilizing Sindice search API 2 and initial search results from the Sindice search are presented to users with no categorization.Images posted by identities on Pinterest are called pins. Identities with black-market association: In this dataset  , we collect information about identities associated with a black-market service.The second is repinning   , or copying an existing pin on Pinterest. The first way is pinning  , which imports an image from an external URL.Table 1compares the implemented annotation systems of GERBIL and the BAT-Framework. provide the source code 25 as well as a webservice. Given the rapid growth of questions on question-and-answer sites  , how does Quora help users find the most interesting and valuable questions and avoid spammy or low-value questions ? Can they generate and focus user attention on individual questions  , thus setting them apart from questions on related topics ?As Figure 1 shows  , its popularity is constantly growing; in January 2016  , 135 ,000 repositories on the GitHub social coding site received more than 600 ,000 pull requests. '16  , May 14 -22  , 2016  , Austin  , TXFigure 1: Monthly growth of pull request usage on GitHub.GitHub facilitates collaborative development through project forking  , pull requests  , code commenting  , and merging. In 2012  , we consolidated the set Bio2RDF open source 5 scripts into a single GitHub repository bio2rdf-scripts 6 .Users on Douban can join different interesting groups. Hence  , Douban is an ideal source for our research on measuring the correlations between social friend and user interest similarity.In Storify  , the people tend to use social media and web resources to create their narratives about events  , or something of interest. Most of the pins on Pinterest come from blogs  , or uploaded by users.Most QA systems are substantial team efforts  , involving the design and maintenance of question taxonomies 14  , 15  , question classifiers  , and passage-scoring heuristics. Fal- con 14  , Webclopedia 15  , Mulder 18  , AnswerBus 28 and AskMSR 11 are some well-known research systems  , as are those built at the University of Waterloo 7  , 8  , and Ask Jeeves http://ask.com.For each input URL the server would respond with a list of incoming links from other WT2g documents and outgoing links. First a connectivity server was made available on the Web.We followed the advice from a Quora data scientist 3 and start our question crawls using 120 randomly selected questions roughly evenly distributed over 19 of the most popular question topics. Since Quora has no predefined topic structures for its questions questions can have one or more arbitrary topic " labels "   , getting the full set of all questions is difficult.They concluded that linkage in WT2g was inadequate for web experiments. Singhal and Kaszkiel 4 looked at average in-and out-links  , within and across hosts  , between the smaller WT2g corpus and their own large crawl.This strategy is also more in line with intuition. and WT2g.Using it  , we first explore the use of almost 2 million pull requests across all projects in Github. Our study is based on data from the Github collaborative development forge  , as made available through our GHTorrent project 16.We studied 10 OSS Java projects  , as shown in Table 1: among these are five projects from Github  , while the others are from the Apache Software Foundation. 43  , in which snapshots of the five Apache projects were taken atBut no explicit social relationships are maintained in TripAdvisor   , so we need to construct an implicit influence network and learn the influence probabilities on the network. In the formulation of the participation maximization problem Section 4  , the social influence network is treated as an input of the problem.We tried to follow crawler-etiquette defined in Quora's robots.txt. We gathered our Quora dataset through web-based crawls between August and early September 2012.To our knowledge  , we are the first paper to explicitly parallelize CART 5  tree construction for the purpose of gradient boosting. On the Microsoft LETOR data set  , we see a small decrease in accuracy  , but the speedups are even more impressive.Another thread of research on social search is closely related to social question-and-answer QA systems  , like Quora 30   , that allow users to ask questions to a larger community  , or Aardvark 15  , 8  , which connected users to individual members to whom they could ask a question. Moreover  , finding others willing to collaborate at the same time seems to be a barrier to wider adoption of this technology.To validate the identified codes  , all three authors applied them on a different set of pull requests  , compared results  , identified inconsistencies and retrofitted the initial selection of codes. We use open coding a grounded theory tool to come up with an inclusive set of reasons of why pull requests are not merged as follows: the first author read the pull request discussion on Github for randomly selected pull requests and summarized the reasons for closing them into one sentence per sample; during a second pass  , the descriptions were aggregated and codes were extracted .Moreover   , we report that females make more use of this kind of interaction and are more active in terms of content generation . For instance  , even with Pinterest restrictions for social communication  , we show that such communication still happens in the form of lightweight interactions such as likes and repins.The latter is typical in our case because the scores generate by different LETOR algorithms are different in terms of scale and rank-score curves. Many previous studies on Data fusion 17 18 19 suggested that when the scores of the systems to be combined are commensurable   , using score based fusion methods are better than using only the rank positions  , but when the scores are incompatible or if the systems generate different rank-score curves  , rank based fusion techniques are better.Our query translation algorithm has been implemented in our latest version of Morph  , which is available as a Java/Scala opensource project in Github 9 . Their details are available in the following sub-sections.A simple search on Quora about how it works produces numerous unanswered questions about Quora's size  , mechanisms  , algorithms  , and user behavior. While it is public knowledge that Quora differs from its competitors in its use of social networks and real identities  , few additional details or quantitative measures are known about its operations.For example  , project managers see an urgent need for automatic testing in their projects in order to maintain quality as the number of peripheral developers scales 23. We see in prior work about GitHub that there are certain contribution norms that signal a technically well-prepared contribution.No one on Xanga mentioned Al-Qaeda. It is evident that Moussaoui is talked about more by Blog Spot users than Live Journal or Xanga  , even though it has only a third of Live Journal's authors.Social collecting is indicative information organization  , use  , and sharing in a social web environment. In this work we introduced social collecting and the website Pinterest as an exemplar of the concept.API Documentation. A main advantage of our work is that we do not rely on one source of information  , but rather combine three di↵erent sources SO  , GitHub projects  , and developer surveys.First-time and secondtime reviewers excluded. c TripAdvisor.The approaches described in 17 and 19 extend upon the paradigm of simple entity search and try to generate interpretations of keyword queries which exploit the semantics available on the Linked Data Web. This led to semantic search engines  , such as Swoogle 5  , Watson 4  , Sigma 20 and Sindice 21  , which aim to index RDF across the Web and make it available for entity search.We take entities as keywords and analyse the searching results in the system. We define some patterns and values as Table 1: In ELC task  , homepages are in the Sindice dataset.Pinterest has an interesting way of dealing with commercial products in the network . We used the tau-b version of Kendall's tau  , which is defined by:Dataset. Note that streams for synthetic data differs from NASDAQ data in terms of the lag and the missing update distributions.With Sindice being discontinued in 2014  , no text-based Semantic Web search engine is widely available to the Semantic Web community today. Falcons  , Swoogle and Sindice have at some point in time been available as public Web Services for users to query.